{"cells":[{"cell_type":"markdown","metadata":{"id":"rxoHWNZEmG4g"},"source":["# Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"T3Y5CLhymG4l","executionInfo":{"status":"ok","timestamp":1717580792657,"user_tz":-480,"elapsed":8,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["# !pip install omegaconf"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BxzI25zfmG4n","executionInfo":{"status":"ok","timestamp":1717580797232,"user_tz":-480,"elapsed":4580,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"outputId":"9a60466f-d710-4bc7-a847-6cc2f2f6ff62"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive/\")\n","#\"/content/drive/My Drive/NN-kNN/\"\n","folder_name = \"/content/drive/Othercomputers/My MacBook Pro/GitHub/NN-kNN/\"\n","import sys\n","sys.path.insert(0,folder_name)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"joYfU4jLmG4o","executionInfo":{"status":"ok","timestamp":1717580797233,"user_tz":-480,"elapsed":6,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["# folder_name = os.getcwd()"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"oDGrACwVmG4o","executionInfo":{"status":"ok","timestamp":1717580805271,"user_tz":-480,"elapsed":8043,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["import torch\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import accuracy_score\n","from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n","from sklearn.metrics import mean_squared_error\n","from tqdm import tqdm\n","from omegaconf import DictConfig, OmegaConf\n","\n","from dataset import cls_small_data as Cdata\n","import model.cls_model as Cmodel\n","from dataset import cls_medium_data\n","\n","from dataset import reg_data as Rdata\n","import model.reg_model as Rmodel"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"bzTxZZJnmG4p","executionInfo":{"status":"ok","timestamp":1717580805272,"user_tz":-480,"elapsed":10,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["conf_file = OmegaConf.load(os.path.join(folder_name, 'config.yaml'))"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"yT3W4iqSmG4p","executionInfo":{"status":"ok","timestamp":1717580805272,"user_tz":-480,"elapsed":8,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"oaKz8Ns3mG4q"},"source":["# NCA and LMNN setup"]},{"cell_type":"code","source":["pip install metric-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cWQ8I6icoU8X","executionInfo":{"status":"ok","timestamp":1717580821058,"user_tz":-480,"elapsed":15792,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"outputId":"c198cbfa-88ed-4c4d-deae-067d3932aae2"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: metric-learn in /usr/local/lib/python3.10/dist-packages (0.7.0)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from metric-learn) (1.25.2)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from metric-learn) (1.11.4)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from metric-learn) (1.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->metric-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->metric-learn) (3.5.0)\n"]}]},{"cell_type":"code","execution_count":8,"metadata":{"id":"zmjbXrjQmG4q","executionInfo":{"status":"ok","timestamp":1717580821059,"user_tz":-480,"elapsed":11,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["import metric_learn\n","from metric_learn import LMNN,NCA"]},{"cell_type":"markdown","metadata":{"id":"46TjfSz-mG4q"},"source":["# Data Sets"]},{"cell_type":"markdown","metadata":{"id":"ZkDrsvjWmG4r"},"source":["Supported small dataset for classification:  \n","'zebra',\n","'zebra_special',\n","'bal',\n","'digits',\n","'iris',\n","'wine',\n","'breast_cancer',\n","'psych_depression_physical_symptons',\n","'covid_anxious'\n","\n","for regression:\n","'califonia_housing',\n","'abalone',\n","'diabets',\n","'body_fat',\n","'ziweifaces'"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"lxq-FY3FmG4r","executionInfo":{"status":"ok","timestamp":1717580821794,"user_tz":-480,"elapsed":743,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["dataset_name = 'covid_anxious'\n","cfg = conf_file['dataset'][dataset_name]\n","\n","if dataset_name in ['covid_anxious','psych_depression_physical_symptons',\n","                    'zebra','zebra_special','bal','digits','iris','wine','breast_cancer']:\n","    criterion = torch.nn.CrossEntropyLoss()\n","    Xs, ys = Cdata.Cls_small_data(dataset_name)\n","elif dataset_name in []:\n","    criterion = torch.nn.CrossEntropyLoss()\n","    Xs, ys = cls_medium_data.Cls_medium_data(dataset_name)\n","else:\n","    criterion = torch.nn.MSELoss()\n","    Xs, ys = Rdata.Reg_data(dataset_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aOIbeEfEmG4s","executionInfo":{"status":"aborted","timestamp":1717580631375,"user_tz":-480,"elapsed":8,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["# This section is used to reload the imported module.\n","# For example, if you made any changes in the model.cls_model, you should run importlib.reload(Cmodel) as long as you set import model.cls_model as Cmodel.\n","# import importlib\n","# importlib.reload(Rmodel)"]},{"cell_type":"markdown","metadata":{"id":"EOEnGkKnmG4s"},"source":["# Classification with NNKNN"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"xOraZstjmG4t","executionInfo":{"status":"ok","timestamp":1717580958431,"user_tz":-480,"elapsed":940,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["def train_cls(X_train,y_train, X_test, y_test, cfg:DictConfig):\n","  X_train = X_train.to(device)\n","  y_train = y_train.to(device)\n","  X_test = X_test.to(device)\n","\n","  train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train, y_train), batch_size=cfg.batch_size, shuffle=True)\n","\n","  # Train model\n","  model = Cmodel.NN_k_NN(X_train,\n","                         y_train,\n","                         cfg.ca_weight_sharing,\n","                         cfg.top_case_enabled,\n","                         cfg.top_k,\n","                         cfg.discount,\n","                         device=device)\n","\n","  optimizer = torch.optim.Adam(model.parameters(), lr=cfg.learning_rate) #, weight_decay=1e-5)\n","\n","  patience_counter = 0\n","  for epoch in range(cfg.training_epochs):\n","    epoch_msg = True\n","\n","    for X_train_batch, y_train_batch in train_loader:\n","      model.train()\n","      _, _, output, predicted_class = model(X_train_batch)\n","      loss = criterion(output, y_train_batch)\n","\n","      # Backward and optimize\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","      if epoch_msg and (epoch + 1) % 2 == 0:\n","        print(f'Epoch [{epoch + 1}/{cfg.training_epochs}], Loss: {loss.item():.4f}')\n","\n","        epoch_msg = False\n","      # print(\"evaluating\")\n","    model.eval()\n","    with torch.no_grad():\n","      _, _, output, predicted_class = model(X_test)\n","\n","      # Calculate accuracy\n","      accuracy_temp = accuracy_score(y_test.numpy(), predicted_class.cpu().numpy())\n","    if epoch == 0:\n","      best_accuracy = accuracy_temp\n","      torch.save(model.state_dict(), cfg.PATH)\n","\n","    elif accuracy_temp > best_accuracy:\n","      #memorize best model\n","      torch.save(model.state_dict(), cfg.PATH)\n","      best_accuracy = accuracy_temp\n","      patience_counter = 0\n","\n","    elif patience_counter > cfg.patience:\n","      model.eval()\n","      print(\"patience exceeded, loading best model\")\n","      break\n","    else:\n","      patience_counter += 1\n","\n","  return best_accuracy, model"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qPIxfcO-mG4t","executionInfo":{"status":"ok","timestamp":1717581060860,"user_tz":-480,"elapsed":99940,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"outputId":"f8452385-8a0d-477e-a6b6-2b19712d860f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [2/1000], Loss: 1.5323\n","Epoch [4/1000], Loss: 0.9529\n","Epoch [6/1000], Loss: 1.0962\n","Epoch [8/1000], Loss: 1.1899\n","Epoch [10/1000], Loss: 1.3773\n","Epoch [12/1000], Loss: 0.8618\n","Epoch [14/1000], Loss: 0.4372\n","Epoch [16/1000], Loss: 0.5109\n","Epoch [18/1000], Loss: 1.2373\n","Epoch [20/1000], Loss: 0.7795\n","Epoch [22/1000], Loss: 0.6260\n","Epoch [24/1000], Loss: 0.3205\n","Epoch [26/1000], Loss: 0.3877\n","Epoch [28/1000], Loss: 0.3976\n","Epoch [30/1000], Loss: 0.6361\n","Epoch [32/1000], Loss: 0.6625\n","Epoch [34/1000], Loss: 0.2729\n","Epoch [36/1000], Loss: 0.3540\n","Epoch [38/1000], Loss: 0.2750\n","Epoch [40/1000], Loss: 0.7160\n","Epoch [42/1000], Loss: 0.2548\n","Epoch [44/1000], Loss: 0.2043\n","Epoch [46/1000], Loss: 0.9909\n","patience exceeded, loading best model\n","Epoch [2/1000], Loss: 1.2473\n","Epoch [4/1000], Loss: 1.6472\n","Epoch [6/1000], Loss: 1.2801\n","Epoch [8/1000], Loss: 1.1077\n","Epoch [10/1000], Loss: 1.4793\n","Epoch [12/1000], Loss: 0.3897\n","Epoch [14/1000], Loss: 0.8525\n","Epoch [16/1000], Loss: 0.4011\n","Epoch [18/1000], Loss: 1.3846\n","Epoch [20/1000], Loss: 1.1219\n","Epoch [22/1000], Loss: 0.4249\n","Epoch [24/1000], Loss: 0.6773\n","Epoch [26/1000], Loss: 0.6035\n","Epoch [28/1000], Loss: 1.5842\n","Epoch [30/1000], Loss: 0.4152\n","Epoch [32/1000], Loss: 0.4564\n","Epoch [34/1000], Loss: 0.3209\n","Epoch [36/1000], Loss: 0.3419\n","Epoch [38/1000], Loss: 0.5381\n","Epoch [40/1000], Loss: 0.2179\n","Epoch [42/1000], Loss: 0.3354\n","Epoch [44/1000], Loss: 0.2352\n","Epoch [46/1000], Loss: 0.3483\n","patience exceeded, loading best model\n","Epoch [2/1000], Loss: 2.0662\n","Epoch [4/1000], Loss: 0.6782\n","Epoch [6/1000], Loss: 0.8274\n","Epoch [8/1000], Loss: 1.1913\n","Epoch [10/1000], Loss: 1.3030\n","Epoch [12/1000], Loss: 0.7596\n","Epoch [14/1000], Loss: 0.6475\n","Epoch [16/1000], Loss: 0.8478\n","Epoch [18/1000], Loss: 0.9890\n","Epoch [20/1000], Loss: 0.3830\n","Epoch [22/1000], Loss: 0.8531\n","Epoch [24/1000], Loss: 0.4206\n","Epoch [26/1000], Loss: 0.6746\n","Epoch [28/1000], Loss: 0.4757\n","Epoch [30/1000], Loss: 0.1311\n","Epoch [32/1000], Loss: 0.7213\n","Epoch [34/1000], Loss: 0.8757\n","Epoch [36/1000], Loss: 0.3134\n","Epoch [38/1000], Loss: 0.5833\n","Epoch [40/1000], Loss: 0.3324\n","Epoch [42/1000], Loss: 0.3661\n","Epoch [44/1000], Loss: 0.7465\n","Epoch [46/1000], Loss: 0.5120\n","patience exceeded, loading best model\n","Epoch [2/1000], Loss: 2.2871\n","Epoch [4/1000], Loss: 2.5355\n","Epoch [6/1000], Loss: 1.5157\n","Epoch [8/1000], Loss: 0.6414\n","Epoch [10/1000], Loss: 1.7461\n","Epoch [12/1000], Loss: 1.4076\n","Epoch [14/1000], Loss: 1.8005\n","Epoch [16/1000], Loss: 1.2656\n","Epoch [18/1000], Loss: 2.1968\n","Epoch [20/1000], Loss: 0.5323\n","Epoch [22/1000], Loss: 1.7587\n","Epoch [24/1000], Loss: 0.6659\n","Epoch [26/1000], Loss: 0.6950\n","Epoch [28/1000], Loss: 0.5356\n","Epoch [30/1000], Loss: 0.7937\n","Epoch [32/1000], Loss: 0.8814\n","Epoch [34/1000], Loss: 0.4241\n","Epoch [36/1000], Loss: 0.5930\n","Epoch [38/1000], Loss: 0.4304\n","Epoch [40/1000], Loss: 0.8733\n","Epoch [42/1000], Loss: 0.5581\n","Epoch [44/1000], Loss: 0.3326\n","Epoch [46/1000], Loss: 0.6544\n","Epoch [48/1000], Loss: 0.3910\n","Epoch [50/1000], Loss: 0.5901\n","Epoch [52/1000], Loss: 0.4315\n","patience exceeded, loading best model\n","Epoch [2/1000], Loss: 2.1945\n","Epoch [4/1000], Loss: 2.0824\n","Epoch [6/1000], Loss: 2.3800\n","Epoch [8/1000], Loss: 1.5490\n","Epoch [10/1000], Loss: 1.5243\n","Epoch [12/1000], Loss: 2.2812\n","Epoch [14/1000], Loss: 1.0084\n","Epoch [16/1000], Loss: 1.0707\n","Epoch [18/1000], Loss: 1.9584\n","Epoch [20/1000], Loss: 0.8457\n","Epoch [22/1000], Loss: 0.8289\n","Epoch [24/1000], Loss: 0.8929\n","Epoch [26/1000], Loss: 0.4543\n","Epoch [28/1000], Loss: 0.9002\n","Epoch [30/1000], Loss: 1.4530\n","Epoch [32/1000], Loss: 0.6722\n","Epoch [34/1000], Loss: 0.8424\n","Epoch [36/1000], Loss: 0.2059\n","Epoch [38/1000], Loss: 0.0875\n","Epoch [40/1000], Loss: 0.9207\n","Epoch [42/1000], Loss: 1.1608\n","Epoch [44/1000], Loss: 0.8006\n","Epoch [46/1000], Loss: 0.2535\n","Epoch [48/1000], Loss: 0.7690\n","Epoch [50/1000], Loss: 0.8000\n","Epoch [52/1000], Loss: 0.4482\n","Epoch [54/1000], Loss: 0.4974\n","Epoch [56/1000], Loss: 1.3799\n","patience exceeded, loading best model\n","Epoch [2/1000], Loss: 2.0719\n","Epoch [4/1000], Loss: 0.8350\n","Epoch [6/1000], Loss: 1.0231\n","Epoch [8/1000], Loss: 1.2400\n","Epoch [10/1000], Loss: 1.2271\n","Epoch [12/1000], Loss: 0.5047\n","Epoch [14/1000], Loss: 1.4677\n","Epoch [16/1000], Loss: 0.8787\n","Epoch [18/1000], Loss: 0.2270\n","Epoch [20/1000], Loss: 1.1748\n","Epoch [22/1000], Loss: 0.7169\n","Epoch [24/1000], Loss: 0.3915\n","Epoch [26/1000], Loss: 0.6790\n","Epoch [28/1000], Loss: 0.5284\n","Epoch [30/1000], Loss: 0.3575\n","Epoch [32/1000], Loss: 0.4682\n","Epoch [34/1000], Loss: 0.4687\n","Epoch [36/1000], Loss: 0.1630\n","Epoch [38/1000], Loss: 0.3088\n","Epoch [40/1000], Loss: 0.3395\n","Epoch [42/1000], Loss: 0.2332\n","patience exceeded, loading best model\n","Epoch [2/1000], Loss: 3.1401\n","Epoch [4/1000], Loss: 2.5069\n","Epoch [6/1000], Loss: 0.7575\n","Epoch [8/1000], Loss: 1.1361\n","Epoch [10/1000], Loss: 0.8585\n","Epoch [12/1000], Loss: 2.2880\n","Epoch [14/1000], Loss: 0.3474\n","Epoch [16/1000], Loss: 1.4246\n","Epoch [18/1000], Loss: 0.9645\n","Epoch [20/1000], Loss: 0.7789\n","Epoch [22/1000], Loss: 0.7898\n","Epoch [24/1000], Loss: 1.1199\n","Epoch [26/1000], Loss: 0.7014\n","Epoch [28/1000], Loss: 0.5837\n","Epoch [30/1000], Loss: 1.3991\n","Epoch [32/1000], Loss: 0.9829\n","Epoch [34/1000], Loss: 0.8503\n","Epoch [36/1000], Loss: 0.6713\n","Epoch [38/1000], Loss: 0.4368\n","Epoch [40/1000], Loss: 0.6003\n","Epoch [42/1000], Loss: 0.4502\n","Epoch [44/1000], Loss: 1.1081\n","Epoch [46/1000], Loss: 0.6699\n","patience exceeded, loading best model\n","Epoch [2/1000], Loss: 1.7170\n","Epoch [4/1000], Loss: 1.3706\n","Epoch [6/1000], Loss: 1.7061\n","Epoch [8/1000], Loss: 1.3575\n","Epoch [10/1000], Loss: 0.3383\n","Epoch [12/1000], Loss: 1.4078\n","Epoch [14/1000], Loss: 0.8471\n","Epoch [16/1000], Loss: 1.1858\n","Epoch [18/1000], Loss: 1.0587\n","Epoch [20/1000], Loss: 0.2369\n","Epoch [22/1000], Loss: 0.2613\n","Epoch [24/1000], Loss: 0.8894\n","Epoch [26/1000], Loss: 0.5553\n","Epoch [28/1000], Loss: 0.5259\n","Epoch [30/1000], Loss: 0.1778\n","Epoch [32/1000], Loss: 0.2403\n","Epoch [34/1000], Loss: 0.1566\n","Epoch [36/1000], Loss: 0.2592\n","Epoch [38/1000], Loss: 0.3747\n","Epoch [40/1000], Loss: 0.1722\n","Epoch [42/1000], Loss: 0.2643\n","Epoch [44/1000], Loss: 0.3679\n","Epoch [46/1000], Loss: 0.4228\n","Epoch [48/1000], Loss: 0.6296\n","Epoch [50/1000], Loss: 0.3804\n","Epoch [52/1000], Loss: 0.1771\n","Epoch [54/1000], Loss: 0.1028\n","Epoch [56/1000], Loss: 0.1490\n","Epoch [58/1000], Loss: 0.2630\n","patience exceeded, loading best model\n","Epoch [2/1000], Loss: 3.8395\n","Epoch [4/1000], Loss: 1.5726\n","Epoch [6/1000], Loss: 0.6749\n","Epoch [8/1000], Loss: 0.4421\n","Epoch [10/1000], Loss: 0.7640\n","Epoch [12/1000], Loss: 1.0208\n","Epoch [14/1000], Loss: 0.2369\n","Epoch [16/1000], Loss: 0.6692\n","Epoch [18/1000], Loss: 0.1956\n","Epoch [20/1000], Loss: 0.8407\n","Epoch [22/1000], Loss: 0.7676\n","Epoch [24/1000], Loss: 0.2154\n","Epoch [26/1000], Loss: 0.7009\n","Epoch [28/1000], Loss: 0.3371\n","Epoch [30/1000], Loss: 0.7609\n","Epoch [32/1000], Loss: 0.4904\n","Epoch [34/1000], Loss: 0.2841\n","Epoch [36/1000], Loss: 0.4860\n","Epoch [38/1000], Loss: 0.8205\n","Epoch [40/1000], Loss: 0.6754\n","Epoch [42/1000], Loss: 1.0638\n","patience exceeded, loading best model\n","Epoch [2/1000], Loss: 1.4725\n","Epoch [4/1000], Loss: 1.8466\n","Epoch [6/1000], Loss: 1.4050\n","Epoch [8/1000], Loss: 1.1851\n","Epoch [10/1000], Loss: 1.6235\n","Epoch [12/1000], Loss: 0.5751\n","Epoch [14/1000], Loss: 0.3850\n","Epoch [16/1000], Loss: 0.7634\n","Epoch [18/1000], Loss: 0.8026\n","Epoch [20/1000], Loss: 0.3452\n","Epoch [22/1000], Loss: 1.2395\n","Epoch [24/1000], Loss: 0.7873\n","Epoch [26/1000], Loss: 0.5279\n","Epoch [28/1000], Loss: 0.5304\n","Epoch [30/1000], Loss: 0.3618\n","Epoch [32/1000], Loss: 0.5539\n","Epoch [34/1000], Loss: 0.5606\n","Epoch [36/1000], Loss: 1.0019\n","Epoch [38/1000], Loss: 0.5974\n","Epoch [40/1000], Loss: 0.3034\n","Epoch [42/1000], Loss: 0.3008\n","patience exceeded, loading best model\n","Average accuracy:0.538\n","KNN accuracy:0.387\n","LMNN/NCA accuracy:0.436\n"]}],"source":["accuracies = []\n","knn_accuracies = []\n","lmnn_accuracies = []\n","PATH = os.path.join(folder_name, f'checkpoints/classifier_{dataset_name}.h5')\n","cfg.PATH = PATH\n","k_fold = KFold(n_splits=10, shuffle=True, random_state = None)\n","\n","for train_index, test_index in k_fold.split(Xs):\n","  # Get training and testing data\n","  X_train, X_test = Xs[train_index], Xs[test_index]\n","  y_train, y_test = ys[train_index], ys[test_index]\n","\n","  # https://contrib.scikit-learn.org/metric-learn/supervised.html#lmnn\n","  lmnn = LMNN(n_neighbors=5, learn_rate=1e-6)\n","  ##TODO, change here if you need to use a different one\n","  # lmnn = metric_learn.MLKR()\n","  # lmnn = metric_learn.NCA(max_iter=1000)\n","  lmnn.fit(X_train,y_train)\n","  knn = KNeighborsClassifier(n_neighbors=5,metric=lmnn.get_metric())\n","  knn.fit(X_train,y_train)\n","  # klmnn_accuracies.append( accuracy_score(knn.predict(X_test), y_test))\n","  lmnn_acc = accuracy_score(knn.predict(X_test), y_test)\n","  lmnn_accuracies.append(lmnn_acc)\n","\n","  knn =  KNeighborsClassifier(n_neighbors=cfg.top_k)\n","  knn.fit(X_train, y_train)\n","  knn_acc  = accuracy_score(knn.predict(X_test), y_test)\n","  knn_accuracies.append(knn_acc)\n","\n","  best_accuracy, model = train_cls(X_train,y_train, X_test, y_test, cfg)\n","  accuracies.append(best_accuracy)\n","\n","print(f\"Average accuracy:{np.mean(accuracies):.3f}\")\n","print(f\"KNN accuracy:{np.mean(knn_accuracies):.3f}\")\n","print(f\"LMNN/NCA accuracy:{np.mean(lmnn_accuracies):.3f}\")\n"]},{"cell_type":"markdown","metadata":{"id":"QVO3SDp9mG4u"},"source":["# Regression with NNKNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ll4n1HNmG4u"},"outputs":[],"source":["def train_reg(X_train,y_train, X_test, y_test, cfg:DictConfig):\n","  X_train = X_train.to(device)\n","  y_train = y_train.to(device)\n","  X_test = X_test.to(device)\n","\n","  train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train, y_train), batch_size=cfg.batch_size, shuffle=True)\n","  test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_test, y_test), batch_size=cfg.batch_size, shuffle=False)\n","\n","\n","    # Train model\n","  model = Rmodel.NN_k_NN_regression(X_train,\n","                                    y_train,\n","                                    cfg.ca_weight_sharing,\n","                                    cfg.top_case_enabled,\n","                                    cfg.top_k,\n","                                    cfg.discount,\n","                                    cfg.class_weight_sharing,\n","                                    device=device)\n","\n","  optimizer = torch.optim.Adam(model.parameters(), lr=cfg.learning_rate) #, weight_decay=1e-5)\n","\n","  patience_counter = 0\n","  for epoch in range(cfg.training_epochs):\n","    # break # no training\n","    epoch_msg = True\n","    for X_train_batch, y_train_batch in train_loader:\n","      model.train()\n","      _, _, _, predicted_number = model(X_train_batch)\n","      # break\n","      loss = criterion(predicted_number.squeeze(), y_train_batch)\n","      # Backward and optimize\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","      if epoch_msg and (epoch + 1) % 2 == 0:\n","        epoch_msg = False\n","        print(f'Epoch [{epoch + 1}/{cfg.training_epochs}], Loss: {loss.item():.4f}')\n","\n","    model.eval()\n","    with torch.no_grad():\n","      predicted_numbers = []\n","      for X_test_batch, _ in test_loader:\n","        X_test_batch = X_test_batch.to(device)\n","        _, _, _, predicted_number = model(X_test_batch)\n","        predicted_numbers.extend(predicted_number.squeeze().cpu().detach())\n","\n","      predicted_numbers = torch.Tensor(predicted_numbers)\n","      accuracy_temp = criterion(y_test, predicted_numbers)\n","\n","    if epoch == 0:\n","      best_accuracy = accuracy_temp\n","      torch.save(model.state_dict(), cfg.PATH)\n","    elif accuracy_temp < best_accuracy:\n","      torch.save(model.state_dict(), cfg.PATH)\n","      best_accuracy = accuracy_temp\n","      patience_counter = 0\n","    elif patience_counter > cfg.patience:\n","      model.eval()\n","      print(\"patience exceeded, loading best model\")\n","      break\n","    else:\n","      patience_counter += 1\n","\n","  _, case_activations, _, predicted_number = model(X_test)\n","\n","  top_case_indices = torch.topk(case_activations, 5, dim=1)[1].cpu()\n","\n","  accuracy = criterion(y_test, predicted_number.squeeze().cpu())\n","  y_train = y_train.cpu()\n","  top_k_average_accuracy = mean_squared_error(torch.mean(y_train[top_case_indices], dim=1), y_test)\n","\n","  return best_accuracy, accuracy, top_k_average_accuracy, model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DN8UlUVpmG4v"},"outputs":[],"source":["best_accuracies = []\n","accuracies = []\n","top_k_average_accuracies = []\n","knn_accuracies = []\n","PATH = os.path.join(folder_name, f'checkpoints/regression_{dataset_name}.h5')\n","cfg.PATH = PATH\n","k_fold = KFold(n_splits=10, shuffle = True,random_state = None)\n","\n","\n","for train_index, test_index in k_fold.split(Xs):\n","  # Get training and testing data\n","  X_train, X_test = Xs[train_index], Xs[test_index]\n","  y_train, y_test = ys[train_index], ys[test_index]\n","\n","  knn = KNeighborsRegressor(n_neighbors=cfg.top_k)\n","  knn.fit(X_train, y_train)\n","  knn_accuracies.append(mean_squared_error(knn.predict(X_test), y_test))\n","\n","  best_accuracy, accuracy, top_k_average_accuracy, model= train_reg(X_train, y_train, X_test, y_test, cfg)\n","  best_accuracies.append(best_accuracy)\n","  accuracies.append(accuracy)\n","  top_k_average_accuracies.append(top_k_average_accuracy)\n","\n","print(\"Average accuracy:\", np.mean([acc.detach().numpy() for acc in accuracies]))\n","print(\"Average top_k_average_accuracies\", np.mean(top_k_average_accuracies))\n","print(\"KNN accuracy:\", np.mean(knn_accuracies))"]},{"cell_type":"markdown","source":["# Results Interpretation"],"metadata":{"id":"aQMTPXLwaBVq"}},{"cell_type":"code","source":["def print_model_features(input_model):\n","  for n, p in model.named_parameters():\n","    print(n)\n","    print(p.data)"],"metadata":{"id":"sf23mP1UaIvx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print_model_features(model)"],"metadata":{"id":"MRO3tUPEbJUs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for regression only. for classification is different\n","#feature_activations, case_activations, predicted_number\n","model.eval()\n","feature_activations, case_activations, output, predicted_class = model(X_test)"],"metadata":{"id":"PkxAqSoldjML"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#inspecting the case activations\n","top_case_indices = torch.topk(case_activations, 5, dim=1)[1]"],"metadata":{"id":"hjaUAY7Bkjyr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test[0]"],"metadata":{"id":"tfi-PKhokmev"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train[top_case_indices[0][0]]"],"metadata":{"id":"73NQbeJ_kpO_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["By comparing the following two blocks' outputs, you can see we are retrieving a good neighbor."],"metadata":{"id":"xMePSTR1lXbb"}},{"cell_type":"code","source":["#sum abs of X_test[0] and the top activated case\n","sum(abs(X_test[0] - X_train[top_case_indices[0][0]]))"],"metadata":{"id":"0izuKF6okrsc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: average sum abs of X_test[0] and X_train data\n","print(np.mean([sum(abs(X_test[0] - X_train[i])) for i in range(len(X_train))]))"],"metadata":{"id":"faYClHOVktuW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["TODO:: A better way is to show the distribution of ``X_test[0] - X_train[i]``"],"metadata":{"id":"zkYKvaP-lz_0"}},{"cell_type":"code","source":["y_train[top_case_indices[0]]"],"metadata":{"id":"xrwLY3gXmCLd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["knn.predict(X_test)[0]"],"metadata":{"id":"es5Kv85CmHMt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["indices = knn.kneighbors(X_test)[1][0]"],"metadata":{"id":"pxOcKMzHmJkS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train[indices]"],"metadata":{"id":"o4vuKW0rmNVi"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[],"toc_visible":true}},"nbformat":4,"nbformat_minor":0}