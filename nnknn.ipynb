{"cells":[{"cell_type":"markdown","metadata":{"id":"rxoHWNZEmG4g"},"source":["# Setup"]},{"cell_type":"markdown","metadata":{"id":"CsfLxAVaPOTf"},"source":["On google colab, you have to restart runtime after running the following line"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4504,"status":"ok","timestamp":1718344697623,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":-480},"id":"T3Y5CLhymG4l","outputId":"54eccab8-5e16-4b19-c1a2-12ea631fc517"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (2.3.0)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf) (4.9.3)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf) (6.0.1)\n"]}],"source":["!pip install omegaconf"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2219,"status":"ok","timestamp":1718344699839,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":-480},"id":"BxzI25zfmG4n","outputId":"136fe8ea-cf23-4729-9ca3-ea3ad60e75fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive/\")\n","#\"/content/drive/My Drive/NN-kNN/\"\n","folder_name = \"/content/drive/Othercomputers/My MacBook Pro/GitHub/NN-kNN/\"\n","import sys\n","sys.path.insert(0,folder_name)"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1718344699839,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":-480},"id":"q-0ffsjpbDLE"},"outputs":[],"source":["##This is added because my Rdata uses Cdata for the covid data set.\n","##Rdata use Cdata function to load the data set, then convert it to regression problem\n","import os\n","import sys\n","sys.path.append('/content/drive/Othercomputers/My MacBook Pro/GitHub/NN-kNN/dataset')\n"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1718344699839,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":-480},"id":"joYfU4jLmG4o"},"outputs":[],"source":["# folder_name = os.getcwd()"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1718344699839,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":-480},"id":"oDGrACwVmG4o"},"outputs":[],"source":["import torch\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import accuracy_score\n","from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n","from sklearn.metrics import mean_squared_error\n","from tqdm import tqdm\n","from omegaconf import DictConfig, OmegaConf\n","\n","from dataset import cls_small_data as Cdata\n","import model.cls_model as Cmodel\n","from dataset import cls_medium_data\n","\n","from dataset import reg_data as Rdata\n","import model.reg_model as Rmodel"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":435,"status":"ok","timestamp":1718344700272,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":-480},"id":"bzTxZZJnmG4p"},"outputs":[],"source":["conf_file = OmegaConf.load(os.path.join(folder_name, 'config.yaml'))"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1718344700273,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":-480},"id":"yT3W4iqSmG4p"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"oaKz8Ns3mG4q"},"source":["# NCA and LMNN setup"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3937,"status":"ok","timestamp":1718344704207,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":-480},"id":"cWQ8I6icoU8X","outputId":"d782f37e-bc8e-4c5f-f8fb-176be9d15bb5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: metric-learn in /usr/local/lib/python3.10/dist-packages (0.7.0)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from metric-learn) (1.25.2)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from metric-learn) (1.11.4)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from metric-learn) (1.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->metric-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->metric-learn) (3.5.0)\n"]}],"source":["pip install metric-learn"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1718344704207,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":-480},"id":"zmjbXrjQmG4q"},"outputs":[],"source":["import metric_learn\n","from metric_learn import LMNN,NCA"]},{"cell_type":"markdown","metadata":{"id":"46TjfSz-mG4q"},"source":["# Data Sets"]},{"cell_type":"markdown","metadata":{"id":"ZkDrsvjWmG4r"},"source":["Supported small dataset for classification:  \n","'zebra',\n","'zebra_special',\n","'bal',\n","'digits',\n","'iris',\n","'wine',\n","'breast_cancer',\n","\n","for regression:\n","'califonia_housing',\n","'abalone',\n","'diabets',\n","'body_fat',\n","'ziweifaces'\n","\n","\n","Newly added data sets for mental health (psychology):\n","\n","Classification:\n","'psych_depression_physical_symptons',\n","'covid_anxious',\n","'covid_depressed'\n"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12510,"status":"ok","timestamp":1718344722968,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":-480},"id":"lxq-FY3FmG4r","outputId":"115a1280-4047-4fce-e7cb-9843eb2d960a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Columns in the dataset: Index(['SU_ID', 'P_PANEL', 'NATIONAL_WEIGHT', 'REGION_WEIGHT',\n","       'NATIONAL_WEIGHT_POP', 'REGION_WEIGHT_POP', 'NAT_WGT_COMB_POP',\n","       'REG_WGT_COMB_POP', 'P_GEO', 'SOC1',\n","       ...\n","       'REGION9', 'P_DENSE', 'MODE', 'LANGUAGE', 'MAIL50', 'RACE1_BANNER',\n","       'RACE2_BANNER', 'INC_BANNER', 'AGE_BANNER', 'HH_BANNER'],\n","      dtype='object', length=177)\n"]}],"source":["dataset_name = 'covid_depressed'\n","cfg = conf_file['dataset'][dataset_name]\n","#TODO need to add other covid data sets here.\n","if dataset_name in ['covid_depressed','covid_anxious','psych_depression_physical_symptons',\n","                    'zebra','zebra_special','bal','digits','iris','wine','breast_cancer']:\n","    criterion = torch.nn.CrossEntropyLoss()\n","    Xs, ys = Cdata.Cls_small_data(dataset_name)\n","elif dataset_name in []:\n","    criterion = torch.nn.CrossEntropyLoss()\n","    Xs, ys = cls_medium_data.Cls_medium_data(dataset_name)\n","else:\n","    criterion = torch.nn.MSELoss()\n","    Xs, ys = Rdata.Reg_data(dataset_name)"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1718344722968,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":-480},"id":"aOIbeEfEmG4s","outputId":"39b8a816-49f3-42b8-d805-9ee74344e454"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<module 'dataset.cls_small_data' from '/content/drive/Othercomputers/My MacBook Pro/GitHub/NN-kNN/dataset/cls_small_data.py'>"]},"metadata":{},"execution_count":36}],"source":["# This section is used to reload the imported module.\n","# For example, if you made any changes in the model.cls_model, you should run importlib.reload(Cmodel) as long as you set import model.cls_model as Cmodel.\n","import importlib\n","importlib.reload(Cdata)"]},{"cell_type":"markdown","metadata":{"id":"EOEnGkKnmG4s"},"source":["# Classification with NNKNN"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":364,"status":"ok","timestamp":1718344729605,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":-480},"id":"fisqdp27w9fg","outputId":"181f3596-cb09-453d-86f0-ff893a517b7f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Unique values: [0 1 2 3]\n","Counts: [1703 1703 1703 1703]\n","Xs.size(): torch.Size([6812, 161])\n"]}],"source":["# prompt: get the unique y values and their counts\n","\n","unique_values, counts = np.unique(ys, return_counts=True)\n","print(f\"Unique values: {unique_values}\")\n","print(f\"Counts: {counts}\")\n","print(f\"Xs.size(): {Xs.size()}\")\n"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"xOraZstjmG4t","executionInfo":{"status":"ok","timestamp":1718344730049,"user_tz":-480,"elapsed":3,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["def train_cls(X_train,y_train, X_test, y_test, cfg:DictConfig):\n","  X_train = X_train.to(device)\n","  y_train = y_train.to(device)\n","  X_test = X_test.to(device)\n","\n","  train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train, y_train), batch_size=cfg.batch_size, shuffle=True)\n","\n","  # Train model\n","  model = Cmodel.NN_k_NN(X_train,\n","                         y_train,\n","                         cfg.ca_weight_sharing,\n","                         cfg.top_case_enabled,\n","                         cfg.top_k,\n","                         cfg.discount,\n","                         device=device)\n","\n","  optimizer = torch.optim.Adam(model.parameters(), lr=cfg.learning_rate) #, weight_decay=1e-5)\n","\n","  patience_counter = 0\n","  for epoch in range(cfg.training_epochs):\n","    epoch_msg = True\n","\n","    for X_train_batch, y_train_batch in train_loader:\n","      model.train()\n","      _, _, output, predicted_class = model(X_train_batch)\n","      loss = criterion(output, y_train_batch)\n","\n","      # Backward and optimize\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","      if epoch_msg and (epoch + 1) % 2 == 0:\n","        print(f'Epoch [{epoch + 1}/{cfg.training_epochs}], Loss: {loss.item():.4f}')\n","\n","        epoch_msg = False\n","      # print(\"evaluating\")\n","    model.eval()\n","    with torch.no_grad():\n","      _, _, output, predicted_class = model(X_test)\n","\n","      # Calculate accuracy\n","      accuracy_temp = accuracy_score(y_test.numpy(), predicted_class.cpu().numpy())\n","    if epoch == 0:\n","      best_accuracy = accuracy_temp\n","      torch.save(model.state_dict(), cfg.PATH)\n","\n","    elif accuracy_temp > best_accuracy:\n","      #memorize best model\n","      torch.save(model.state_dict(), cfg.PATH)\n","      best_accuracy = accuracy_temp\n","      patience_counter = 0\n","\n","    elif patience_counter > cfg.patience:\n","      model.eval()\n","      print(\"patience exceeded, loading best model\")\n","      break\n","    else:\n","      patience_counter += 1\n","\n","  return best_accuracy, model"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"DMKsNhL3ItkK","executionInfo":{"status":"ok","timestamp":1718344730050,"user_tz":-480,"elapsed":3,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["def load_model_cls(X_train,y_train,cfg):\n","  # Define the model architecture\n","  model = Cmodel.NN_k_NN(\n","      X_train,\n","      y_train,\n","      cfg.ca_weight_sharing,\n","      cfg.top_case_enabled,\n","      cfg.top_k,\n","      cfg.discount,\n","      device=device\n","  )\n","  # Load the state dictionary\n","  model.load_state_dict(torch.load(cfg.path))\n","  model.to(device)\n","  model.eval()\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qPIxfcO-mG4t"},"outputs":[],"source":["accuracies = []\n","knn_accuracies = []\n","lmnn_accuracies = []\n","PATH = os.path.join(folder_name, f'checkpoints/classifier_{dataset_name}.h5')\n","cfg.PATH = PATH\n","k_fold = KFold(n_splits=10, shuffle=True, random_state = None)\n","enable_lmnn = False\n","\n","for train_index, test_index in k_fold.split(Xs):\n","  # Get training and testing data\n","  X_train, X_test = Xs[train_index], Xs[test_index]\n","  y_train, y_test = ys[train_index], ys[test_index]\n","  if(enable_lmnn):\n","    # https://contrib.scikit-learn.org/metric-learn/supervised.html#lmnn\n","    lmnn = LMNN(n_neighbors=5, learn_rate=1e-6)\n","    ##TODO, change here if you need to use a different one\n","    # lmnn = metric_learn.MLKR()\n","    # lmnn = metric_learn.NCA(max_iter=1000)\n","    lmnn.fit(X_train,y_train)\n","    knn = KNeighborsClassifier(n_neighbors=5,metric=lmnn.get_metric())\n","    knn.fit(X_train,y_train)\n","    # klmnn_accuracies.append( accuracy_score(knn.predict(X_test), y_test))\n","    lmnn_acc = accuracy_score(knn.predict(X_test), y_test)\n","    lmnn_accuracies.append(lmnn_acc)\n","\n","  knn =  KNeighborsClassifier(n_neighbors=cfg.top_k)\n","  knn.fit(X_train, y_train)\n","  knn_acc  = accuracy_score(knn.predict(X_test), y_test)\n","  knn_accuracies.append(knn_acc)\n","\n","  best_accuracy, model = train_cls(X_train,y_train, X_test, y_test, cfg)\n","  accuracies.append(best_accuracy)\n","  break\n","\n","print(f\"Average accuracy:{np.mean(accuracies):.3f}\")\n","print(f\"KNN accuracy:{np.mean(knn_accuracies):.3f}\")\n","print(f\"LMNN/NCA accuracy:{np.mean(lmnn_accuracies):.3f}\")\n"]},{"cell_type":"markdown","metadata":{"id":"QVO3SDp9mG4u"},"source":["# Regression with NNKNN"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1718333774147,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":-480},"id":"x2uuoXv9ceJL","outputId":"9ce57a25-c8ab-44d9-ccef-56bbe5eca8b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Unique values: [-1.3415393  -0.44717973  0.44717973  1.3415393 ]\n","Counts: [1651 1651 1651 1651]\n","Xs.size(): torch.Size([6604, 161])\n"]}],"source":["unique_values, counts = np.unique(ys, return_counts=True)\n","print(f\"Unique values: {unique_values}\")\n","print(f\"Counts: {counts}\")\n","print(f\"Xs.size(): {Xs.size()}\")"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1718333774147,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":-480},"id":"7ll4n1HNmG4u"},"outputs":[],"source":["def train_reg(X_train,y_train, X_test, y_test, cfg:DictConfig):\n","  X_train = X_train.to(device)\n","  y_train = y_train.to(device)\n","  X_test = X_test.to(device)\n","\n","  train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train, y_train), batch_size=cfg.batch_size, shuffle=True)\n","  test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_test, y_test), batch_size=cfg.batch_size, shuffle=False)\n","\n","\n","    # Train model\n","  model = Rmodel.NN_k_NN_regression(X_train,\n","                                    y_train,\n","                                    cfg.ca_weight_sharing,\n","                                    cfg.top_case_enabled,\n","                                    cfg.top_k,\n","                                    cfg.discount,\n","                                    cfg.class_weight_sharing,\n","                                    device=device)\n","\n","  optimizer = torch.optim.Adam(model.parameters(), lr=cfg.learning_rate) #, weight_decay=1e-5)\n","\n","  patience_counter = 0\n","  for epoch in range(cfg.training_epochs):\n","    # break # no training\n","    epoch_msg = True\n","    for X_train_batch, y_train_batch in train_loader:\n","      model.train()\n","      _, _, _, predicted_number = model(X_train_batch)\n","      # break\n","      loss = criterion(predicted_number.squeeze(), y_train_batch)\n","      # Backward and optimize\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","      if epoch_msg and (epoch + 1) % 2 == 0:\n","        epoch_msg = False\n","        print(f'Epoch [{epoch + 1}/{cfg.training_epochs}], Loss: {loss.item():.4f}')\n","\n","    model.eval()\n","    with torch.no_grad():\n","      predicted_numbers = []\n","      for X_test_batch, _ in test_loader:\n","        X_test_batch = X_test_batch.to(device)\n","        _, _, _, predicted_number = model(X_test_batch)\n","        predicted_numbers.extend(predicted_number.squeeze().cpu().detach())\n","\n","      predicted_numbers = torch.Tensor(predicted_numbers)\n","      accuracy_temp = criterion(y_test, predicted_numbers)\n","\n","    if epoch == 0:\n","      best_accuracy = accuracy_temp\n","      torch.save(model.state_dict(), cfg.PATH)\n","    elif accuracy_temp < best_accuracy:\n","      torch.save(model.state_dict(), cfg.PATH)\n","      best_accuracy = accuracy_temp\n","      patience_counter = 0\n","    elif patience_counter > cfg.patience:\n","      model.eval()\n","      print(\"patience exceeded, loading best model\")\n","      break\n","    else:\n","      patience_counter += 1\n","\n","  _, case_activations, _, predicted_number = model(X_test)\n","\n","  top_case_indices = torch.topk(case_activations, 5, dim=1)[1].cpu()\n","\n","  accuracy = criterion(y_test, predicted_number.squeeze().cpu())\n","  y_train = y_train.cpu()\n","  top_k_average_accuracy = mean_squared_error(torch.mean(y_train[top_case_indices], dim=1), y_test)\n","\n","  return best_accuracy, accuracy, top_k_average_accuracy, model"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1718333774147,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":-480},"id":"9yCDMIuMRN38"},"outputs":[],"source":["# prompt: load_model_reg()\n","\n","def load_model_reg(X_train,y_train,cfg):\n","  # Define the model architecture\n","  model = Rmodel.NN_k_NN_regression(\n","      X_train,\n","      y_train,\n","      cfg.ca_weight_sharing,\n","      cfg.top_case_enabled,\n","      cfg.top_k,\n","      cfg.discount,\n","      cfg.class_weight_sharing,\n","      device=device\n","  )\n","  # Load the state dictionary\n","  model.load_state_dict(torch.load(cfg.path))\n","  model.to(device)\n","  model.eval()\n","  return model\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DN8UlUVpmG4v","executionInfo":{"status":"ok","timestamp":1718336229701,"user_tz":-480,"elapsed":2455557,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"outputId":"bd338dc9-a4bc-4c6b-d952-7239d8949bc3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [2/1000], Loss: 0.9530\n","Epoch [4/1000], Loss: 1.2346\n","Epoch [6/1000], Loss: 1.0282\n","Epoch [8/1000], Loss: 1.2116\n","Epoch [10/1000], Loss: 0.7650\n","Epoch [12/1000], Loss: 0.6646\n","Epoch [14/1000], Loss: 1.1751\n","Epoch [16/1000], Loss: 1.0585\n","Epoch [18/1000], Loss: 0.6065\n","Epoch [20/1000], Loss: 1.2232\n","Epoch [22/1000], Loss: 1.0657\n","Epoch [24/1000], Loss: 0.5398\n","Epoch [26/1000], Loss: 0.4660\n","Epoch [28/1000], Loss: 1.0912\n","Epoch [30/1000], Loss: 0.7082\n","Epoch [32/1000], Loss: 0.8464\n","Epoch [34/1000], Loss: 0.4497\n","Epoch [36/1000], Loss: 0.8295\n","Epoch [38/1000], Loss: 0.7380\n","Epoch [40/1000], Loss: 0.6853\n","Epoch [42/1000], Loss: 0.6481\n","Epoch [44/1000], Loss: 0.6393\n","Epoch [46/1000], Loss: 0.6188\n","Epoch [48/1000], Loss: 0.8710\n","Epoch [50/1000], Loss: 0.9190\n","Epoch [52/1000], Loss: 1.0682\n","Epoch [54/1000], Loss: 0.7960\n","Epoch [56/1000], Loss: 0.4212\n","patience exceeded, loading best model\n","Average accuracy: 1.1028702\n","Average top_k_average_accuracies 1.1869186\n","KNN accuracy: 1.1681862\n"]}],"source":["best_accuracies = []\n","accuracies = []\n","top_k_average_accuracies = []\n","knn_accuracies = []\n","PATH = os.path.join(folder_name, f'checkpoints/regression_{dataset_name}.h5')\n","cfg.PATH = PATH\n","k_fold = KFold(n_splits=10, shuffle = True,random_state = None)\n","\n","\n","for train_index, test_index in k_fold.split(Xs):\n","  # Get training and testing data\n","  X_train, X_test = Xs[train_index], Xs[test_index]\n","  y_train, y_test = ys[train_index], ys[test_index]\n","\n","  knn = KNeighborsRegressor(n_neighbors=cfg.top_k)\n","  knn.fit(X_train, y_train)\n","  knn_accuracies.append(mean_squared_error(knn.predict(X_test), y_test))\n","\n","  best_accuracy, accuracy, top_k_average_accuracy, model= train_reg(X_train, y_train, X_test, y_test, cfg)\n","  best_accuracies.append(best_accuracy)\n","  accuracies.append(accuracy)\n","  top_k_average_accuracies.append(top_k_average_accuracy)\n","  break\n","print(\"Average accuracy:\", np.mean([acc.detach().numpy() for acc in accuracies]))\n","print(\"Average top_k_average_accuracies\", np.mean(top_k_average_accuracies))\n","print(\"KNN accuracy:\", np.mean(knn_accuracies))"]},{"cell_type":"markdown","metadata":{"id":"aQMTPXLwaBVq"},"source":["# Results Interpretation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sf23mP1UaIvx"},"outputs":[],"source":["def print_model_features(input_model):\n","  for n, p in model.named_parameters():\n","    print(n)\n","    print(p.data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MRO3tUPEbJUs"},"outputs":[],"source":["print_model_features(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PkxAqSoldjML"},"outputs":[],"source":["# for regression only. for classification is different\n","#feature_activations, case_activations, predicted_number\n","model.eval()\n","feature_activations, case_activations, output, predicted_class = model(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PtwGRyMjeXtp"},"outputs":[],"source":["predicted_class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EvY5_WGkeaxg"},"outputs":[],"source":["y_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Eb7wyntlXft_"},"outputs":[],"source":["# prompt: accuracy comparing predicted_class and y_test\n","\n","accuracy = accuracy_score(y_test.numpy(), predicted_class.cpu().numpy())\n","print(\"Accuracy:\", accuracy)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hjaUAY7Bkjyr"},"outputs":[],"source":["#inspecting the case activations\n","top_case_indices = torch.topk(case_activations, 5, dim=1)[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tfi-PKhokmev"},"outputs":[],"source":["X_test[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oMxrFCywYIaQ"},"outputs":[],"source":["y_test[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"73NQbeJ_kpO_"},"outputs":[],"source":["X_train[top_case_indices[0][0]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q9_6zvszYKPw"},"outputs":[],"source":["y_train[top_case_indices[0][0]]"]},{"cell_type":"markdown","metadata":{"id":"xMePSTR1lXbb"},"source":["By comparing the following two blocks' outputs, you can see we are retrieving a good neighbor."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0izuKF6okrsc"},"outputs":[],"source":["#sum abs of X_test[0] and the top activated case\n","sum(abs(X_test[0] - X_train[top_case_indices[0][0]]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"faYClHOVktuW"},"outputs":[],"source":["# prompt: average sum abs of X_test[0] and X_train data\n","print(np.mean([sum(abs(X_test[0] - X_train[i])) for i in range(len(X_train))]))"]},{"cell_type":"markdown","metadata":{"id":"zkYKvaP-lz_0"},"source":["TODO:: A better way is to show the distribution of ``X_test[0] - X_train[i]``"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xrwLY3gXmCLd"},"outputs":[],"source":["y_train[top_case_indices[0]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"es5Kv85CmHMt"},"outputs":[],"source":["knn.predict(X_test)[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pxOcKMzHmJkS"},"outputs":[],"source":["indices = knn.kneighbors(X_test)[1][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o4vuKW0rmNVi"},"outputs":[],"source":["y_train[indices]"]},{"cell_type":"markdown","source":["# Sanity Check\n"],"metadata":{"id":"uZsxNJZDQ8RQ"}},{"cell_type":"markdown","source":["## Classification Neural Network"],"metadata":{"id":"ZhHAd1y-Q_C2"}},{"cell_type":"code","source":["# Hyperparameters\n","input_size = X_train.shape[1]\n","hidden_size = 1024\n","num_classes = torch.unique(ys).shape[0]\n","learning_rate = 1e-5\n","batch_size = 16\n","epochs = 2000"],"metadata":{"id":"pXu1CDqXRR_O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the neural network architecture for classification\n","class NeuralNet(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(NeuralNet, self).__init__()\n","        self.nn = nn.Sequential(\n","            nn.Linear(input_size, hidden_size ),\n","            nn.LeakyReLU(),\n","            nn.Linear(hidden_size , hidden_size // 2),\n","            # nn.Dropout(0.5),\n","            nn.LeakyReLU(),\n","            nn.Linear(hidden_size // 2, hidden_size // 4),\n","            # nn.Dropout(0.5),\n","            nn.LeakyReLU(),\n","            nn.Linear(hidden_size // 4, num_classes)\n","            )\n","        self.init_weights()\n","\n","    def init_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Linear):\n","                torch.nn.init.xavier_uniform_(m.weight)\n","                if m.bias is not None:\n","                    m.bias.data.fill_(0)\n","\n","    def forward(self, x):\n","        return self.nn(x)\n"],"metadata":{"id":"CBu0Gj9vRKYf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n","patience_counter = 0\n","best_model = None\n","best_accuracy = None\n","# Initialize the model, loss function, and optimizer\n","model = NeuralNet(input_size, hidden_size, num_classes)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Training loop\n","for epoch in range(epochs):\n","  epoch_msg = True\n","  training_total_acc = 0.0\n","  training_total_loss = 0.0\n","  num_of_batches = len(train_loader)\n","  for X_train_batch, y_train_batch in train_loader:\n","    model.train()\n","    # Forward pass\n","    outputs = model(X_train_batch)\n","    loss = criterion(outputs, y_train_batch)\n","\n","    # Backward and optimize\n","    _, predicted = torch.max(outputs, 1)\n","    training_total_acc += torch.sum(predicted == y_train_batch).item()\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    training_total_loss += loss.item()\n","    # if (i + 1) % 5 == 0\n","  if epoch == 0 or (epoch + 1) % 100 == 0:\n","    print(f\"Epoch: {epoch + 1}, Training Loss: {training_total_loss/num_of_batches:.2f} Acc: {training_total_acc/num_of_batches:.2f}\")\n","  # Testing the model\n","  model.eval()\n","  with torch.no_grad():\n","    outputs = model(X_test)\n","    loss = criterion(outputs, y_test)\n","    _, predicted = torch.max(outputs, 1)\n","    accuracy = torch.sum(predicted == y_test).item() / len(y_test)\n","    print(f'Accuracy on the test set: {accuracy * 100:.2f}%')\n","    if best_accuracy is None or accuracy > best_accuracy:\n","      best_accuracy = accuracy\n","      best_model = model\n","      patience_counter = 0\n","    else:\n","      patience_counter += 1\n","    if epoch_msg and (epoch + 1) % 100 == 0:\n","      epoch_msg = False\n","      print(f'Epoch [{epoch + 1}/{epoch}], Test Loss: {loss.item()}')\n","  if patience_counter >= cfg.patience:\n","    print(\"Best acc achieved: \", best_accuracy)\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mcwG0kIDRnfg","executionInfo":{"status":"ok","timestamp":1718287675139,"user_tz":-480,"elapsed":70058,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"outputId":"25a3c5d6-6dea-407e-afe0-5690506ce438"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 1, Training Loss: 1.39 Acc: 4.19\n","Accuracy on the test set: 26.48%\n","Accuracy on the test set: 30.41%\n","Accuracy on the test set: 29.35%\n","Accuracy on the test set: 32.53%\n","Accuracy on the test set: 30.71%\n","Accuracy on the test set: 32.68%\n","Accuracy on the test set: 32.83%\n","Accuracy on the test set: 30.86%\n","Accuracy on the test set: 33.28%\n","Accuracy on the test set: 32.83%\n","Accuracy on the test set: 32.98%\n","Accuracy on the test set: 32.38%\n","Accuracy on the test set: 31.62%\n","Accuracy on the test set: 32.98%\n","Accuracy on the test set: 31.47%\n","Accuracy on the test set: 32.22%\n","Accuracy on the test set: 32.22%\n","Accuracy on the test set: 31.62%\n","Accuracy on the test set: 31.47%\n","Accuracy on the test set: 32.38%\n","Accuracy on the test set: 32.38%\n","Accuracy on the test set: 31.47%\n","Accuracy on the test set: 32.38%\n","Accuracy on the test set: 32.38%\n","Accuracy on the test set: 32.38%\n","Accuracy on the test set: 31.77%\n","Accuracy on the test set: 31.47%\n","Accuracy on the test set: 31.92%\n","Accuracy on the test set: 31.62%\n","Accuracy on the test set: 32.53%\n","Accuracy on the test set: 31.32%\n","Accuracy on the test set: 30.86%\n","Accuracy on the test set: 32.07%\n","Accuracy on the test set: 32.07%\n","Accuracy on the test set: 31.92%\n","Accuracy on the test set: 32.38%\n","Accuracy on the test set: 32.38%\n","Accuracy on the test set: 31.92%\n","Accuracy on the test set: 31.01%\n","Accuracy on the test set: 30.86%\n","Accuracy on the test set: 31.01%\n","Accuracy on the test set: 30.86%\n","Accuracy on the test set: 31.01%\n","Accuracy on the test set: 31.32%\n","Accuracy on the test set: 31.01%\n","Accuracy on the test set: 30.71%\n","Accuracy on the test set: 29.50%\n","Accuracy on the test set: 32.53%\n","Accuracy on the test set: 32.38%\n","Best acc achieved:  0.3328290468986384\n"]}]},{"cell_type":"markdown","source":["## Regression Neural Network"],"metadata":{"id":"wF89uiJWRIcf"}},{"cell_type":"code","source":["# Hyperparameters\n","input_size = X_train.shape[1]\n","hidden_size = 100\n","# num_classes = torch.unique(ys).shape[0]\n","learning_rate = 1e-5\n","batch_size = 16\n","epochs = 2000"],"metadata":{"id":"SUqIgNipWaOk","executionInfo":{"status":"ok","timestamp":1718340074035,"user_tz":-480,"elapsed":3,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# prompt: a standard neural network with 3 fully connected layers for regression\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class RegressionNet(nn.Module):\n","    def __init__(self, input_size):\n","        super(RegressionNet, self).__init__()\n","        self.nn = nn.Sequential(\n","            nn.Linear(input_size, hidden_size ),\n","            nn.LeakyReLU(),\n","            nn.Linear(hidden_size , hidden_size // 2),\n","            # nn.Dropout(0.5),\n","            nn.LeakyReLU(),\n","            nn.Linear(hidden_size // 2, hidden_size // 4),\n","            # nn.Dropout(0.5),\n","            nn.LeakyReLU(),\n","            nn.Linear(hidden_size // 4, 1)\n","            )\n","        self.init_weights()\n","\n","    def init_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Linear):\n","                torch.nn.init.xavier_uniform_(m.weight)\n","                if m.bias is not None:\n","                    m.bias.data.fill_(0)\n","\n","    def forward(self, x):\n","        return self.nn(x).squeeze()"],"metadata":{"id":"BLy5JoRbWSI0","executionInfo":{"status":"ok","timestamp":1718340074755,"user_tz":-480,"elapsed":1,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n","patience_counter = 0\n","best_model = None\n","best_accuracy = None\n","model = RegressionNet(Xs.shape[1])\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","for epoch in range(epochs):\n","  epoch_msg = True\n","  training_total_loss = 0.0\n","  num_of_batches = len(train_loader)\n","  for X_train_batch, y_train_batch in train_loader:\n","    model.train()\n","    # Forward pass\n","    outputs = model(X_train_batch)\n","    loss = criterion(outputs, y_train_batch)\n","    training_total_loss += loss.item()\n","    # Backward and optimize\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","  if epoch == 0 or (epoch + 1) % 3 == 0:\n","    print(f'Epoch: {epoch + 1}, Training Loss: {training_total_loss/num_of_batches:.2f}')\n","\n","  # Testing the model\n","  model.eval()\n","  with torch.no_grad():\n","    outputs = model(X_test)\n","    loss = criterion(outputs, y_test)\n","    if best_accuracy is None or loss.item() < best_accuracy:\n","      best_accuracy = loss.item()\n","      best_model = model\n","      patience_counter = 0\n","    else:\n","      patience_counter += 1\n","    if epoch_msg and (epoch + 1) % 100 == 0:\n","      epoch_msg = False\n","      print(f'Epoch [{epoch + 1}/{epochs}], Test Loss: {loss.item()}')\n","      # print(f'Loss on the test set: {loss.item()}')\n","  if patience_counter >= cfg.patience:\n","    print(\"Best loss achieved: \", best_accuracy)\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"55RGrtO-XZuG","executionInfo":{"status":"ok","timestamp":1718340141149,"user_tz":-480,"elapsed":31097,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"outputId":"d6df439b-1b51-4e0f-c78f-41bf37b98944"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 1, Training Loss: 2.88\n","Epoch: 3, Training Loss: 1.48\n","Epoch: 6, Training Loss: 1.08\n","Epoch: 9, Training Loss: 1.02\n","Epoch: 12, Training Loss: 1.00\n","Epoch: 15, Training Loss: 0.99\n","Epoch: 18, Training Loss: 0.99\n","Epoch: 21, Training Loss: 0.98\n","Epoch: 24, Training Loss: 0.97\n","Epoch: 27, Training Loss: 0.97\n","Epoch: 30, Training Loss: 0.96\n","Epoch: 33, Training Loss: 0.96\n","Epoch: 36, Training Loss: 0.95\n","Epoch: 39, Training Loss: 0.95\n","Epoch: 42, Training Loss: 0.94\n","Epoch: 45, Training Loss: 0.94\n","Epoch: 48, Training Loss: 0.93\n","Epoch: 51, Training Loss: 0.93\n","Epoch: 54, Training Loss: 0.92\n","Epoch: 57, Training Loss: 0.92\n","Epoch: 60, Training Loss: 0.91\n","Epoch: 63, Training Loss: 0.91\n","Epoch: 66, Training Loss: 0.91\n","Best loss achieved:  0.9809331893920898\n"]}]}],"metadata":{"colab":{"machine_shape":"hm","toc_visible":true,"provenance":[],"collapsed_sections":["rxoHWNZEmG4g"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}