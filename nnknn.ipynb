{"cells":[{"cell_type":"markdown","metadata":{"id":"rxoHWNZEmG4g"},"source":["# Setup"]},{"cell_type":"markdown","metadata":{"id":"CsfLxAVaPOTf"},"source":["On google colab, you have to restart runtime after running the following line"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4793,"status":"ok","timestamp":1718678716150,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":-480},"id":"T3Y5CLhymG4l","outputId":"3b73b71a-b559-4852-df71-b742adb9c51b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (2.3.0)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf) (4.9.3)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf) (6.0.1)\n"]}],"source":["!pip install omegaconf"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2727,"status":"ok","timestamp":1718678718874,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":-480},"id":"BxzI25zfmG4n","outputId":"69aa79ae-348b-46e0-8d42-0dea7ae92589"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive/\")\n","#\"/content/drive/My Drive/NN-kNN/\"\n","folder_name = \"/content/drive/Othercomputers/My MacBook Pro/GitHub/NN-kNN/\"\n","import sys\n","sys.path.insert(0,folder_name)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"q-0ffsjpbDLE","executionInfo":{"status":"ok","timestamp":1718678718875,"user_tz":-480,"elapsed":8,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["##This is added because my Rdata uses Cdata for the covid data set.\n","##Rdata use Cdata function to load the data set, then convert it to regression problem\n","import os\n","import sys\n","sys.path.append('/content/drive/Othercomputers/My MacBook Pro/GitHub/NN-kNN/dataset')\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"joYfU4jLmG4o","executionInfo":{"status":"ok","timestamp":1718678718875,"user_tz":-480,"elapsed":6,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["# folder_name = os.getcwd()"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"oDGrACwVmG4o","executionInfo":{"status":"ok","timestamp":1718678730494,"user_tz":-480,"elapsed":11624,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["import torch\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import accuracy_score\n","from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n","from sklearn.metrics import mean_squared_error\n","from tqdm import tqdm\n","from omegaconf import DictConfig, OmegaConf\n","\n","from dataset import cls_small_data as Cdata\n","import model.cls_model as Cmodel\n","from dataset import cls_medium_data\n","\n","from dataset import reg_data as Rdata\n","import model.reg_model as Rmodel"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"bzTxZZJnmG4p","executionInfo":{"status":"ok","timestamp":1718678731058,"user_tz":-480,"elapsed":575,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["conf_file = OmegaConf.load(os.path.join(folder_name, 'config.yaml'))"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"yT3W4iqSmG4p","executionInfo":{"status":"ok","timestamp":1718678731058,"user_tz":-480,"elapsed":2,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"oaKz8Ns3mG4q"},"source":["# NCA and LMNN setup"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4282,"status":"ok","timestamp":1718678735339,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":-480},"id":"cWQ8I6icoU8X","outputId":"e1f5ffc5-d409-4d08-e791-2ee04e6c618d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting metric-learn\n","  Downloading metric_learn-0.7.0-py2.py3-none-any.whl (67 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from metric-learn) (1.25.2)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from metric-learn) (1.11.4)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from metric-learn) (1.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->metric-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->metric-learn) (3.5.0)\n","Installing collected packages: metric-learn\n","Successfully installed metric-learn-0.7.0\n"]}],"source":["pip install metric-learn"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"zmjbXrjQmG4q","executionInfo":{"status":"ok","timestamp":1718678735339,"user_tz":-480,"elapsed":5,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["import metric_learn\n","from metric_learn import LMNN,NCA"]},{"cell_type":"markdown","metadata":{"id":"46TjfSz-mG4q"},"source":["# Data Sets"]},{"cell_type":"markdown","metadata":{"id":"ZkDrsvjWmG4r"},"source":["Supported small dataset for classification:  \n","'zebra',\n","'zebra_special',\n","'bal',\n","'digits',\n","'iris',\n","'wine',\n","'breast_cancer',\n","\n","for regression:\n","'califonia_housing',\n","'abalone',\n","'diabets',\n","'body_fat',\n","'ziweifaces'\n","\n","\n","Newly added data sets for mental health (psychology):\n","\n","Classification:\n","'psych_depression_physical_symptons',\n","'covid_anxious',\n","'covid_depressed'\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15702,"status":"ok","timestamp":1718678751038,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":-480},"id":"lxq-FY3FmG4r","outputId":"dc9f29ae-5551-4b1d-ce43-855b7d3af289"},"outputs":[{"output_type":"stream","name":"stdout","text":["Columns in the dataset: Index(['SU_ID', 'P_PANEL', 'NATIONAL_WEIGHT', 'REGION_WEIGHT',\n","       'NATIONAL_WEIGHT_POP', 'REGION_WEIGHT_POP', 'NAT_WGT_COMB_POP',\n","       'REG_WGT_COMB_POP', 'P_GEO', 'SOC1',\n","       ...\n","       'REGION9', 'P_DENSE', 'MODE', 'LANGUAGE', 'MAIL50', 'RACE1_BANNER',\n","       'RACE2_BANNER', 'INC_BANNER', 'AGE_BANNER', 'HH_BANNER'],\n","      dtype='object', length=177)\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/Othercomputers/My MacBook Pro/GitHub/NN-kNN/dataset/reg_data.py:108: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  ys = torch.tensor(ys, dtype=torch.float32)\n"]}],"source":["dataset_name = 'covid_depressed_reg'\n","cfg = conf_file['dataset'][dataset_name]\n","#TODO need to add other covid data sets here.\n","if dataset_name in ['covid_depressed','covid_anxious','covid_physical','covid_lonely','covid_hopeless',\n","                    'psych_depression_physical_symptons',\n","                    'zebra','zebra_special','bal','digits','iris','wine','breast_cancer']:\n","    criterion = torch.nn.CrossEntropyLoss()\n","    Xs, ys = Cdata.Cls_small_data(dataset_name)\n","elif dataset_name in []:\n","    criterion = torch.nn.CrossEntropyLoss()\n","    Xs, ys = cls_medium_data.Cls_medium_data(dataset_name)\n","else:\n","    criterion = torch.nn.MSELoss()\n","    Xs, ys = Rdata.Reg_data(dataset_name)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1718678751038,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":-480},"id":"aOIbeEfEmG4s","outputId":"7481c0e1-b601-4b85-8adb-22458d6906f7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<module 'dataset.cls_small_data' from '/content/drive/Othercomputers/My MacBook Pro/GitHub/NN-kNN/dataset/cls_small_data.py'>"]},"metadata":{},"execution_count":11}],"source":["# This section is used to reload the imported module.\n","# For example, if you made any changes in the model.cls_model, you should run importlib.reload(Cmodel) as long as you set import model.cls_model as Cmodel.\n","import importlib\n","importlib.reload(Cdata)"]},{"cell_type":"markdown","metadata":{"id":"EOEnGkKnmG4s"},"source":["# Classification with NNKNN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1718553861036,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":-480},"id":"fisqdp27w9fg","outputId":"ecc01a3c-e19e-48c7-fa4f-cb27b9a761a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Unique values: [-1.3411014 -0.4470338  0.4470338  1.3411014]\n","Counts: [311 311 311 311]\n","Xs.size(): torch.Size([1244, 161])\n"]}],"source":["# prompt: get the unique y values and their counts\n","\n","unique_values, counts = np.unique(ys, return_counts=True)\n","print(f\"Unique values: {unique_values}\")\n","print(f\"Counts: {counts}\")\n","print(f\"Xs.size(): {Xs.size()}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xOraZstjmG4t"},"outputs":[],"source":["def train_cls(X_train,y_train, X_test, y_test, cfg:DictConfig):\n","  X_train = X_train.to(device)\n","  y_train = y_train.to(device)\n","  X_test = X_test.to(device)\n","\n","  train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train, y_train), batch_size=cfg.batch_size, shuffle=True)\n","\n","  # Train model\n","  model = Cmodel.NN_k_NN(X_train,\n","                         y_train,\n","                         cfg.ca_weight_sharing,\n","                         cfg.top_case_enabled,\n","                         cfg.top_k,\n","                         cfg.discount,\n","                         device=device)\n","\n","  optimizer = torch.optim.Adam(model.parameters(), lr=cfg.learning_rate) #, weight_decay=1e-5)\n","\n","  patience_counter = 0\n","  for epoch in range(cfg.training_epochs):\n","    epoch_msg = True\n","\n","    for X_train_batch, y_train_batch in train_loader:\n","      model.train()\n","      _, _, output, predicted_class = model(X_train_batch)\n","      loss = criterion(output, y_train_batch)\n","\n","      # Backward and optimize\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","      if epoch_msg and (epoch + 1) % 2 == 0:\n","        print(f'Epoch [{epoch + 1}/{cfg.training_epochs}], Loss: {loss.item():.4f}')\n","\n","        epoch_msg = False\n","      # print(\"evaluating\")\n","    model.eval()\n","    with torch.no_grad():\n","      _, _, output, predicted_class = model(X_test)\n","\n","      # Calculate accuracy\n","      accuracy_temp = accuracy_score(y_test.numpy(), predicted_class.cpu().numpy())\n","    if epoch == 0:\n","      best_accuracy = accuracy_temp\n","      torch.save(model.state_dict(), cfg.PATH)\n","\n","    elif accuracy_temp > best_accuracy:\n","      #memorize best model\n","      torch.save(model.state_dict(), cfg.PATH)\n","      best_accuracy = accuracy_temp\n","      patience_counter = 0\n","\n","    elif patience_counter > cfg.patience:\n","      model.eval()\n","      print(\"patience exceeded, loading best model\")\n","      break\n","    else:\n","      patience_counter += 1\n","\n","  return best_accuracy, model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DMKsNhL3ItkK"},"outputs":[],"source":["def load_model_cls(X_train,y_train,cfg):\n","  # Define the model architecture\n","  model = Cmodel.NN_k_NN(\n","      X_train,\n","      y_train,\n","      cfg.ca_weight_sharing,\n","      cfg.top_case_enabled,\n","      cfg.top_k,\n","      cfg.discount,\n","      device=device\n","  )\n","  # Load the state dictionary\n","  model.load_state_dict(torch.load(cfg.path))\n","  model.to(device)\n","  model.eval()\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":350},"executionInfo":{"elapsed":714550,"status":"error","timestamp":1718554575580,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":-480},"id":"qPIxfcO-mG4t","outputId":"cbfb6287-7dc7-4ffd-c67e-f9a7ce0f34d9"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Unknown label type: 'continuous'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-71-a9df00cf600f>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mlmnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlmnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;31m# klmnn_accuracies.append( accuracy_score(knn.predict(X_test), y_test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mlmnn_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    474\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs_2d_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m                 \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;34m\"multilabel-sequences\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     ]:\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"]}],"source":["accuracies = []\n","knn_accuracies = []\n","lmnn_accuracies = []\n","PATH = os.path.join(folder_name, f'checkpoints/classifier_{dataset_name}.h5')\n","cfg.PATH = PATH\n","k_fold = KFold(n_splits=10, shuffle=True, random_state = None)\n","enable_lmnn = True\n","\n","for train_index, test_index in k_fold.split(Xs):\n","  # Get training and testing data\n","  X_train, X_test = Xs[train_index], Xs[test_index]\n","  y_train, y_test = ys[train_index], ys[test_index]\n","  if(enable_lmnn):\n","    # https://contrib.scikit-learn.org/metric-learn/supervised.html#lmnn\n","    lmnn = LMNN(n_neighbors=5, learn_rate=1e-6)\n","    ##TODO, change here if you need to use a different one\n","    # lmnn = metric_learn.MLKR()\n","    # lmnn = metric_learn.NCA(max_iter=1000)\n","    lmnn.fit(X_train,y_train)\n","    knn = KNeighborsClassifier(n_neighbors=5,metric=lmnn.get_metric())\n","    knn.fit(X_train,y_train)\n","    # klmnn_accuracies.append( accuracy_score(knn.predict(X_test), y_test))\n","    lmnn_acc = accuracy_score(knn.predict(X_test), y_test)\n","    lmnn_accuracies.append(lmnn_acc)\n","    # continue\n","\n","  knn =  KNeighborsClassifier(n_neighbors=cfg.top_k)\n","  knn.fit(X_train, y_train)\n","  knn_acc  = accuracy_score(knn.predict(X_test), y_test)\n","  knn_accuracies.append(knn_acc)\n","\n","  best_accuracy, model = train_cls(X_train,y_train, X_test, y_test, cfg)\n","  accuracies.append(best_accuracy)\n","  break\n","\n","print(f\"Average accuracy:{np.mean(accuracies):.3f}\")\n","print(f\"KNN accuracy:{np.mean(knn_accuracies):.3f}\")\n","print(f\"LMNN/NCA accuracy:{np.mean(lmnn_accuracies):.3f}\")\n"]},{"cell_type":"code","source":["print(f\"Average accuracy:{np.mean(accuracies):.3f}\")\n","print(f\"KNN accuracy:{np.mean(knn_accuracies):.3f}\")\n","print(f\"LMNN/NCA accuracy:{np.mean(lmnn_accuracies):.3f}\")"],"metadata":{"id":"hmEeDk1RXAwp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QVO3SDp9mG4u"},"source":["# Regression with NNKNN"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1718678751038,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":-480},"id":"x2uuoXv9ceJL","outputId":"76a8d430-2a36-4cd6-ec98-49fcbf29c1f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Unique values: [-1.3415424  -0.44718078  0.44718078  1.3415424 ]\n","Counts: [1703 1703 1703 1703]\n","Xs.size(): torch.Size([6812, 161])\n"]}],"source":["unique_values, counts = np.unique(ys, return_counts=True)\n","print(f\"Unique values: {unique_values}\")\n","print(f\"Counts: {counts}\")\n","print(f\"Xs.size(): {Xs.size()}\")"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"7ll4n1HNmG4u","executionInfo":{"status":"ok","timestamp":1718678751039,"user_tz":-480,"elapsed":13,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["def train_reg(X_train,y_train, X_test, y_test, cfg:DictConfig):\n","  X_train = X_train.to(device)\n","  y_train = y_train.to(device)\n","  X_test = X_test.to(device)\n","\n","  train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train, y_train), batch_size=cfg.batch_size, shuffle=True)\n","  test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_test, y_test), batch_size=cfg.batch_size, shuffle=False)\n","\n","\n","    # Train model\n","  model = Rmodel.NN_k_NN_regression(X_train,\n","                                    y_train,\n","                                    cfg.ca_weight_sharing,\n","                                    cfg.top_case_enabled,\n","                                    cfg.top_k,\n","                                    cfg.discount,\n","                                    cfg.class_weight_sharing,\n","                                    device=device)\n","\n","  optimizer = torch.optim.Adam(model.parameters(), lr=cfg.learning_rate) #, weight_decay=1e-5)\n","\n","  patience_counter = 0\n","  for epoch in range(cfg.training_epochs):\n","    # break # no training\n","    epoch_msg = True\n","    for X_train_batch, y_train_batch in train_loader:\n","      model.train()\n","      _, _, _, predicted_number = model(X_train_batch)\n","      # break\n","      loss = criterion(predicted_number.squeeze(), y_train_batch)\n","      # Backward and optimize\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","      if epoch_msg and (epoch + 1) % 2 == 0:\n","        epoch_msg = False\n","        print(f'Epoch [{epoch + 1}/{cfg.training_epochs}], Loss: {loss.item():.4f}')\n","\n","    model.eval()\n","    with torch.no_grad():\n","      predicted_numbers = []\n","      for X_test_batch, _ in test_loader:\n","        X_test_batch = X_test_batch.to(device)\n","        _, _, _, predicted_number = model(X_test_batch)\n","        predicted_numbers.extend(predicted_number.squeeze().cpu().detach())\n","\n","      predicted_numbers = torch.Tensor(predicted_numbers)\n","      accuracy_temp = criterion(y_test, predicted_numbers)\n","\n","    if epoch == 0:\n","      best_accuracy = accuracy_temp\n","      torch.save(model.state_dict(), cfg.PATH)\n","    elif accuracy_temp < best_accuracy:\n","      torch.save(model.state_dict(), cfg.PATH)\n","      best_accuracy = accuracy_temp\n","      patience_counter = 0\n","    elif patience_counter > cfg.patience:\n","      model.eval()\n","      print(\"patience exceeded, loading best model\")\n","      break\n","    else:\n","      patience_counter += 1\n","\n","  _, case_activations, _, predicted_number = model(X_test)\n","\n","  top_case_indices = torch.topk(case_activations, 5, dim=1)[1].cpu()\n","\n","  accuracy = criterion(y_test, predicted_number.squeeze().cpu())\n","  y_train = y_train.cpu()\n","  top_k_average_accuracy = mean_squared_error(torch.mean(y_train[top_case_indices], dim=1), y_test)\n","\n","  return best_accuracy, accuracy, top_k_average_accuracy, model"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"9yCDMIuMRN38","executionInfo":{"status":"ok","timestamp":1718678751039,"user_tz":-480,"elapsed":13,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["# prompt: load_model_reg()\n","\n","def load_model_reg(X_train,y_train,cfg):\n","  # Define the model architecture\n","  model = Rmodel.NN_k_NN_regression(\n","      X_train,\n","      y_train,\n","      cfg.ca_weight_sharing,\n","      cfg.top_case_enabled,\n","      cfg.top_k,\n","      cfg.discount,\n","      cfg.class_weight_sharing,\n","      device=device\n","  )\n","  # Load the state dictionary\n","  model.load_state_dict(torch.load(cfg.path))\n","  model.to(device)\n","  model.eval()\n","  return model\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DN8UlUVpmG4v","executionInfo":{"status":"ok","timestamp":1718681055158,"user_tz":-480,"elapsed":2304132,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"outputId":"0e011537-a905-4c34-962d-df3852416e52"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [2/1000], Loss: 1.4495\n","Epoch [4/1000], Loss: 0.7553\n","Epoch [6/1000], Loss: 1.3963\n","Epoch [8/1000], Loss: 0.2535\n","Epoch [10/1000], Loss: 0.3123\n","Epoch [12/1000], Loss: 0.6351\n","Epoch [14/1000], Loss: 0.7720\n","Epoch [16/1000], Loss: 0.4123\n","Epoch [18/1000], Loss: 0.1538\n","Epoch [20/1000], Loss: 0.4140\n","Epoch [22/1000], Loss: 0.3706\n","Epoch [24/1000], Loss: 0.3531\n","Epoch [26/1000], Loss: 0.1146\n","Epoch [28/1000], Loss: 0.0835\n","Epoch [30/1000], Loss: 0.0354\n","Epoch [32/1000], Loss: 0.0692\n","Epoch [34/1000], Loss: 0.3004\n","Epoch [36/1000], Loss: 0.0075\n","Epoch [38/1000], Loss: 0.0147\n","Epoch [40/1000], Loss: 0.0375\n","Epoch [42/1000], Loss: 0.1143\n","Epoch [44/1000], Loss: 0.3383\n","Epoch [46/1000], Loss: 0.0599\n","patience exceeded, loading best model\n","Average accuracy: 1.4184847\n","Average top_k_average_accuracies 1.1956955\n","KNN accuracy: 1.0800996\n"]}],"source":["best_accuracies = []\n","accuracies = []\n","top_k_average_accuracies = []\n","knn_accuracies = []\n","PATH = os.path.join(folder_name, f'checkpoints/regression_{dataset_name}.h5')\n","cfg.PATH = PATH\n","k_fold = KFold(n_splits=10, shuffle = True,random_state = None)\n","\n","\n","for train_index, test_index in k_fold.split(Xs):\n","  # Get training and testing data\n","  X_train, X_test = Xs[train_index], Xs[test_index]\n","  y_train, y_test = ys[train_index], ys[test_index]\n","\n","  knn = KNeighborsRegressor(n_neighbors=cfg.top_k)\n","  knn.fit(X_train, y_train)\n","  knn_accuracies.append(mean_squared_error(knn.predict(X_test), y_test))\n","\n","  best_accuracy, accuracy, top_k_average_accuracy, model= train_reg(X_train, y_train, X_test, y_test, cfg)\n","  best_accuracies.append(best_accuracy)\n","  accuracies.append(accuracy)\n","  top_k_average_accuracies.append(top_k_average_accuracy)\n","  break\n","print(\"Average accuracy:\", np.mean([acc.detach().numpy() for acc in accuracies]))\n","print(\"Average top_k_average_accuracies\", np.mean(top_k_average_accuracies))\n","print(\"KNN accuracy:\", np.mean(knn_accuracies))"]},{"cell_type":"markdown","metadata":{"id":"aQMTPXLwaBVq"},"source":["# Results Interpretation"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"sf23mP1UaIvx","executionInfo":{"status":"ok","timestamp":1718681055158,"user_tz":-480,"elapsed":4,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["def print_model_features(input_model):\n","  for n, p in model.named_parameters():\n","    print(n)\n","    print(p.data)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"MRO3tUPEbJUs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718681055159,"user_tz":-480,"elapsed":4,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"outputId":"dd7b9e86-5054-4624-c9d2-4953e8303043"},"outputs":[{"output_type":"stream","name":"stdout","text":["fa_layer.f1weight\n","tensor([11.4285,  6.2285,  0.9245,  5.9591,  2.9276,  1.2348,  1.3394,  8.3062,\n","         1.1304,  1.0490,  1.2083,  1.4562,  0.8585,  5.3763,  3.4906,  1.3939,\n","         3.2728,  2.0456,  1.3683,  2.2877,  1.4824,  2.0650,  2.2546,  1.5591,\n","         1.3316, 13.3507, 16.8494, 14.4817, 13.2512, 15.6008, 14.8567, 16.4928,\n","        13.5141, 16.6919, 14.6584, 12.7533, 13.5484, 15.7830, 15.3520, 14.5649,\n","        13.9639, 17.3138, 13.2132, 17.7573,  2.1341, 10.5041,  1.0000,  4.8032,\n","         7.4429,  4.6615,  2.1582,  2.9782,  1.4024,  0.8306,  0.8756,  1.3588,\n","         0.8092,  1.3054,  1.8860,  1.1991,  1.0479,  1.0136,  5.6394,  1.0001,\n","         1.3445,  4.2428,  1.5379,  4.8339,  1.0910,  5.8768,  1.5989, 12.3270,\n","        15.8744, 14.1680, 16.1559, 12.6565, 12.2387, 13.6426, 10.4749,  8.0653,\n","         9.1063,  7.9274,  3.4648,  1.3647,  4.7532,  0.8574,  1.4925,  0.9616,\n","         3.1056,  3.1585,  1.0405,  5.0599,  1.3888,  3.3215,  6.7450,  1.6237,\n","         6.1367,  0.7910,  2.5904,  1.5563,  3.0369,  4.9091, 12.5678, 13.2662,\n","        11.3151, 11.2259,  3.9862, 13.9075,  2.8799,  1.3402,  1.0123,  1.1538,\n","         2.2587,  1.7799,  1.1549,  1.0466,  4.5137,  1.0375,  0.7715,  1.5577,\n","         0.6481,  1.2029,  1.5729,  1.4480,  0.5426,  1.3706,  0.8252,  1.1675,\n","         0.6999,  1.5771,  0.9572,  0.7443,  0.9114,  1.2115,  1.5375, 11.7715,\n","        11.1054, 10.8769,  1.4543, 10.4359,  7.9518, 10.0448,  9.8968,  3.6648,\n","         6.1419, 11.1462,  2.6222, 14.8344, 12.5529,  9.0039, 11.1309, 13.5043,\n","        12.0195,  7.7735, 12.4519, 15.0200, 12.7031,  1.2795, 11.2294, 11.4634,\n","         9.9749])\n","ca_layer.fa_weight\n","tensor([[-4.4202e-02,  9.6520e-01,  8.5125e-01,  ...,  2.2690e-01,\n","          4.2361e+00,  1.0933e+00],\n","        [-3.2828e-03,  5.8841e-01,  8.2416e-01,  ..., -2.9379e-02,\n","         -1.7125e-01, -3.4157e-03],\n","        [ 1.3784e+00,  3.3155e+00,  1.7769e+00,  ..., -7.7571e-02,\n","         -2.8262e-01, -1.0224e+00],\n","        ...,\n","        [ 1.8080e+00, -4.9662e-02,  1.2840e+00,  ...,  6.5598e-01,\n","         -6.7373e-02,  2.1477e+00],\n","        [ 1.0000e+00,  1.0000e+00,  1.0000e+00,  ...,  9.9999e-01,\n","          1.0000e+00,  1.0000e+00],\n","        [ 1.0156e+00,  1.4435e+00,  1.2339e+00,  ...,  1.4408e+00,\n","          1.0984e+00,  1.9561e+00]])\n","ca_layer.bias\n","tensor([4.3176, 4.4057, 3.8566,  ..., 4.4595, 4.0254, 3.5747])\n"]}],"source":["print_model_features(model)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"PkxAqSoldjML","executionInfo":{"status":"ok","timestamp":1718681056561,"user_tz":-480,"elapsed":1405,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["# for regression only. for classification is different\n","#feature_activations, case_activations, predicted_number\n","model.eval()\n","feature_activations, case_activations, output, predicted_class = model(X_test)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"PtwGRyMjeXtp","executionInfo":{"status":"ok","timestamp":1718681056561,"user_tz":-480,"elapsed":13,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5918ad90-8f72-4101-866c-a8f2272c7076"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-7.0261e-01,  9.1787e-01, -7.9738e-01,  1.2080e+00, -1.3392e+00,\n","         1.3151e+00,  1.1774e+00,  7.6159e-01, -1.3415e+00,  7.5229e-01,\n","         6.7541e-01,  1.0123e+00,  1.3415e+00, -1.3415e+00, -2.6702e-01,\n","         1.3415e+00, -1.3407e+00, -1.3415e+00,  1.1031e-01,  1.6076e-01,\n","         5.5327e-01,  1.3346e+00,  8.7274e-01,  2.4256e-18, -2.9290e-17,\n","         1.1995e+00, -1.3165e+00, -1.3483e-01, -1.2264e+00,  2.4375e-03,\n","         5.9283e-01,  8.7178e-01,  2.1912e-02,  4.4718e-01, -1.3295e+00,\n","         9.4657e-01, -9.7813e-01,  7.3051e-01, -2.9784e-01,  1.1654e+00,\n","        -7.6678e-01,  9.7782e-01, -6.6859e-01,  5.9132e-01,  1.2908e+00,\n","        -1.1332e+00,  0.0000e+00,  6.7590e-01, -1.0801e+00,  0.0000e+00,\n","         5.4436e-01, -2.7856e-03, -1.2769e+00,  1.3399e+00, -1.7933e-01,\n","         1.2000e+00,  1.3005e+00, -1.2273e+00, -1.3396e+00, -1.0259e+00,\n","         1.3304e+00,  1.5101e-01, -1.3202e+00,  1.3241e+00,  5.2207e-01,\n","        -4.4718e-01, -2.5443e-02, -5.0490e-01,  6.2535e-01,  4.4702e-01,\n","        -4.1227e-01, -4.4812e-01, -1.2972e+00,  1.3358e+00, -7.2259e-01,\n","         3.1547e-01,  1.1715e-01, -9.7882e-01,  1.1436e+00,  6.7425e-02,\n","        -4.8399e-01, -1.1603e+00,  4.2936e-01, -1.3069e+00, -1.2887e+00,\n","        -4.1669e-01, -1.8163e-01,  1.2978e+00, -1.1670e+00,  4.6477e-01,\n","        -1.3412e+00,  3.5475e-01, -3.4289e-01,  1.8923e-02, -4.8679e-01,\n","        -1.3410e+00,  1.1192e+00,  1.0712e+00, -1.1551e+00, -1.0983e+00,\n","         8.8105e-01, -1.6171e-01, -1.0101e+00,  3.1022e-01, -2.9545e-01,\n","        -1.0004e+00, -4.4983e-01, -4.3538e-01,  1.0099e+00,  7.8926e-01,\n","        -4.4722e-01, -1.3411e+00,  7.8148e-01, -8.9169e-01, -8.6272e-01,\n","        -7.1200e-01,  5.0824e-01, -1.3192e+00,  1.8680e-01,  4.2729e-01,\n","         1.3415e+00, -1.3163e+00,  5.5227e-01,  6.1814e-01, -1.1681e-01,\n","        -4.2541e-01,  1.0769e+00, -4.4726e-01,  1.3415e+00,  0.0000e+00,\n","        -9.2132e-01, -5.9085e-01, -1.0138e+00, -1.3223e+00,  1.5536e-01,\n","         1.3204e+00,  2.2742e-01, -5.5630e-01,  1.3128e+00, -1.3097e+00,\n","        -8.3571e-02, -4.7480e-01, -1.1556e+00,  4.6404e-01, -1.3129e+00,\n","         4.5158e-01, -1.2776e-01, -3.7517e-01,  1.3212e+00,  1.0567e+00,\n","         2.2884e-01,  7.5667e-01, -6.2589e-01,  1.3519e-01, -6.5888e-08,\n","         4.5286e-01,  2.5559e-01, -1.1018e+00, -9.0852e-01,  1.3355e+00,\n","        -1.3222e+00, -6.3185e-01,  4.2782e-01, -1.0878e+00, -3.5628e-01,\n","         3.5572e-01,  1.6393e-14,  1.1397e+00, -1.9141e-01,  9.1290e-08,\n","        -1.3414e+00,  4.5606e-01,  1.1654e+00,  1.2208e+00,  3.6132e-01,\n","        -1.3349e+00,  1.0578e+00, -5.2853e-01,  1.2466e+00, -7.0122e-01,\n","        -7.8151e-01,  1.2090e+00, -9.7007e-01, -1.1435e-01, -2.5333e-01,\n","         1.0949e+00,  4.7048e-01, -1.3415e+00, -7.3784e-01,  1.3393e+00,\n","        -3.4662e-01, -7.8595e-01, -4.4836e-01,  6.3096e-02, -1.3091e+00,\n","         1.2930e+00,  1.2665e+00, -1.3358e+00, -5.0587e-01, -4.2414e-01,\n","         7.0515e-01, -6.1159e-08, -2.2773e-01, -5.7531e-01, -1.2646e+00,\n","         7.0716e-01, -5.1151e-01, -1.2553e+00, -1.3390e+00,  1.2118e+00,\n","        -8.1375e-01,  1.3226e+00, -3.0377e-01, -1.1418e+00,  4.6050e-01,\n","         0.0000e+00, -2.2835e-01, -4.4433e-01,  9.1786e-01, -8.8522e-01,\n","        -6.1999e-01, -7.8842e-01,  1.2787e+00,  1.3394e+00,  1.2981e+00,\n","         1.3395e+00, -1.0065e+00,  1.3415e+00, -8.2344e-01,  1.0713e+00,\n","        -1.3068e+00, -4.7608e-01, -6.1759e-01,  4.0630e-01,  1.3279e+00,\n","        -3.4035e-01,  4.8676e-01,  1.0505e+00, -4.4718e-01, -1.3415e+00,\n","        -1.2916e+00,  1.1163e+00, -1.5082e-01,  6.5306e-01,  1.3058e+00,\n","         1.2262e+00, -4.6978e-01, -1.1427e+00, -1.3370e+00,  0.0000e+00,\n","         1.3407e+00,  2.9409e-02, -9.8523e-01,  4.5910e-01, -1.3413e+00,\n","         1.3402e+00, -1.0211e+00, -1.1561e+00,  0.0000e+00,  7.3056e-01,\n","         8.1086e-02,  7.6212e-02, -1.3152e+00, -1.3153e+00,  8.0424e-01,\n","        -4.9845e-01, -1.0386e-01, -1.3030e+00,  6.3539e-01, -4.9331e-01,\n","         3.2223e-01, -1.1165e+00, -3.8739e-01,  3.9353e-01, -4.4156e-01,\n","        -1.3411e+00, -8.6516e-01,  9.7111e-01, -1.3769e-01, -8.2453e-01,\n","        -7.5073e-01,  3.5623e-01,  6.4145e-01, -6.7122e-01, -1.0745e+00,\n","         1.0237e+00, -6.4223e-01,  1.3185e+00, -4.4718e-01,  6.0143e-01,\n","         3.9873e-01,  1.1558e+00,  1.3367e+00,  2.6338e-01,  1.3084e+00,\n","        -4.4958e-01, -4.4661e-01,  9.1757e-13,  4.3552e-01, -9.5595e-01,\n","        -3.1981e-01, -7.0139e-01,  4.3365e-01,  1.3261e+00,  4.4264e-01,\n","        -3.2852e-01, -1.2535e+00,  4.8725e-01,  1.2250e+00,  3.1749e-02,\n","         1.2062e+00,  6.5024e-02, -1.2518e+00,  4.4895e-01,  0.0000e+00,\n","         4.5592e-01, -9.7108e-01,  1.0225e+00, -1.0127e-01,  6.3644e-01,\n","         5.2522e-01,  6.4512e-01, -1.2105e+00, -9.2384e-01, -1.1722e+00,\n","        -9.5302e-02,  1.1428e+00,  1.3415e+00, -1.1479e+00,  9.9904e-01,\n","         7.2788e-02,  3.6168e-01,  1.5064e-28, -6.9274e-02, -6.2507e-02,\n","        -5.3499e-01, -1.0426e+00, -6.6118e-01, -1.1540e+00, -5.0440e-01,\n","         1.3100e+00, -4.8618e-01,  1.3001e+00, -1.2877e+00, -1.2219e+00,\n","        -1.4158e-01,  1.0921e+00, -1.0615e+00, -1.3150e+00,  1.3021e+00,\n","         1.2818e+00, -1.3415e+00,  4.4699e-01,  1.2797e+00, -1.0986e-01,\n","         1.3401e+00,  6.4762e-01,  2.9237e-01,  4.1928e-17,  6.8500e-01,\n","        -6.1131e-01,  5.0174e-01,  1.2421e+00, -1.2183e+00,  1.3296e+00,\n","         3.5085e-02,  1.3383e+00,  4.7512e-01, -1.1236e+00,  1.3412e+00,\n","         4.5761e-01, -2.9597e-01,  1.3195e+00, -1.0370e+00, -1.2911e+00,\n","         1.0215e+00,  7.6015e-01, -2.4268e-01,  5.2089e-01, -1.2979e+00,\n","         1.2507e+00, -1.3198e+00,  7.3627e-01, -4.0167e-01, -1.3000e+00,\n","        -1.2696e+00, -1.2792e+00,  1.1759e+00, -2.8706e-01, -4.3799e-01,\n","         1.0869e+00, -1.3246e+00, -3.5133e-06, -4.8127e-01, -1.4851e-18,\n","         1.1533e+00,  5.4217e-01, -9.9089e-01,  5.7858e-02, -1.3220e+00,\n","         2.5876e-01, -1.6447e-01,  1.6192e-01,  4.0116e-01,  6.3559e-01,\n","        -1.8154e-02, -1.1370e+00, -1.3402e+00,  4.8641e-02,  5.5241e-02,\n","         7.1927e-01,  1.1766e+00, -4.4716e-01, -1.1582e+00,  0.0000e+00,\n","         1.3415e+00,  1.1275e+00,  1.3309e+00,  1.3233e+00, -1.3411e+00,\n","        -7.6034e-01,  4.4945e-01,  3.0173e-01,  5.8354e-01, -1.3407e+00,\n","         5.7451e-01,  3.6767e-01,  9.7368e-01,  1.3351e+00,  1.3347e+00,\n","        -1.9663e-01,  5.7567e-01,  1.2920e+00, -4.4718e-01,  1.3337e+00,\n","        -4.2219e-02,  4.1482e-01, -4.4681e-01, -4.4653e-01,  1.2128e+00,\n","        -2.6175e-01,  1.4404e-01, -1.1820e+00,  1.2549e+00,  1.3378e+00,\n","        -1.1339e+00,  1.2582e+00,  1.3066e+00, -1.9424e-01,  9.7750e-01,\n","         4.4817e-01,  8.1750e-02, -1.0728e+00,  4.4718e-01, -8.1009e-01,\n","        -1.2618e+00, -4.8604e-01,  1.3061e+00,  1.3402e+00,  0.0000e+00,\n","         0.0000e+00, -1.0417e+00,  1.2579e+00,  1.3392e+00, -9.7496e-01,\n","        -7.2272e-01, -7.5130e-01, -4.0728e-01,  1.0097e+00,  7.3906e-01,\n","        -5.6553e-01, -6.1892e-01, -3.3128e-01,  3.2155e-01, -8.6508e-01,\n","        -4.1757e-01, -1.0329e+00,  1.1794e-01, -3.2788e-01,  8.3364e-01,\n","         3.3927e-02,  1.3045e+00, -9.0358e-01,  5.3909e-01, -1.3395e+00,\n","        -1.1984e+00,  1.1501e+00,  1.8079e-01, -9.3756e-01,  1.2249e-01,\n","        -8.8978e-01,  4.4341e-01,  6.0327e-01,  1.0065e+00,  1.3315e+00,\n","        -9.3777e-02, -4.4718e-01,  5.0838e-17,  8.6663e-01, -9.3127e-01,\n","         2.7424e-01,  3.8915e-01, -5.7295e-01,  5.5101e-01, -4.4297e-01,\n","        -4.4837e-01,  1.1863e+00,  1.3273e+00,  1.2252e+00,  7.2174e-10,\n","        -1.1951e+00,  9.0496e-01,  1.3407e+00,  9.4881e-01, -4.4659e-01,\n","        -3.5156e-01, -4.1149e-01, -1.2886e+00, -4.5765e-01,  1.3225e+00,\n","        -2.1296e-18, -2.9174e-01,  3.5613e-01,  1.0483e+00, -7.7270e-01,\n","        -5.8624e-01, -2.5856e-02,  1.2194e+00,  1.3888e-01, -2.3525e-01,\n","         4.4991e-01,  1.3096e+00, -1.1713e+00,  1.0498e-02, -2.8447e-04,\n","        -8.7071e-01, -9.9660e-01,  1.3415e+00,  2.4810e-03, -8.4518e-02,\n","         2.2388e-01, -1.2875e+00,  5.3124e-01, -1.2810e+00,  1.3355e+00,\n","         1.0174e+00, -1.2188e+00, -4.3439e-01, -1.1778e+00, -6.9624e-01,\n","        -5.5415e-01, -1.3415e+00,  9.3013e-01,  6.8400e-01, -3.1723e-01,\n","         1.1277e+00,  0.0000e+00,  5.0590e-01, -6.6109e-01,  2.6666e-01,\n","        -1.3212e+00,  1.3405e+00,  6.7976e-01,  0.0000e+00, -3.9724e-01,\n","         4.2522e-01, -1.1026e+00, -1.1328e+00, -2.7452e-01, -1.1700e+00,\n","         1.2533e+00, -1.3415e+00,  1.3415e+00,  6.2143e-01,  9.9238e-01,\n","         1.3461e-01, -3.7040e-01, -5.3492e-01,  1.1024e+00, -5.9372e-01,\n","        -7.0572e-01, -4.1565e-01, -2.1047e-01,  3.5351e-01, -5.6095e-01,\n","        -3.3085e-01,  2.9406e-01,  1.3185e+00, -6.5970e-01,  1.3411e+00,\n","         6.2829e-01, -1.2427e+00, -1.0076e+00,  9.5805e-01,  3.9080e-01,\n","        -1.0331e+00,  4.0377e-01, -8.0054e-01,  7.0895e-01,  7.8105e-01,\n","        -1.5224e-01,  1.2788e-02,  4.4514e-01, -4.6216e-01, -1.1353e+00,\n","         1.7215e-01,  1.1773e+00, -3.7638e-03, -4.7851e-01,  1.1141e+00,\n","        -4.8132e-01, -9.0912e-01, -7.5546e-01, -9.5891e-01, -1.8968e-01,\n","        -1.1834e+00, -9.5568e-01, -7.3415e-01, -7.1033e-01,  1.3415e+00,\n","        -1.0601e+00,  1.3413e+00, -4.4711e-01, -4.8894e-01,  1.7390e-01,\n","        -1.2755e+00, -7.2394e-07, -6.8920e-01,  1.3414e+00, -1.2233e+00,\n","         4.2973e-01, -9.1774e-02,  5.4573e-01,  1.3299e+00, -1.0584e+00,\n","         1.2982e+00,  1.3186e+00, -1.1704e+00,  8.9836e-01, -1.0199e+00,\n","        -1.1307e+00,  2.8302e-01,  1.3307e+00,  1.3472e-05,  1.2462e+00,\n","        -8.9485e-02, -6.3457e-01, -1.9450e-03,  1.3382e+00, -1.6862e-01,\n","         4.4477e-01,  1.2938e+00, -1.0292e+00, -6.9945e-01, -1.3415e+00,\n","         4.9715e-01, -8.3561e-01,  3.5105e-01, -2.6638e-01, -1.1749e+00,\n","        -5.9622e-01,  1.3197e+00, -4.1515e-05, -4.4690e-01,  5.5630e-01,\n","         1.2947e+00, -8.4541e-01,  5.5297e-01, -1.0818e+00,  5.3805e-01,\n","        -1.2975e+00,  1.9158e-01, -1.3389e+00, -1.3231e+00, -8.8371e-01,\n","         1.6895e-01, -4.1491e-01, -7.1078e-01,  7.6928e-02,  8.6727e-01,\n","         6.9768e-02, -5.6581e-01], grad_fn=<MvBackward0>)"]},"metadata":{},"execution_count":19}],"source":["predicted_class"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"EvY5_WGkeaxg","executionInfo":{"status":"ok","timestamp":1718681056561,"user_tz":-480,"elapsed":11,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ef285f7d-3e5a-457a-9074-988c8acaa704"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 0.4472,  1.3415, -0.4472,  1.3415, -1.3415,  0.4472, -0.4472,  0.4472,\n","        -1.3415,  0.4472,  0.4472,  0.4472,  0.4472, -1.3415, -1.3415,  1.3415,\n","        -1.3415, -1.3415, -1.3415,  0.4472,  1.3415, -1.3415, -0.4472, -0.4472,\n","        -0.4472,  0.4472, -1.3415,  0.4472,  0.4472, -1.3415, -1.3415, -1.3415,\n","        -0.4472,  1.3415, -1.3415,  1.3415, -1.3415, -1.3415,  1.3415,  1.3415,\n","        -1.3415,  1.3415, -0.4472,  0.4472, -1.3415,  1.3415, -1.3415, -0.4472,\n","        -1.3415, -0.4472, -1.3415,  0.4472,  1.3415, -0.4472,  0.4472,  0.4472,\n","         0.4472, -0.4472, -1.3415, -0.4472, -1.3415,  0.4472, -1.3415,  0.4472,\n","        -0.4472, -0.4472, -0.4472, -1.3415,  0.4472,  0.4472,  0.4472,  1.3415,\n","        -0.4472,  1.3415, -0.4472, -1.3415,  1.3415,  1.3415,  0.4472, -1.3415,\n","        -0.4472, -0.4472, -0.4472, -0.4472,  0.4472, -1.3415,  0.4472,  0.4472,\n","        -1.3415, -1.3415, -1.3415,  0.4472, -1.3415,  1.3415,  0.4472, -0.4472,\n","         0.4472,  1.3415, -1.3415, -0.4472,  0.4472, -0.4472, -1.3415, -0.4472,\n","         1.3415, -1.3415,  1.3415, -1.3415, -0.4472, -1.3415, -1.3415, -0.4472,\n","         1.3415,  1.3415, -0.4472, -1.3415,  1.3415, -0.4472, -0.4472,  0.4472,\n","        -1.3415,  1.3415,  1.3415,  0.4472,  1.3415,  0.4472,  1.3415,  0.4472,\n","         0.4472, -1.3415, -0.4472, -1.3415, -0.4472, -1.3415,  0.4472, -0.4472,\n","        -1.3415,  0.4472, -0.4472,  1.3415,  1.3415,  0.4472, -1.3415,  0.4472,\n","        -1.3415,  1.3415, -0.4472, -1.3415,  1.3415,  1.3415, -0.4472, -0.4472,\n","         0.4472,  1.3415,  0.4472,  0.4472,  1.3415, -1.3415,  1.3415,  1.3415,\n","         1.3415, -0.4472, -1.3415, -0.4472, -0.4472,  0.4472,  1.3415,  1.3415,\n","        -0.4472, -0.4472, -1.3415, -0.4472,  0.4472, -0.4472, -0.4472, -1.3415,\n","        -1.3415, -1.3415, -0.4472,  0.4472, -0.4472, -1.3415, -1.3415,  1.3415,\n","         0.4472, -0.4472,  0.4472, -0.4472, -1.3415, -1.3415,  1.3415,  1.3415,\n","         1.3415,  1.3415, -1.3415,  0.4472, -0.4472, -1.3415,  0.4472,  0.4472,\n","        -0.4472,  0.4472, -1.3415,  0.4472,  1.3415,  0.4472,  0.4472,  0.4472,\n","        -1.3415, -1.3415,  0.4472, -0.4472, -1.3415, -1.3415, -1.3415,  1.3415,\n","         0.4472,  0.4472, -1.3415,  1.3415, -0.4472, -1.3415,  1.3415,  0.4472,\n","         0.4472,  1.3415, -1.3415,  0.4472, -0.4472,  0.4472, -0.4472, -1.3415,\n","        -1.3415, -0.4472,  1.3415,  0.4472,  1.3415,  0.4472, -0.4472, -1.3415,\n","        -1.3415,  0.4472, -0.4472,  1.3415,  0.4472, -0.4472, -1.3415, -1.3415,\n","        -0.4472, -0.4472,  1.3415, -1.3415,  1.3415,  1.3415, -1.3415, -0.4472,\n","         1.3415,  0.4472,  0.4472, -1.3415, -0.4472,  1.3415, -0.4472, -0.4472,\n","         0.4472,  0.4472,  0.4472, -1.3415, -0.4472, -0.4472,  1.3415, -1.3415,\n","         0.4472, -0.4472,  1.3415,  0.4472,  0.4472,  1.3415, -1.3415, -0.4472,\n","        -1.3415, -1.3415, -0.4472, -0.4472, -1.3415,  0.4472,  1.3415, -0.4472,\n","         1.3415, -0.4472,  0.4472,  0.4472,  0.4472,  0.4472,  0.4472,  0.4472,\n","        -0.4472, -0.4472,  0.4472, -0.4472, -1.3415, -1.3415, -1.3415,  0.4472,\n","        -0.4472,  1.3415, -1.3415, -1.3415,  0.4472,  0.4472, -0.4472, -1.3415,\n","        -0.4472,  1.3415,  1.3415,  1.3415, -0.4472,  1.3415,  1.3415, -0.4472,\n","        -0.4472, -1.3415,  1.3415, -0.4472,  1.3415,  1.3415,  1.3415,  0.4472,\n","         1.3415, -1.3415, -0.4472,  1.3415,  1.3415, -1.3415,  1.3415,  0.4472,\n","        -1.3415,  0.4472, -1.3415,  0.4472,  0.4472, -1.3415, -0.4472, -1.3415,\n","         0.4472, -0.4472, -0.4472, -1.3415, -0.4472, -0.4472, -1.3415, -0.4472,\n","        -0.4472,  1.3415,  1.3415, -1.3415,  0.4472, -1.3415, -1.3415, -1.3415,\n","         0.4472, -1.3415, -0.4472, -0.4472,  1.3415, -0.4472,  0.4472,  1.3415,\n","        -1.3415,  1.3415, -1.3415, -0.4472,  0.4472, -1.3415,  1.3415,  0.4472,\n","         0.4472,  0.4472, -0.4472,  0.4472, -1.3415, -1.3415,  0.4472,  0.4472,\n","        -1.3415, -1.3415, -0.4472, -0.4472, -0.4472,  1.3415,  1.3415,  0.4472,\n","        -1.3415, -1.3415,  0.4472,  1.3415, -1.3415,  1.3415,  0.4472, -1.3415,\n","         1.3415,  1.3415, -1.3415, -1.3415, -1.3415,  0.4472, -0.4472,  0.4472,\n","        -0.4472, -0.4472,  1.3415,  0.4472,  1.3415, -0.4472, -0.4472, -0.4472,\n","         1.3415,  1.3415, -0.4472, -1.3415, -0.4472,  1.3415, -0.4472,  0.4472,\n","        -1.3415, -0.4472, -0.4472,  1.3415,  1.3415, -0.4472, -0.4472,  1.3415,\n","         1.3415,  0.4472, -0.4472, -0.4472,  0.4472,  1.3415, -1.3415, -0.4472,\n","         1.3415,  0.4472, -1.3415, -0.4472,  0.4472, -1.3415, -1.3415,  0.4472,\n","        -1.3415,  0.4472,  1.3415,  1.3415, -1.3415,  1.3415,  0.4472, -0.4472,\n","        -0.4472,  1.3415, -0.4472,  1.3415,  1.3415,  0.4472, -0.4472, -1.3415,\n","        -0.4472,  0.4472,  0.4472, -1.3415,  0.4472, -0.4472, -1.3415,  0.4472,\n","        -0.4472, -0.4472, -0.4472,  0.4472,  1.3415,  1.3415,  0.4472,  0.4472,\n","        -1.3415, -0.4472, -0.4472, -1.3415, -1.3415,  0.4472,  1.3415,  0.4472,\n","        -0.4472,  1.3415,  0.4472, -0.4472, -1.3415,  0.4472,  1.3415, -0.4472,\n","         1.3415,  1.3415, -0.4472,  1.3415, -0.4472,  1.3415, -1.3415, -0.4472,\n","        -1.3415,  1.3415,  0.4472, -1.3415, -1.3415,  1.3415,  1.3415,  0.4472,\n","         0.4472, -1.3415, -0.4472, -1.3415, -1.3415, -0.4472,  1.3415, -1.3415,\n","         0.4472, -1.3415,  1.3415,  1.3415,  1.3415, -1.3415,  1.3415,  0.4472,\n","         0.4472,  1.3415, -0.4472, -0.4472, -1.3415,  1.3415, -0.4472, -0.4472,\n","         0.4472, -0.4472, -0.4472, -0.4472,  0.4472, -1.3415,  1.3415, -0.4472,\n","         0.4472,  1.3415, -1.3415, -0.4472,  0.4472, -0.4472,  0.4472,  0.4472,\n","        -1.3415, -0.4472,  1.3415, -0.4472, -0.4472, -1.3415, -0.4472, -1.3415,\n","        -0.4472, -0.4472, -1.3415, -0.4472, -1.3415,  1.3415, -0.4472, -0.4472,\n","         1.3415,  0.4472, -0.4472, -1.3415,  0.4472,  0.4472, -1.3415,  1.3415,\n","         1.3415, -0.4472, -0.4472, -0.4472, -0.4472, -0.4472, -0.4472, -1.3415,\n","        -0.4472, -1.3415, -1.3415, -0.4472, -1.3415,  0.4472,  1.3415, -0.4472,\n","        -1.3415,  1.3415,  1.3415, -1.3415, -0.4472,  0.4472,  0.4472, -0.4472,\n","        -0.4472, -1.3415,  0.4472,  0.4472,  0.4472,  0.4472, -1.3415,  1.3415,\n","        -1.3415, -1.3415, -1.3415, -1.3415,  0.4472, -1.3415, -1.3415,  1.3415,\n","        -0.4472, -0.4472, -1.3415, -1.3415, -0.4472, -1.3415,  1.3415, -0.4472,\n","        -0.4472, -1.3415,  1.3415, -0.4472,  1.3415, -1.3415, -1.3415,  0.4472,\n","        -1.3415,  1.3415,  1.3415,  1.3415,  1.3415, -0.4472,  0.4472, -1.3415,\n","         1.3415,  0.4472,  1.3415, -0.4472,  1.3415,  0.4472, -1.3415, -1.3415,\n","         0.4472,  0.4472,  1.3415,  0.4472,  0.4472,  1.3415, -0.4472,  1.3415,\n","         0.4472,  1.3415, -1.3415,  0.4472,  0.4472,  1.3415, -0.4472, -0.4472,\n","        -1.3415, -1.3415,  1.3415,  1.3415,  1.3415,  1.3415,  1.3415, -0.4472,\n","         1.3415, -1.3415, -1.3415,  1.3415,  1.3415,  1.3415,  0.4472,  0.4472,\n","         0.4472, -0.4472])"]},"metadata":{},"execution_count":20}],"source":["y_test"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"Eb7wyntlXft_","executionInfo":{"status":"error","timestamp":1718681056562,"user_tz":-480,"elapsed":9,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"colab":{"base_uri":"https://localhost:8080/","height":193},"outputId":"7e8683eb-81f5-444d-9d34-ca58a4e95944"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-70ff8e18b811>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# prompt: accuracy comparing predicted_class and y_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."]}],"source":["# prompt: accuracy comparing predicted_class and y_test\n","\n","accuracy = accuracy_score(y_test.numpy(), predicted_class.cpu().numpy())\n","print(\"Accuracy:\", accuracy)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hjaUAY7Bkjyr","executionInfo":{"status":"aborted","timestamp":1718681056562,"user_tz":-480,"elapsed":8,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["#inspecting the case activations\n","top_case_indices = torch.topk(case_activations, 5, dim=1)[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tfi-PKhokmev","executionInfo":{"status":"aborted","timestamp":1718681056562,"user_tz":-480,"elapsed":7,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["X_test[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oMxrFCywYIaQ","executionInfo":{"status":"aborted","timestamp":1718681056562,"user_tz":-480,"elapsed":7,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["y_test[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"73NQbeJ_kpO_","executionInfo":{"status":"aborted","timestamp":1718681056563,"user_tz":-480,"elapsed":8,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["X_train[top_case_indices[0][0]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q9_6zvszYKPw","executionInfo":{"status":"aborted","timestamp":1718681056563,"user_tz":-480,"elapsed":8,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["y_train[top_case_indices[0][0]]"]},{"cell_type":"markdown","metadata":{"id":"xMePSTR1lXbb"},"source":["By comparing the following two blocks' outputs, you can see we are retrieving a good neighbor."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0izuKF6okrsc","executionInfo":{"status":"aborted","timestamp":1718681056564,"user_tz":-480,"elapsed":9,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["#sum abs of X_test[0] and the top activated case\n","sum(abs(X_test[0] - X_train[top_case_indices[0][0]]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"faYClHOVktuW","executionInfo":{"status":"aborted","timestamp":1718681056564,"user_tz":-480,"elapsed":9,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["# prompt: average sum abs of X_test[0] and X_train data\n","print(np.mean([sum(abs(X_test[0] - X_train[i])) for i in range(len(X_train))]))"]},{"cell_type":"markdown","metadata":{"id":"zkYKvaP-lz_0"},"source":["TODO:: A better way is to show the distribution of ``X_test[0] - X_train[i]``"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xrwLY3gXmCLd","executionInfo":{"status":"aborted","timestamp":1718681056564,"user_tz":-480,"elapsed":9,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["y_train[top_case_indices[0]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"es5Kv85CmHMt","executionInfo":{"status":"aborted","timestamp":1718681056564,"user_tz":-480,"elapsed":9,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["knn.predict(X_test)[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pxOcKMzHmJkS","executionInfo":{"status":"aborted","timestamp":1718681056564,"user_tz":-480,"elapsed":9,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["indices = knn.kneighbors(X_test)[1][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o4vuKW0rmNVi","executionInfo":{"status":"aborted","timestamp":1718681056564,"user_tz":-480,"elapsed":8,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["y_train[indices]"]},{"cell_type":"markdown","source":["# Sanity Check\n"],"metadata":{"id":"uZsxNJZDQ8RQ"}},{"cell_type":"markdown","source":["## Classification Neural Network"],"metadata":{"id":"ZhHAd1y-Q_C2"}},{"cell_type":"code","source":["# Hyperparameters\n","input_size = X_train.shape[1]\n","hidden_size = 1024\n","num_classes = torch.unique(ys).shape[0]\n","learning_rate = 1e-5\n","batch_size = 16\n","epochs = 2000"],"metadata":{"id":"pXu1CDqXRR_O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# Define the neural network architecture for classification\n","class NeuralNet(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(NeuralNet, self).__init__()\n","        self.nn = nn.Sequential(\n","            nn.Linear(input_size, hidden_size ),\n","            nn.LeakyReLU(),\n","            nn.Linear(hidden_size , hidden_size // 2),\n","            # nn.Dropout(0.5),\n","            nn.LeakyReLU(),\n","            nn.Linear(hidden_size // 2, hidden_size // 4),\n","            # nn.Dropout(0.5),\n","            nn.LeakyReLU(),\n","            nn.Linear(hidden_size // 4, num_classes)\n","            )\n","        self.init_weights()\n","\n","    def init_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Linear):\n","                torch.nn.init.xavier_uniform_(m.weight)\n","                if m.bias is not None:\n","                    m.bias.data.fill_(0)\n","\n","    def forward(self, x):\n","        return self.nn(x)\n"],"metadata":{"id":"CBu0Gj9vRKYf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n","patience_counter = 0\n","best_model = None\n","best_accuracy = None\n","# Initialize the model, loss function, and optimizer\n","model = NeuralNet(input_size, hidden_size, num_classes)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Training loop\n","for epoch in range(epochs):\n","  epoch_msg = True\n","  training_total_acc = 0.0\n","  training_total_loss = 0.0\n","  num_of_batches = len(train_loader)\n","  for X_train_batch, y_train_batch in train_loader:\n","    model.train()\n","    # Forward pass\n","    outputs = model(X_train_batch)\n","    loss = criterion(outputs, y_train_batch)\n","\n","    # Backward and optimize\n","    _, predicted = torch.max(outputs, 1)\n","    training_total_acc += torch.sum(predicted == y_train_batch).item()\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    training_total_loss += loss.item()\n","    # if (i + 1) % 5 == 0\n","  if epoch == 0 or (epoch + 1) % 100 == 0:\n","    print(f\"Epoch: {epoch + 1}, Training Loss: {training_total_loss/num_of_batches:.2f} Acc: {training_total_acc/num_of_batches:.2f}\")\n","  # Testing the model\n","  model.eval()\n","  with torch.no_grad():\n","    outputs = model(X_test)\n","    loss = criterion(outputs, y_test)\n","    _, predicted = torch.max(outputs, 1)\n","    accuracy = torch.sum(predicted == y_test).item() / len(y_test)\n","    print(f'Accuracy on the test set: {accuracy * 100:.2f}%')\n","    if best_accuracy is None or accuracy > best_accuracy:\n","      best_accuracy = accuracy\n","      best_model = model\n","      patience_counter = 0\n","    else:\n","      patience_counter += 1\n","    if epoch_msg and (epoch + 1) % 100 == 0:\n","      epoch_msg = False\n","      print(f'Epoch [{epoch + 1}/{epoch}], Test Loss: {loss.item()}')\n","  if patience_counter >= cfg.patience:\n","    print(\"Best acc achieved: \", best_accuracy)\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mcwG0kIDRnfg","executionInfo":{"status":"ok","timestamp":1718530224224,"user_tz":-480,"elapsed":274050,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"outputId":"f94ce26f-c2d1-4163-ae09-b3b50ec1230f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 1, Training Loss: 1.39 Acc: 4.15\n","Accuracy on the test set: 26.32%\n","Accuracy on the test set: 26.62%\n","Accuracy on the test set: 28.72%\n","Accuracy on the test set: 29.32%\n","Accuracy on the test set: 29.02%\n","Accuracy on the test set: 30.68%\n","Accuracy on the test set: 29.62%\n","Accuracy on the test set: 31.28%\n","Accuracy on the test set: 30.53%\n","Accuracy on the test set: 29.17%\n","Accuracy on the test set: 30.08%\n","Accuracy on the test set: 31.43%\n","Accuracy on the test set: 30.68%\n","Accuracy on the test set: 30.83%\n","Accuracy on the test set: 30.53%\n","Accuracy on the test set: 29.92%\n","Accuracy on the test set: 30.38%\n","Accuracy on the test set: 30.08%\n","Accuracy on the test set: 30.98%\n","Accuracy on the test set: 30.08%\n","Accuracy on the test set: 30.08%\n","Accuracy on the test set: 30.83%\n","Accuracy on the test set: 31.28%\n","Accuracy on the test set: 29.92%\n","Accuracy on the test set: 30.83%\n","Accuracy on the test set: 31.28%\n","Accuracy on the test set: 31.28%\n","Accuracy on the test set: 32.03%\n","Accuracy on the test set: 29.92%\n","Accuracy on the test set: 31.88%\n","Accuracy on the test set: 30.83%\n","Accuracy on the test set: 31.88%\n","Accuracy on the test set: 31.73%\n","Accuracy on the test set: 31.28%\n","Accuracy on the test set: 33.38%\n","Accuracy on the test set: 32.63%\n","Accuracy on the test set: 33.23%\n","Accuracy on the test set: 32.78%\n","Accuracy on the test set: 31.28%\n","Accuracy on the test set: 32.03%\n","Accuracy on the test set: 32.33%\n","Accuracy on the test set: 35.19%\n","Accuracy on the test set: 33.38%\n","Accuracy on the test set: 33.38%\n","Accuracy on the test set: 33.53%\n","Accuracy on the test set: 34.44%\n","Accuracy on the test set: 34.29%\n","Accuracy on the test set: 33.38%\n","Accuracy on the test set: 34.44%\n","Accuracy on the test set: 33.53%\n","Accuracy on the test set: 33.98%\n","Accuracy on the test set: 34.29%\n","Accuracy on the test set: 34.29%\n","Accuracy on the test set: 33.08%\n","Accuracy on the test set: 34.74%\n","Accuracy on the test set: 33.83%\n","Accuracy on the test set: 34.74%\n","Accuracy on the test set: 33.08%\n","Accuracy on the test set: 33.53%\n","Accuracy on the test set: 34.74%\n","Accuracy on the test set: 35.49%\n","Accuracy on the test set: 32.48%\n","Accuracy on the test set: 33.83%\n","Accuracy on the test set: 35.49%\n","Accuracy on the test set: 34.29%\n","Accuracy on the test set: 34.59%\n","Accuracy on the test set: 33.68%\n","Accuracy on the test set: 35.19%\n","Accuracy on the test set: 35.64%\n","Accuracy on the test set: 33.83%\n","Accuracy on the test set: 35.19%\n","Accuracy on the test set: 33.83%\n","Accuracy on the test set: 34.59%\n","Accuracy on the test set: 33.23%\n","Accuracy on the test set: 35.94%\n","Accuracy on the test set: 33.98%\n","Accuracy on the test set: 33.98%\n","Accuracy on the test set: 34.44%\n","Accuracy on the test set: 35.64%\n","Accuracy on the test set: 33.83%\n","Accuracy on the test set: 35.19%\n","Accuracy on the test set: 33.98%\n","Accuracy on the test set: 33.38%\n","Accuracy on the test set: 34.74%\n","Accuracy on the test set: 35.19%\n","Accuracy on the test set: 33.53%\n","Accuracy on the test set: 34.74%\n","Accuracy on the test set: 35.04%\n","Accuracy on the test set: 35.94%\n","Accuracy on the test set: 35.34%\n","Accuracy on the test set: 34.74%\n","Accuracy on the test set: 34.59%\n","Accuracy on the test set: 34.29%\n","Accuracy on the test set: 34.74%\n","Accuracy on the test set: 35.64%\n","Accuracy on the test set: 34.89%\n","Accuracy on the test set: 34.89%\n","Accuracy on the test set: 35.34%\n","Accuracy on the test set: 35.34%\n","Epoch: 100, Training Loss: 0.90 Acc: 10.05\n","Accuracy on the test set: 35.64%\n","Epoch [100/99], Test Loss: 1.50249183177948\n","Accuracy on the test set: 35.04%\n","Accuracy on the test set: 34.89%\n","Accuracy on the test set: 34.59%\n","Accuracy on the test set: 35.19%\n","Accuracy on the test set: 35.64%\n","Accuracy on the test set: 36.09%\n","Accuracy on the test set: 36.69%\n","Accuracy on the test set: 36.39%\n","Accuracy on the test set: 36.54%\n","Accuracy on the test set: 36.24%\n","Accuracy on the test set: 36.09%\n","Accuracy on the test set: 35.79%\n","Accuracy on the test set: 35.49%\n","Accuracy on the test set: 35.34%\n","Accuracy on the test set: 35.94%\n","Accuracy on the test set: 36.54%\n","Accuracy on the test set: 35.79%\n","Accuracy on the test set: 36.69%\n","Accuracy on the test set: 37.29%\n","Accuracy on the test set: 36.54%\n","Accuracy on the test set: 36.84%\n","Accuracy on the test set: 36.54%\n","Accuracy on the test set: 36.24%\n","Accuracy on the test set: 35.79%\n","Accuracy on the test set: 35.79%\n","Accuracy on the test set: 37.14%\n","Accuracy on the test set: 36.39%\n","Accuracy on the test set: 36.09%\n","Accuracy on the test set: 36.69%\n","Accuracy on the test set: 36.09%\n","Accuracy on the test set: 37.14%\n","Accuracy on the test set: 38.05%\n","Accuracy on the test set: 36.54%\n","Accuracy on the test set: 37.44%\n","Accuracy on the test set: 36.69%\n","Accuracy on the test set: 36.39%\n","Accuracy on the test set: 37.29%\n","Accuracy on the test set: 36.39%\n","Accuracy on the test set: 36.69%\n","Accuracy on the test set: 36.24%\n","Accuracy on the test set: 37.44%\n","Accuracy on the test set: 37.29%\n","Accuracy on the test set: 36.39%\n","Accuracy on the test set: 37.29%\n","Accuracy on the test set: 36.24%\n","Accuracy on the test set: 37.14%\n","Accuracy on the test set: 35.79%\n","Accuracy on the test set: 36.84%\n","Accuracy on the test set: 35.79%\n","Accuracy on the test set: 36.54%\n","Accuracy on the test set: 36.69%\n","Accuracy on the test set: 35.79%\n","Accuracy on the test set: 36.39%\n","Accuracy on the test set: 35.49%\n","Accuracy on the test set: 36.24%\n","Accuracy on the test set: 36.99%\n","Accuracy on the test set: 37.59%\n","Accuracy on the test set: 36.24%\n","Accuracy on the test set: 35.64%\n","Accuracy on the test set: 36.54%\n","Accuracy on the test set: 36.54%\n","Accuracy on the test set: 35.04%\n","Accuracy on the test set: 35.04%\n","Accuracy on the test set: 35.79%\n","Accuracy on the test set: 36.54%\n","Accuracy on the test set: 36.39%\n","Accuracy on the test set: 34.44%\n","Accuracy on the test set: 35.79%\n","Accuracy on the test set: 36.39%\n","Accuracy on the test set: 36.09%\n","Accuracy on the test set: 36.24%\n","Accuracy on the test set: 37.14%\n","Best acc achieved:  0.3804511278195489\n"]}]},{"cell_type":"markdown","source":["## Regression Neural Network"],"metadata":{"id":"wF89uiJWRIcf"}},{"cell_type":"code","source":["# Hyperparameters\n","input_size = X_train.shape[1]\n","hidden_size = 100\n","# num_classes = torch.unique(ys).shape[0]\n","learning_rate = 1e-5\n","batch_size = 16\n","epochs = 2000"],"metadata":{"id":"SUqIgNipWaOk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: a standard neural network with 3 fully connected layers for regression\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class RegressionNet(nn.Module):\n","    def __init__(self, input_size):\n","        super(RegressionNet, self).__init__()\n","        self.nn = nn.Sequential(\n","            nn.Linear(input_size, hidden_size ),\n","            nn.LeakyReLU(),\n","            nn.Linear(hidden_size , hidden_size // 2),\n","            # nn.Dropout(0.5),\n","            nn.LeakyReLU(),\n","            nn.Linear(hidden_size // 2, hidden_size // 4),\n","            # nn.Dropout(0.5),\n","            nn.LeakyReLU(),\n","            nn.Linear(hidden_size // 4, 1)\n","            )\n","        self.init_weights()\n","\n","    def init_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Linear):\n","                torch.nn.init.xavier_uniform_(m.weight)\n","                if m.bias is not None:\n","                    m.bias.data.fill_(0)\n","\n","    def forward(self, x):\n","        return self.nn(x).squeeze()"],"metadata":{"id":"BLy5JoRbWSI0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n","patience_counter = 0\n","best_model = None\n","best_accuracy = None\n","model = RegressionNet(Xs.shape[1])\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","for epoch in range(epochs):\n","  epoch_msg = True\n","  training_total_loss = 0.0\n","  num_of_batches = len(train_loader)\n","  for X_train_batch, y_train_batch in train_loader:\n","    model.train()\n","    # Forward pass\n","    outputs = model(X_train_batch)\n","    loss = criterion(outputs, y_train_batch)\n","    training_total_loss += loss.item()\n","    # Backward and optimize\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","  if epoch == 0 or (epoch + 1) % 3 == 0:\n","    print(f'Epoch: {epoch + 1}, Training Loss: {training_total_loss/num_of_batches:.2f}')\n","\n","  # Testing the model\n","  model.eval()\n","  with torch.no_grad():\n","    outputs = model(X_test)\n","    loss = criterion(outputs, y_test)\n","    if best_accuracy is None or loss.item() < best_accuracy:\n","      best_accuracy = loss.item()\n","      best_model = model\n","      patience_counter = 0\n","    else:\n","      patience_counter += 1\n","    if epoch_msg and (epoch + 1) % 100 == 0:\n","      epoch_msg = False\n","      print(f'Epoch [{epoch + 1}/{epochs}], Test Loss: {loss.item()}')\n","      # print(f'Loss on the test set: {loss.item()}')\n","  if patience_counter >= cfg.patience:\n","    print(\"Best loss achieved: \", best_accuracy)\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"55RGrtO-XZuG","executionInfo":{"status":"ok","timestamp":1718555665698,"user_tz":-480,"elapsed":44353,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"outputId":"9f7ba27d-9f5e-4e2d-c906-55c672327e32"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 1, Training Loss: 1.05\n","Epoch: 3, Training Loss: 1.04\n","Epoch: 6, Training Loss: 1.03\n","Epoch: 9, Training Loss: 1.02\n","Epoch: 12, Training Loss: 1.01\n","Epoch: 15, Training Loss: 1.00\n","Epoch: 18, Training Loss: 1.00\n","Epoch: 21, Training Loss: 0.99\n","Epoch: 24, Training Loss: 0.98\n","Epoch: 27, Training Loss: 0.98\n","Epoch: 30, Training Loss: 0.97\n","Epoch: 33, Training Loss: 0.97\n","Epoch: 36, Training Loss: 0.96\n","Epoch: 39, Training Loss: 0.95\n","Epoch: 42, Training Loss: 0.95\n","Epoch: 45, Training Loss: 0.94\n","Epoch: 48, Training Loss: 0.94\n","Epoch: 51, Training Loss: 0.93\n","Epoch: 54, Training Loss: 0.93\n","Epoch: 57, Training Loss: 0.93\n","Epoch: 60, Training Loss: 0.92\n","Epoch: 63, Training Loss: 0.92\n","Epoch: 66, Training Loss: 0.91\n","Epoch: 69, Training Loss: 0.91\n","Epoch: 72, Training Loss: 0.91\n","Epoch: 75, Training Loss: 0.90\n","Epoch: 78, Training Loss: 0.90\n","Epoch: 81, Training Loss: 0.89\n","Epoch: 84, Training Loss: 0.89\n","Epoch: 87, Training Loss: 0.89\n","Epoch: 90, Training Loss: 0.88\n","Epoch: 93, Training Loss: 0.88\n","Epoch: 96, Training Loss: 0.88\n","Epoch: 99, Training Loss: 0.87\n","Epoch [100/2000], Test Loss: 0.8358848094940186\n","Epoch: 102, Training Loss: 0.87\n","Epoch: 105, Training Loss: 0.87\n","Epoch: 108, Training Loss: 0.86\n","Epoch: 111, Training Loss: 0.86\n","Epoch: 114, Training Loss: 0.85\n","Epoch: 117, Training Loss: 0.85\n","Epoch: 120, Training Loss: 0.85\n","Epoch: 123, Training Loss: 0.84\n","Epoch: 126, Training Loss: 0.84\n","Epoch: 129, Training Loss: 0.84\n","Epoch: 132, Training Loss: 0.83\n","Epoch: 135, Training Loss: 0.83\n","Epoch: 138, Training Loss: 0.83\n","Epoch: 141, Training Loss: 0.82\n","Epoch: 144, Training Loss: 0.82\n","Epoch: 147, Training Loss: 0.82\n","Epoch: 150, Training Loss: 0.81\n","Epoch: 153, Training Loss: 0.81\n","Epoch: 156, Training Loss: 0.81\n","Epoch: 159, Training Loss: 0.80\n","Epoch: 162, Training Loss: 0.80\n","Epoch: 165, Training Loss: 0.80\n","Epoch: 168, Training Loss: 0.79\n","Epoch: 171, Training Loss: 0.79\n","Epoch: 174, Training Loss: 0.79\n","Epoch: 177, Training Loss: 0.78\n","Epoch: 180, Training Loss: 0.78\n","Epoch: 183, Training Loss: 0.78\n","Epoch: 186, Training Loss: 0.77\n","Epoch: 189, Training Loss: 0.77\n","Epoch: 192, Training Loss: 0.77\n","Epoch: 195, Training Loss: 0.76\n","Epoch: 198, Training Loss: 0.76\n","Epoch [200/2000], Test Loss: 0.8233303427696228\n","Epoch: 201, Training Loss: 0.76\n","Epoch: 204, Training Loss: 0.75\n","Epoch: 207, Training Loss: 0.75\n","Epoch: 210, Training Loss: 0.75\n","Epoch: 213, Training Loss: 0.74\n","Epoch: 216, Training Loss: 0.74\n","Epoch: 219, Training Loss: 0.74\n","Epoch: 222, Training Loss: 0.74\n","Epoch: 225, Training Loss: 0.73\n","Epoch: 228, Training Loss: 0.73\n","Epoch: 231, Training Loss: 0.73\n","Epoch: 234, Training Loss: 0.72\n","Epoch: 237, Training Loss: 0.72\n","Epoch: 240, Training Loss: 0.72\n","Epoch: 243, Training Loss: 0.72\n","Epoch: 246, Training Loss: 0.71\n","Epoch: 249, Training Loss: 0.71\n","Epoch: 252, Training Loss: 0.71\n","Epoch: 255, Training Loss: 0.70\n","Epoch: 258, Training Loss: 0.70\n","Epoch: 261, Training Loss: 0.70\n","Epoch: 264, Training Loss: 0.69\n","Epoch: 267, Training Loss: 0.69\n","Epoch: 270, Training Loss: 0.69\n","Epoch: 273, Training Loss: 0.69\n","Epoch: 276, Training Loss: 0.68\n","Epoch: 279, Training Loss: 0.68\n","Epoch: 282, Training Loss: 0.68\n","Epoch: 285, Training Loss: 0.68\n","Best loss achieved:  0.819346010684967\n"]}]}],"metadata":{"colab":{"machine_shape":"hm","toc_visible":true,"provenance":[],"collapsed_sections":["oaKz8Ns3mG4q","EOEnGkKnmG4s"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}