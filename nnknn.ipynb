{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install omegaconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive \n",
    "drive.mount(\"/content/drive/\")\n",
    "folder_name = \"/content/drive/My Drive/NN-kNN/\"\n",
    "import sys\n",
    "sys.path.insert(0,folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_name = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "from dataset import cls_small_data as Cdata\n",
    "import model.cls_model as Cmodel\n",
    "\n",
    "from dataset import reg_data as Rdata\n",
    "import model.reg_model as Rmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_file = OmegaConf.load(os.path.join(folder_name, 'config.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCA and LMNN setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install metric-learn\n",
    "import metric_learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supported small dataset for classification:  \n",
    "'zebra',\n",
    "'zebra_special',\n",
    "'bal',\n",
    "'digits',\n",
    "'iris',\n",
    "'wine',\n",
    "'breast_cancer'\n",
    "\n",
    "for regression:\n",
    "'califonia_housing', \n",
    "'abalone', \n",
    "'diabets', \n",
    "'body_fat',\n",
    "'ziweifaces'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'califonia_housing'\n",
    "cfg = conf_file['dataset'][dataset_name]\n",
    "\n",
    "if dataset_name in ['zebra','zebra_special','bal','digits','iris','wine','breast_cancer']:\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    Xs, ys = Cdata.Cls_small_data(dataset_name)\n",
    "else:\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    Xs, ys = Rdata.Reg_data(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is used to reload the imported module. For example, if you made any changes in the model.cls_model, you should run importlib.reload(Cmodel) as long as you set import model.cls_model as Cmodel.\n",
    "# import importlib\n",
    "# importlib.reload(Rmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with NNKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cls(X_train,y_train, X_test, y_test, cfg:DictConfig):\n",
    "  X_train = X_train.to(device)\n",
    "  y_train = y_train.to(device)\n",
    "  X_test = X_test.to(device)\n",
    "\n",
    "  train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train, y_train), batch_size=cfg.batch_size, shuffle=True)\n",
    "\n",
    "  # Train model\n",
    "  model = Cmodel.NN_k_NN(X_train,\n",
    "                         y_train,\n",
    "                         cfg.ca_weight_sharing,\n",
    "                         cfg.top_case_enabled,\n",
    "                         cfg.top_k,\n",
    "                         cfg.discount,\n",
    "                         device=device)\n",
    "  \n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=cfg.learning_rate) #, weight_decay=1e-5)\n",
    "\n",
    "  patience_counter = 0\n",
    "  for epoch in range(cfg.training_epochs):\n",
    "    epoch_msg = True\n",
    "    \n",
    "    for X_train_batch, y_train_batch in train_loader:\n",
    "      model.train()\n",
    "      _, _, output, predicted_class = model(X_train_batch)\n",
    "      loss = criterion(output, y_train_batch)\n",
    "\n",
    "      # Backward and optimize\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      if epoch_msg and (epoch + 1) % 2 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{cfg.training_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "        epoch_msg = False\n",
    "      # print(\"evaluating\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      _, _, output, predicted_class = model(X_test)\n",
    "\n",
    "      # Calculate accuracy\n",
    "      accuracy_temp = accuracy_score(y_test.numpy(), predicted_class.cpu().numpy())\n",
    "    if epoch == 0:\n",
    "      best_accuracy = accuracy_temp\n",
    "      torch.save(model.state_dict(), cfg.PATH)\n",
    "      \n",
    "    elif accuracy_temp > best_accuracy:\n",
    "      #memorize best model\n",
    "      torch.save(model.state_dict(), cfg.PATH)\n",
    "      best_accuracy = accuracy_temp\n",
    "      patience_counter = 0\n",
    "\n",
    "    elif patience_counter > cfg.patience:\n",
    "      model.eval()\n",
    "      print(\"patience exceeded, loading best model\")\n",
    "      break\n",
    "    else:\n",
    "      patience_counter += 1\n",
    "  \n",
    "  return best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "knn_accuracies = []\n",
    "lmnn_accuracies = []\n",
    "PATH = os.path.join(folder_name, f'checkpoints/classifier_{dataset_name}.h5')\n",
    "cfg.PATH = PATH\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state = None)\n",
    "\n",
    "for train_index, test_index in k_fold.split(Xs):\n",
    "  # Get training and testing data\n",
    "  X_train, X_test = Xs[train_index], Xs[test_index]\n",
    "  y_train, y_test = ys[train_index], ys[test_index]\n",
    "\n",
    "  # https://contrib.scikit-learn.org/metric-learn/supervised.html#lmnn\n",
    "  lmnn = LMNN(n_neighbors=5, learn_rate=1e-6)\n",
    "  ##TODO, change here if you need to use a different one\n",
    "  # lmnn = metric_learn.MLKR()\n",
    "  # lmnn = metric_learn.NCA(max_iter=1000)\n",
    "  lmnn.fit(X_train,y_train)\n",
    "  knn = KNeighborsClassifier(n_neighbors=5,metric=lmnn.get_metric())\n",
    "  knn.fit(X_train,y_train)\n",
    "  # klmnn_accuracies.append( accuracy_score(knn.predict(X_test), y_test))\n",
    "  lmnn_acc = accuracy_score(knn.predict(X_test), y_test)\n",
    "  lmnn_accuracies.append(lmnn_acc)\n",
    "\n",
    "  knn =  KNeighborsClassifier(n_neighbors=cfg.top_k)\n",
    "  knn.fit(X_train, y_train)\n",
    "  knn_acc  = accuracy_score(knn.predict(X_test), y_test)\n",
    "  knn_accuracies.append(knn_acc)\n",
    "\n",
    "  best_accuracy = train_cls(X_train,y_train, X_test, y_test, cfg)\n",
    "  accuracies.append(best_accuracy)\n",
    "\n",
    "print(f\"Average accuracy:{np.mean(accuracies):.3f}\")\n",
    "print(f\"KNN accuracy:{np.mean(knn_accuracies):.3f}\")\n",
    "print(f\"LMNN/NCA accuracy:{np.mean(lmnn_accuracies):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with NNKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_reg(X_train,y_train, X_test, y_test, cfg:DictConfig):\n",
    "  X_train = X_train.to(device)\n",
    "  y_train = y_train.to(device)\n",
    "  X_test = X_test.to(device)\n",
    "\n",
    "  train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train, y_train), batch_size=cfg.batch_size, shuffle=True)\n",
    "  test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_test, y_test), batch_size=cfg.batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "    # Train model\n",
    "  model = Rmodel.NN_k_NN_regression(X_train, \n",
    "                                    y_train,\n",
    "                                    cfg.ca_weight_sharing,\n",
    "                                    cfg.top_case_enabled, \n",
    "                                    cfg.top_k,\n",
    "                                    cfg.discount,\n",
    "                                    cfg.class_weight_sharing,\n",
    "                                    device=device)\n",
    "    \n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=cfg.learning_rate) #, weight_decay=1e-5)\n",
    "\n",
    "  patience_counter = 0\n",
    "  for epoch in range(cfg.training_epochs):\n",
    "    # break # no training\n",
    "    epoch_msg = True\n",
    "    for X_train_batch, y_train_batch in train_loader:\n",
    "      model.train()\n",
    "      _, _, _, predicted_number = model(X_train_batch)\n",
    "      # break\n",
    "      loss = criterion(predicted_number.squeeze(), y_train_batch)\n",
    "      # Backward and optimize\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      if epoch_msg and (epoch + 1) % 2 == 0:\n",
    "        epoch_msg = False\n",
    "        print(f'Epoch [{epoch + 1}/{cfg.training_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      predicted_numbers = []\n",
    "      for X_test_batch, _ in test_loader:\n",
    "        X_test_batch = X_test_batch.to(device)\n",
    "        _, _, _, predicted_number = model(X_test_batch)\n",
    "        predicted_numbers.extend(predicted_number.squeeze().cpu().detach())\n",
    "      \n",
    "      predicted_numbers = torch.Tensor(predicted_numbers)\n",
    "      accuracy_temp = criterion(y_test, predicted_numbers)\n",
    "\n",
    "    if epoch == 0:\n",
    "      best_accuracy = accuracy_temp\n",
    "      torch.save(model.state_dict(), cfg.PATH)\n",
    "    elif accuracy_temp < best_accuracy:\n",
    "      torch.save(model.state_dict(), cfg.PATH)\n",
    "      best_accuracy = accuracy_temp\n",
    "      patience_counter = 0\n",
    "    elif patience_counter > cfg.patience:\n",
    "      model.eval()\n",
    "      print(\"patience exceeded, loading best model\")\n",
    "      break\n",
    "    else:\n",
    "      patience_counter += 1    \n",
    "\n",
    "  _, case_activations, _, predicted_number = model(X_test)\n",
    "\n",
    "  top_case_indices = torch.topk(case_activations, 5, dim=1)[1].cpu()\n",
    "\n",
    "  accuracy = criterion(y_test, predicted_number.squeeze().cpu())\n",
    "  y_train = y_train.cpu()\n",
    "  top_k_average_accuracy = mean_squared_error(torch.mean(y_train[top_case_indices], dim=1), y_test)\n",
    "      \n",
    "  return best_accuracy, accuracy, top_k_average_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracies = []\n",
    "accuracies = []\n",
    "top_k_average_accuracies = []\n",
    "knn_accuracies = []\n",
    "PATH = os.path.join(folder_name, f'checkpoints/regression_{dataset_name}.h5')\n",
    "cfg.PATH = PATH\n",
    "k_fold = KFold(n_splits=10, shuffle = True,random_state = None)\n",
    "\n",
    "\n",
    "for train_index, test_index in k_fold.split(Xs):\n",
    "  # Get training and testing data\n",
    "  X_train, X_test = Xs[train_index], Xs[test_index]\n",
    "  y_train, y_test = ys[train_index], ys[test_index]\n",
    "\n",
    "  knn = KNeighborsRegressor(n_neighbors=cfg.top_k)\n",
    "  knn.fit(X_train, y_train)\n",
    "  knn_accuracies.append(mean_squared_error(knn.predict(X_test), y_test))\n",
    "\n",
    "  best_accuracy, accuracy, top_k_average_accuracy = train_reg(X_train, y_train, X_test, y_test, cfg)\n",
    "  best_accuracies.append(best_accuracy)\n",
    "  accuracies.append(accuracy)\n",
    "  top_k_average_accuracies.append(top_k_average_accuracy)\n",
    "\n",
    "print(\"Average accuracy:\", np.mean([acc.detach().numpy() for acc in accuracies]))\n",
    "print(\"Average top_k_average_accuracies\", np.mean(top_k_average_accuracies))\n",
    "print(\"KNN accuracy:\", np.mean(knn_accuracies))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
