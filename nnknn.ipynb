{"cells":[{"cell_type":"markdown","metadata":{"id":"rxoHWNZEmG4g"},"source":["# Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T3Y5CLhymG4l","executionInfo":{"status":"ok","timestamp":1717578006306,"user_tz":-480,"elapsed":16547,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"outputId":"0211e237-4387-420e-b395-f28ebefdb1e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (2.3.0)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf) (4.9.3)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf) (6.0.1)\n"]}],"source":["!pip install omegaconf"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BxzI25zfmG4n","executionInfo":{"status":"ok","timestamp":1717578010369,"user_tz":-480,"elapsed":4071,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"outputId":"68e8e4c7-89d9-46c6-a4a5-262bc46efb4d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive/\")\n","#\"/content/drive/My Drive/NN-kNN/\"\n","folder_name = \"/content/drive/Othercomputers/My MacBook Pro/GitHub/NN-kNN/\"\n","import sys\n","sys.path.insert(0,folder_name)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"joYfU4jLmG4o","executionInfo":{"status":"ok","timestamp":1717578010369,"user_tz":-480,"elapsed":6,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["# folder_name = os.getcwd()"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"oDGrACwVmG4o","executionInfo":{"status":"ok","timestamp":1717578018685,"user_tz":-480,"elapsed":8320,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["import torch\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import accuracy_score\n","from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n","from sklearn.metrics import mean_squared_error\n","from tqdm import tqdm\n","from omegaconf import DictConfig, OmegaConf\n","\n","from dataset import cls_small_data as Cdata\n","import model.cls_model as Cmodel\n","\n","from dataset import reg_data as Rdata\n","import model.reg_model as Rmodel"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"bzTxZZJnmG4p","executionInfo":{"status":"ok","timestamp":1717578018685,"user_tz":-480,"elapsed":7,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["conf_file = OmegaConf.load(os.path.join(folder_name, 'config.yaml'))"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"yT3W4iqSmG4p","executionInfo":{"status":"ok","timestamp":1717578018686,"user_tz":-480,"elapsed":6,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"oaKz8Ns3mG4q"},"source":["# NCA and LMNN setup"]},{"cell_type":"code","source":["pip install metric-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cWQ8I6icoU8X","executionInfo":{"status":"ok","timestamp":1717578073856,"user_tz":-480,"elapsed":11990,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"outputId":"e476f727-eea3-4f86-907f-229732ed25ce"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting metric-learn\n","  Downloading metric_learn-0.7.0-py2.py3-none-any.whl (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from metric-learn) (1.25.2)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from metric-learn) (1.11.4)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from metric-learn) (1.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->metric-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->metric-learn) (3.5.0)\n","Installing collected packages: metric-learn\n","Successfully installed metric-learn-0.7.0\n"]}]},{"cell_type":"code","execution_count":14,"metadata":{"id":"zmjbXrjQmG4q","executionInfo":{"status":"ok","timestamp":1717578369801,"user_tz":-480,"elapsed":724,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["import metric_learn\n","from metric_learn import LMNN,NCA\n"]},{"cell_type":"markdown","metadata":{"id":"46TjfSz-mG4q"},"source":["# Data Sets"]},{"cell_type":"markdown","metadata":{"id":"ZkDrsvjWmG4r"},"source":["Supported small dataset for classification:  \n","'zebra',\n","'zebra_special',\n","'bal',\n","'digits',\n","'iris',\n","'wine',\n","'breast_cancer'\n","\n","for regression:\n","'califonia_housing',\n","'abalone',\n","'diabets',\n","'body_fat',\n","'ziweifaces'"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"lxq-FY3FmG4r","executionInfo":{"status":"ok","timestamp":1717578095550,"user_tz":-480,"elapsed":7,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["dataset_name = 'iris'\n","cfg = conf_file['dataset'][dataset_name]\n","\n","if dataset_name in ['zebra','zebra_special','bal','digits','iris','wine','breast_cancer']:\n","    criterion = torch.nn.CrossEntropyLoss()\n","    Xs, ys = Cdata.Cls_small_data(dataset_name)\n","else:\n","    criterion = torch.nn.MSELoss()\n","    Xs, ys = Rdata.Reg_data(dataset_name)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"aOIbeEfEmG4s","executionInfo":{"status":"ok","timestamp":1717578095551,"user_tz":-480,"elapsed":5,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["# This section is used to reload the imported module. For example, if you made any changes in the model.cls_model, you should run importlib.reload(Cmodel) as long as you set import model.cls_model as Cmodel.\n","# import importlib\n","# importlib.reload(Rmodel)"]},{"cell_type":"markdown","metadata":{"id":"EOEnGkKnmG4s"},"source":["# Classification with NNKNN"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"xOraZstjmG4t","executionInfo":{"status":"ok","timestamp":1717578189738,"user_tz":-480,"elapsed":664,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["def train_cls(X_train,y_train, X_test, y_test, cfg:DictConfig):\n","  X_train = X_train.to(device)\n","  y_train = y_train.to(device)\n","  X_test = X_test.to(device)\n","\n","  train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train, y_train), batch_size=cfg.batch_size, shuffle=True)\n","\n","  # Train model\n","  model = Cmodel.NN_k_NN(X_train,\n","                         y_train,\n","                         cfg.ca_weight_sharing,\n","                         cfg.top_case_enabled,\n","                         cfg.top_k,\n","                         cfg.discount,\n","                         device=device)\n","\n","  optimizer = torch.optim.Adam(model.parameters(), lr=cfg.learning_rate) #, weight_decay=1e-5)\n","\n","  patience_counter = 0\n","  for epoch in range(cfg.training_epochs):\n","    epoch_msg = True\n","\n","    for X_train_batch, y_train_batch in train_loader:\n","      model.train()\n","      _, _, output, predicted_class = model(X_train_batch)\n","      loss = criterion(output, y_train_batch)\n","\n","      # Backward and optimize\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","      if epoch_msg and (epoch + 1) % 2 == 0:\n","        print(f'Epoch [{epoch + 1}/{cfg.training_epochs}], Loss: {loss.item():.4f}')\n","\n","        epoch_msg = False\n","      # print(\"evaluating\")\n","    model.eval()\n","    with torch.no_grad():\n","      _, _, output, predicted_class = model(X_test)\n","\n","      # Calculate accuracy\n","      accuracy_temp = accuracy_score(y_test.numpy(), predicted_class.cpu().numpy())\n","    if epoch == 0:\n","      best_accuracy = accuracy_temp\n","      torch.save(model.state_dict(), cfg.PATH)\n","\n","    elif accuracy_temp > best_accuracy:\n","      #memorize best model\n","      torch.save(model.state_dict(), cfg.PATH)\n","      best_accuracy = accuracy_temp\n","      patience_counter = 0\n","\n","    elif patience_counter > cfg.patience:\n","      model.eval()\n","      print(\"patience exceeded, loading best model\")\n","      break\n","    else:\n","      patience_counter += 1\n","\n","  return best_accuracy"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qPIxfcO-mG4t","executionInfo":{"status":"ok","timestamp":1717578475713,"user_tz":-480,"elapsed":25933,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"outputId":"f7966f69-c465-4c1c-880d-ff2f043e9904"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [2/1000], Loss: 0.3428\n","Epoch [4/1000], Loss: 0.2811\n","Epoch [6/1000], Loss: 0.2185\n","Epoch [8/1000], Loss: 0.0736\n","Epoch [10/1000], Loss: 0.2367\n","Epoch [12/1000], Loss: 0.2208\n","Epoch [14/1000], Loss: 0.2154\n","Epoch [16/1000], Loss: 0.2150\n","Epoch [18/1000], Loss: 0.1926\n","Epoch [20/1000], Loss: 0.2087\n","Epoch [22/1000], Loss: 0.1000\n","Epoch [24/1000], Loss: 0.1901\n","Epoch [26/1000], Loss: 0.1813\n","Epoch [28/1000], Loss: 0.1840\n","Epoch [30/1000], Loss: 0.1175\n","Epoch [32/1000], Loss: 0.1864\n","Epoch [34/1000], Loss: 0.1628\n","Epoch [36/1000], Loss: 0.1632\n","Epoch [38/1000], Loss: 0.0354\n","Epoch [40/1000], Loss: 0.1679\n","Epoch [42/1000], Loss: 0.1447\n","patience exceeded, loading best model\n","Epoch [2/1000], Loss: 0.1837\n","Epoch [4/1000], Loss: 0.3332\n","Epoch [6/1000], Loss: 0.2200\n","Epoch [8/1000], Loss: 0.2068\n","Epoch [10/1000], Loss: 0.2167\n","Epoch [12/1000], Loss: 0.1971\n","Epoch [14/1000], Loss: 0.2321\n","Epoch [16/1000], Loss: 0.1294\n","Epoch [18/1000], Loss: 0.1253\n","Epoch [20/1000], Loss: 0.1478\n","Epoch [22/1000], Loss: 0.1882\n","Epoch [24/1000], Loss: 0.1741\n","Epoch [26/1000], Loss: 0.2169\n","Epoch [28/1000], Loss: 0.1705\n","Epoch [30/1000], Loss: 0.1942\n","Epoch [32/1000], Loss: 0.0513\n","Epoch [34/1000], Loss: 0.2125\n","Epoch [36/1000], Loss: 0.1820\n","Epoch [38/1000], Loss: 0.1992\n","Epoch [40/1000], Loss: 0.0844\n","Epoch [42/1000], Loss: 0.0849\n","patience exceeded, loading best model\n","Epoch [2/1000], Loss: 0.2767\n","Epoch [4/1000], Loss: 0.1925\n","Epoch [6/1000], Loss: 0.2152\n","Epoch [8/1000], Loss: 0.0614\n","Epoch [10/1000], Loss: 0.1963\n","Epoch [12/1000], Loss: 0.0901\n","Epoch [14/1000], Loss: 0.1441\n","Epoch [16/1000], Loss: 0.0906\n","Epoch [18/1000], Loss: 0.0759\n","Epoch [20/1000], Loss: 0.1534\n","Epoch [22/1000], Loss: 0.0474\n","Epoch [24/1000], Loss: 0.1451\n","Epoch [26/1000], Loss: 0.0230\n","Epoch [28/1000], Loss: 0.1310\n","Epoch [30/1000], Loss: 0.1152\n","Epoch [32/1000], Loss: 0.1089\n","Epoch [34/1000], Loss: 0.1217\n","Epoch [36/1000], Loss: 0.0914\n","Epoch [38/1000], Loss: 0.0899\n","Epoch [40/1000], Loss: 0.1101\n","Epoch [42/1000], Loss: 0.0947\n","patience exceeded, loading best model\n","Epoch [2/1000], Loss: 0.4184\n","Epoch [4/1000], Loss: 0.2826\n","Epoch [6/1000], Loss: 0.2883\n","Epoch [8/1000], Loss: 0.2578\n","Epoch [10/1000], Loss: 0.2872\n","Epoch [12/1000], Loss: 0.2774\n","Epoch [14/1000], Loss: 0.1697\n","Epoch [16/1000], Loss: 0.1955\n","Epoch [18/1000], Loss: 0.2010\n","Epoch [20/1000], Loss: 0.2011\n","Epoch [22/1000], Loss: 0.1144\n","Epoch [24/1000], Loss: 0.1208\n","Epoch [26/1000], Loss: 0.2356\n","Epoch [28/1000], Loss: 0.2354\n","Epoch [30/1000], Loss: 0.1555\n","Epoch [32/1000], Loss: 0.2193\n","Epoch [34/1000], Loss: 0.1190\n","Epoch [36/1000], Loss: 0.2058\n","Epoch [38/1000], Loss: 0.1105\n","Epoch [40/1000], Loss: 0.1437\n","Epoch [42/1000], Loss: 0.0323\n","patience exceeded, loading best model\n","Epoch [2/1000], Loss: 0.3757\n","Epoch [4/1000], Loss: 0.3240\n","Epoch [6/1000], Loss: 0.2533\n","Epoch [8/1000], Loss: 0.2179\n","Epoch [10/1000], Loss: 0.2649\n","Epoch [12/1000], Loss: 0.1949\n","Epoch [14/1000], Loss: 0.2419\n","Epoch [16/1000], Loss: 0.1625\n","Epoch [18/1000], Loss: 0.1820\n","Epoch [20/1000], Loss: 0.2366\n","Epoch [22/1000], Loss: 0.2255\n","Epoch [24/1000], Loss: 0.1547\n","Epoch [26/1000], Loss: 0.1968\n","Epoch [28/1000], Loss: 0.1279\n","Epoch [30/1000], Loss: 0.1548\n","Epoch [32/1000], Loss: 0.1145\n","Epoch [34/1000], Loss: 0.1309\n","Epoch [36/1000], Loss: 0.1328\n","Epoch [38/1000], Loss: 0.0692\n","Epoch [40/1000], Loss: 0.0829\n","Epoch [42/1000], Loss: 0.1157\n","patience exceeded, loading best model\n","Epoch [2/1000], Loss: 0.5061\n","Epoch [4/1000], Loss: 0.3213\n","Epoch [6/1000], Loss: 0.1281\n","Epoch [8/1000], Loss: 0.3091\n","Epoch [10/1000], Loss: 0.1195\n","Epoch [12/1000], Loss: 0.2087\n","Epoch [14/1000], Loss: 0.2439\n","Epoch [16/1000], Loss: 0.1497\n","Epoch [18/1000], Loss: 0.1918\n","Epoch [20/1000], Loss: 0.1512\n","Epoch [22/1000], Loss: 0.1623\n","Epoch [24/1000], Loss: 0.2240\n","Epoch [26/1000], Loss: 0.0698\n","Epoch [28/1000], Loss: 0.1773\n","Epoch [30/1000], Loss: 0.1873\n","Epoch [32/1000], Loss: 0.1778\n","Epoch [34/1000], Loss: 0.1833\n","Epoch [36/1000], Loss: 0.0671\n","Epoch [38/1000], Loss: 0.0987\n","Epoch [40/1000], Loss: 0.1135\n","Epoch [42/1000], Loss: 0.1498\n","patience exceeded, loading best model\n","Epoch [2/1000], Loss: 0.3183\n","Epoch [4/1000], Loss: 0.2612\n","Epoch [6/1000], Loss: 0.0580\n","Epoch [8/1000], Loss: 0.2102\n","Epoch [10/1000], Loss: 0.1460\n","Epoch [12/1000], Loss: 0.1857\n","Epoch [14/1000], Loss: 0.1420\n","Epoch [16/1000], Loss: 0.1256\n","Epoch [18/1000], Loss: 0.1039\n","Epoch [20/1000], Loss: 0.1578\n","Epoch [22/1000], Loss: 0.1425\n","Epoch [24/1000], Loss: 0.1483\n","Epoch [26/1000], Loss: 0.1467\n","Epoch [28/1000], Loss: 0.1074\n","Epoch [30/1000], Loss: 0.1184\n","Epoch [32/1000], Loss: 0.1130\n","Epoch [34/1000], Loss: 0.1310\n","Epoch [36/1000], Loss: 0.1257\n","Epoch [38/1000], Loss: 0.1037\n","Epoch [40/1000], Loss: 0.0927\n","Epoch [42/1000], Loss: 0.0741\n","patience exceeded, loading best model\n","Epoch [2/1000], Loss: 0.3789\n","Epoch [4/1000], Loss: 0.1161\n","Epoch [6/1000], Loss: 0.1541\n","Epoch [8/1000], Loss: 0.2727\n","Epoch [10/1000], Loss: 0.2501\n","Epoch [12/1000], Loss: 0.1207\n","Epoch [14/1000], Loss: 0.2238\n","Epoch [16/1000], Loss: 0.1255\n","Epoch [18/1000], Loss: 0.1479\n","Epoch [20/1000], Loss: 0.2092\n","Epoch [22/1000], Loss: 0.2248\n","Epoch [24/1000], Loss: 0.2131\n","Epoch [26/1000], Loss: 0.2221\n","Epoch [28/1000], Loss: 0.2013\n","Epoch [30/1000], Loss: 0.1332\n","Epoch [32/1000], Loss: 0.1084\n","Epoch [34/1000], Loss: 0.0845\n","Epoch [36/1000], Loss: 0.1796\n","Epoch [38/1000], Loss: 0.1423\n","Epoch [40/1000], Loss: 0.1837\n","Epoch [42/1000], Loss: 0.1499\n","patience exceeded, loading best model\n","Epoch [2/1000], Loss: 0.2959\n","Epoch [4/1000], Loss: 0.2886\n","Epoch [6/1000], Loss: 0.1425\n","Epoch [8/1000], Loss: 0.2755\n","Epoch [10/1000], Loss: 0.1882\n","Epoch [12/1000], Loss: 0.2446\n","Epoch [14/1000], Loss: 0.2135\n","Epoch [16/1000], Loss: 0.1856\n","Epoch [18/1000], Loss: 0.2393\n","Epoch [20/1000], Loss: 0.1801\n","Epoch [22/1000], Loss: 0.1465\n","Epoch [24/1000], Loss: 0.1010\n","Epoch [26/1000], Loss: 0.0974\n","Epoch [28/1000], Loss: 0.0622\n","Epoch [30/1000], Loss: 0.2134\n","Epoch [32/1000], Loss: 0.2059\n","Epoch [34/1000], Loss: 0.1703\n","Epoch [36/1000], Loss: 0.1785\n","Epoch [38/1000], Loss: 0.0674\n","Epoch [40/1000], Loss: 0.1866\n","Epoch [42/1000], Loss: 0.1557\n","patience exceeded, loading best model\n","Epoch [2/1000], Loss: 0.2827\n","Epoch [4/1000], Loss: 0.3397\n","Epoch [6/1000], Loss: 0.0960\n","Epoch [8/1000], Loss: 0.2775\n","Epoch [10/1000], Loss: 0.2895\n","Epoch [12/1000], Loss: 0.2953\n","Epoch [14/1000], Loss: 0.2479\n","Epoch [16/1000], Loss: 0.1459\n","Epoch [18/1000], Loss: 0.1439\n","Epoch [20/1000], Loss: 0.2022\n","Epoch [22/1000], Loss: 0.2466\n","Epoch [24/1000], Loss: 0.2517\n","Epoch [26/1000], Loss: 0.2457\n","Epoch [28/1000], Loss: 0.2442\n","Epoch [30/1000], Loss: 0.2312\n","Epoch [32/1000], Loss: 0.1951\n","Epoch [34/1000], Loss: 0.1443\n","Epoch [36/1000], Loss: 0.1678\n","Epoch [38/1000], Loss: 0.1548\n","Epoch [40/1000], Loss: 0.0887\n","Epoch [42/1000], Loss: 0.1519\n","patience exceeded, loading best model\n","Average accuracy:0.967\n","KNN accuracy:0.967\n","LMNN/NCA accuracy:0.960\n"]}],"source":["accuracies = []\n","knn_accuracies = []\n","lmnn_accuracies = []\n","PATH = os.path.join(folder_name, f'checkpoints/classifier_{dataset_name}.h5')\n","cfg.PATH = PATH\n","k_fold = KFold(n_splits=10, shuffle=True, random_state = None)\n","\n","for train_index, test_index in k_fold.split(Xs):\n","  # Get training and testing data\n","  X_train, X_test = Xs[train_index], Xs[test_index]\n","  y_train, y_test = ys[train_index], ys[test_index]\n","\n","  # https://contrib.scikit-learn.org/metric-learn/supervised.html#lmnn\n","  lmnn = LMNN(n_neighbors=5, learn_rate=1e-6)\n","  ##TODO, change here if you need to use a different one\n","  # lmnn = metric_learn.MLKR()\n","  # lmnn = metric_learn.NCA(max_iter=1000)\n","  lmnn.fit(X_train,y_train)\n","  knn = KNeighborsClassifier(n_neighbors=5,metric=lmnn.get_metric())\n","  knn.fit(X_train,y_train)\n","  # klmnn_accuracies.append( accuracy_score(knn.predict(X_test), y_test))\n","  lmnn_acc = accuracy_score(knn.predict(X_test), y_test)\n","  lmnn_accuracies.append(lmnn_acc)\n","\n","  knn =  KNeighborsClassifier(n_neighbors=cfg.top_k)\n","  knn.fit(X_train, y_train)\n","  knn_acc  = accuracy_score(knn.predict(X_test), y_test)\n","  knn_accuracies.append(knn_acc)\n","\n","  best_accuracy = train_cls(X_train,y_train, X_test, y_test, cfg)\n","  accuracies.append(best_accuracy)\n","\n","print(f\"Average accuracy:{np.mean(accuracies):.3f}\")\n","print(f\"KNN accuracy:{np.mean(knn_accuracies):.3f}\")\n","print(f\"LMNN/NCA accuracy:{np.mean(lmnn_accuracies):.3f}\")\n"]},{"cell_type":"markdown","metadata":{"id":"QVO3SDp9mG4u"},"source":["# Regression with NNKNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ll4n1HNmG4u"},"outputs":[],"source":["def train_reg(X_train,y_train, X_test, y_test, cfg:DictConfig):\n","  X_train = X_train.to(device)\n","  y_train = y_train.to(device)\n","  X_test = X_test.to(device)\n","\n","  train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train, y_train), batch_size=cfg.batch_size, shuffle=True)\n","  test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_test, y_test), batch_size=cfg.batch_size, shuffle=False)\n","\n","\n","    # Train model\n","  model = Rmodel.NN_k_NN_regression(X_train,\n","                                    y_train,\n","                                    cfg.ca_weight_sharing,\n","                                    cfg.top_case_enabled,\n","                                    cfg.top_k,\n","                                    cfg.discount,\n","                                    cfg.class_weight_sharing,\n","                                    device=device)\n","\n","  optimizer = torch.optim.Adam(model.parameters(), lr=cfg.learning_rate) #, weight_decay=1e-5)\n","\n","  patience_counter = 0\n","  for epoch in range(cfg.training_epochs):\n","    # break # no training\n","    epoch_msg = True\n","    for X_train_batch, y_train_batch in train_loader:\n","      model.train()\n","      _, _, _, predicted_number = model(X_train_batch)\n","      # break\n","      loss = criterion(predicted_number.squeeze(), y_train_batch)\n","      # Backward and optimize\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","      if epoch_msg and (epoch + 1) % 2 == 0:\n","        epoch_msg = False\n","        print(f'Epoch [{epoch + 1}/{cfg.training_epochs}], Loss: {loss.item():.4f}')\n","\n","    model.eval()\n","    with torch.no_grad():\n","      predicted_numbers = []\n","      for X_test_batch, _ in test_loader:\n","        X_test_batch = X_test_batch.to(device)\n","        _, _, _, predicted_number = model(X_test_batch)\n","        predicted_numbers.extend(predicted_number.squeeze().cpu().detach())\n","\n","      predicted_numbers = torch.Tensor(predicted_numbers)\n","      accuracy_temp = criterion(y_test, predicted_numbers)\n","\n","    if epoch == 0:\n","      best_accuracy = accuracy_temp\n","      torch.save(model.state_dict(), cfg.PATH)\n","    elif accuracy_temp < best_accuracy:\n","      torch.save(model.state_dict(), cfg.PATH)\n","      best_accuracy = accuracy_temp\n","      patience_counter = 0\n","    elif patience_counter > cfg.patience:\n","      model.eval()\n","      print(\"patience exceeded, loading best model\")\n","      break\n","    else:\n","      patience_counter += 1\n","\n","  _, case_activations, _, predicted_number = model(X_test)\n","\n","  top_case_indices = torch.topk(case_activations, 5, dim=1)[1].cpu()\n","\n","  accuracy = criterion(y_test, predicted_number.squeeze().cpu())\n","  y_train = y_train.cpu()\n","  top_k_average_accuracy = mean_squared_error(torch.mean(y_train[top_case_indices], dim=1), y_test)\n","\n","  return best_accuracy, accuracy, top_k_average_accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DN8UlUVpmG4v"},"outputs":[],"source":["best_accuracies = []\n","accuracies = []\n","top_k_average_accuracies = []\n","knn_accuracies = []\n","PATH = os.path.join(folder_name, f'checkpoints/regression_{dataset_name}.h5')\n","cfg.PATH = PATH\n","k_fold = KFold(n_splits=10, shuffle = True,random_state = None)\n","\n","\n","for train_index, test_index in k_fold.split(Xs):\n","  # Get training and testing data\n","  X_train, X_test = Xs[train_index], Xs[test_index]\n","  y_train, y_test = ys[train_index], ys[test_index]\n","\n","  knn = KNeighborsRegressor(n_neighbors=cfg.top_k)\n","  knn.fit(X_train, y_train)\n","  knn_accuracies.append(mean_squared_error(knn.predict(X_test), y_test))\n","\n","  best_accuracy, accuracy, top_k_average_accuracy = train_reg(X_train, y_train, X_test, y_test, cfg)\n","  best_accuracies.append(best_accuracy)\n","  accuracies.append(accuracy)\n","  top_k_average_accuracies.append(top_k_average_accuracy)\n","\n","print(\"Average accuracy:\", np.mean([acc.detach().numpy() for acc in accuracies]))\n","print(\"Average top_k_average_accuracies\", np.mean(top_k_average_accuracies))\n","print(\"KNN accuracy:\", np.mean(knn_accuracies))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}