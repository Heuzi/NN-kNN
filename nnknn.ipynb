{"cells":[{"cell_type":"markdown","metadata":{"id":"rxoHWNZEmG4g"},"source":["# Setup"]},{"cell_type":"markdown","source":["On google colab, you have to restart runtime after running the following line"],"metadata":{"id":"CsfLxAVaPOTf"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T3Y5CLhymG4l","executionInfo":{"status":"ok","timestamp":1718006287964,"user_tz":-480,"elapsed":6961,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"outputId":"af0a5383-83db-4489-b46a-73d642cf6e64"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (2.3.0)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf) (4.9.3)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf) (6.0.1)\n"]}],"source":["!pip install omegaconf"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BxzI25zfmG4n","executionInfo":{"status":"ok","timestamp":1718006290330,"user_tz":-480,"elapsed":2370,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"outputId":"5f897cb0-e9d5-4415-d30b-20b43851ba2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive/\")\n","#\"/content/drive/My Drive/NN-kNN/\"\n","folder_name = \"/content/drive/Othercomputers/My MacBook Pro/GitHub/NN-kNN/\"\n","import sys\n","sys.path.insert(0,folder_name)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"joYfU4jLmG4o","executionInfo":{"status":"ok","timestamp":1718006290330,"user_tz":-480,"elapsed":3,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["# folder_name = os.getcwd()"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"oDGrACwVmG4o","executionInfo":{"status":"ok","timestamp":1718006307716,"user_tz":-480,"elapsed":17388,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["import torch\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import accuracy_score\n","from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n","from sklearn.metrics import mean_squared_error\n","from tqdm import tqdm\n","from omegaconf import DictConfig, OmegaConf\n","\n","from dataset import cls_small_data as Cdata\n","import model.cls_model as Cmodel\n","from dataset import cls_medium_data\n","\n","from dataset import reg_data as Rdata\n","import model.reg_model as Rmodel"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"bzTxZZJnmG4p","executionInfo":{"status":"ok","timestamp":1718006307716,"user_tz":-480,"elapsed":14,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["conf_file = OmegaConf.load(os.path.join(folder_name, 'config.yaml'))"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"yT3W4iqSmG4p","executionInfo":{"status":"ok","timestamp":1718006307716,"user_tz":-480,"elapsed":13,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"oaKz8Ns3mG4q"},"source":["# NCA and LMNN setup"]},{"cell_type":"code","source":["pip install metric-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cWQ8I6icoU8X","executionInfo":{"status":"ok","timestamp":1718006312002,"user_tz":-480,"elapsed":4299,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"outputId":"ceee2ecb-5e6b-4bc8-80a3-507be4a2ea2a"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: metric-learn in /usr/local/lib/python3.10/dist-packages (0.7.0)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from metric-learn) (1.25.2)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from metric-learn) (1.11.4)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from metric-learn) (1.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->metric-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->metric-learn) (3.5.0)\n"]}]},{"cell_type":"code","execution_count":8,"metadata":{"id":"zmjbXrjQmG4q","executionInfo":{"status":"ok","timestamp":1718006312002,"user_tz":-480,"elapsed":5,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["import metric_learn\n","from metric_learn import LMNN,NCA"]},{"cell_type":"markdown","metadata":{"id":"46TjfSz-mG4q"},"source":["# Data Sets"]},{"cell_type":"markdown","metadata":{"id":"ZkDrsvjWmG4r"},"source":["Supported small dataset for classification:  \n","'zebra',\n","'zebra_special',\n","'bal',\n","'digits',\n","'iris',\n","'wine',\n","'breast_cancer',\n","\n","for regression:\n","'califonia_housing',\n","'abalone',\n","'diabets',\n","'body_fat',\n","'ziweifaces'\n","\n","\n","Newly added data sets for mental health (psychology):\n","\n","Classification:\n","'psych_depression_physical_symptons',\n","'covid_anxious',\n","'covid_depressed'\n"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":634},"id":"lxq-FY3FmG4r","executionInfo":{"status":"error","timestamp":1718009512649,"user_tz":-480,"elapsed":12311,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"outputId":"62b5946c-e796-4e3d-a0ee-6fd6417c56c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Columns in the dataset: Index(['SU_ID', 'P_PANEL', 'NATIONAL_WEIGHT', 'REGION_WEIGHT',\n","       'NATIONAL_WEIGHT_POP', 'REGION_WEIGHT_POP', 'NAT_WGT_COMB_POP',\n","       'REG_WGT_COMB_POP', 'P_GEO', 'SOC1',\n","       ...\n","       'REGION9', 'P_DENSE', 'MODE', 'LANGUAGE', 'MAIL50', 'RACE1_BANNER',\n","       'RACE2_BANNER', 'INC_BANNER', 'AGE_BANNER', 'HH_BANNER'],\n","      dtype='object', length=177)\n","tensor([[14.,  2.,  2.,  ...,  3.,  2.,  5.],\n","        [10.,  1.,  3.,  ...,  1.,  1.,  4.],\n","        [17.,  3.,  5.,  ...,  0.,  3.,  1.],\n","        ...,\n","        [ 8.,  3.,  2.,  ...,  3.,  2.,  2.],\n","        [15.,  2.,  3.,  ...,  3.,  2.,  5.],\n","        [ 1.,  2.,  1.,  ...,  1.,  2.,  1.]])\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"Could not infer dtype of builtin_function_or_method","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-621c6d159a6b>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                     'zebra','zebra_special','bal','digits','iris','wine','breast_cancer']:\n\u001b[1;32m      6\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCls_small_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/Othercomputers/My MacBook Pro/GitHub/NN-kNN/dataset/cls_small_data.py\u001b[0m in \u001b[0;36mCls_small_data\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m    342\u001b[0m }\n\u001b[1;32m    343\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mCls_small_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m     \u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDATATYPES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/Othercomputers/My MacBook Pro/GitHub/NN-kNN/dataset/cls_small_data.py\u001b[0m in \u001b[0;36mcovid_depressed\u001b[0;34m()\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcovid_depressed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcovid_soc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SOC5B'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcovid_lonely\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/Othercomputers/My MacBook Pro/GitHub/NN-kNN/dataset/cls_small_data.py\u001b[0m in \u001b[0;36mcovid_soc\u001b[0;34m(target)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;31m# ys = ys[:num_train]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m     \u001b[0mXs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m     \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Could not infer dtype of builtin_function_or_method"]}],"source":["dataset_name = 'covid_depressed'\n","cfg = conf_file['dataset'][dataset_name]\n","\n","if dataset_name in ['covid_depressed','covid_anxious','psych_depression_physical_symptons',\n","                    'zebra','zebra_special','bal','digits','iris','wine','breast_cancer']:\n","    criterion = torch.nn.CrossEntropyLoss()\n","    Xs, ys = Cdata.Cls_small_data(dataset_name)\n","elif dataset_name in []:\n","    criterion = torch.nn.CrossEntropyLoss()\n","    Xs, ys = cls_medium_data.Cls_medium_data(dataset_name)\n","else:\n","    criterion = torch.nn.MSELoss()\n","    Xs, ys = Rdata.Reg_data(dataset_name)"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aOIbeEfEmG4s","executionInfo":{"status":"ok","timestamp":1718009499247,"user_tz":-480,"elapsed":3,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"outputId":"1958c2a2-1fe9-417f-824a-5da688915a71"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<module 'dataset.cls_small_data' from '/content/drive/Othercomputers/My MacBook Pro/GitHub/NN-kNN/dataset/cls_small_data.py'>"]},"metadata":{},"execution_count":25}],"source":["# This section is used to reload the imported module.\n","# For example, if you made any changes in the model.cls_model, you should run importlib.reload(Cmodel) as long as you set import model.cls_model as Cmodel.\n","import importlib\n","importlib.reload(Cdata)"]},{"cell_type":"markdown","metadata":{"id":"EOEnGkKnmG4s"},"source":["# Classification with NNKNN"]},{"cell_type":"code","source":["# prompt: get the unique y values and their counts\n","\n","unique_values, counts = np.unique(ys, return_counts=True)\n","print(f\"Unique values: {unique_values}\")\n","print(f\"Counts: {counts}\")\n","print(f\"Xs.size(): {Xs.size()}\")\n"],"metadata":{"id":"fisqdp27w9fg","executionInfo":{"status":"aborted","timestamp":1718009157369,"user_tz":-480,"elapsed":2,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":11,"metadata":{"id":"xOraZstjmG4t","executionInfo":{"status":"ok","timestamp":1718006021601,"user_tz":-480,"elapsed":25,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["def train_cls(X_train,y_train, X_test, y_test, cfg:DictConfig):\n","  X_train = X_train.to(device)\n","  y_train = y_train.to(device)\n","  X_test = X_test.to(device)\n","\n","  train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train, y_train), batch_size=cfg.batch_size, shuffle=True)\n","\n","  # Train model\n","  model = Cmodel.NN_k_NN(X_train,\n","                         y_train,\n","                         cfg.ca_weight_sharing,\n","                         cfg.top_case_enabled,\n","                         cfg.top_k,\n","                         cfg.discount,\n","                         device=device)\n","\n","  optimizer = torch.optim.Adam(model.parameters(), lr=cfg.learning_rate) #, weight_decay=1e-5)\n","\n","  patience_counter = 0\n","  for epoch in range(cfg.training_epochs):\n","    epoch_msg = True\n","\n","    for X_train_batch, y_train_batch in train_loader:\n","      model.train()\n","      _, _, output, predicted_class = model(X_train_batch)\n","      loss = criterion(output, y_train_batch)\n","\n","      # Backward and optimize\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","      if epoch_msg and (epoch + 1) % 2 == 0:\n","        print(f'Epoch [{epoch + 1}/{cfg.training_epochs}], Loss: {loss.item():.4f}')\n","\n","        epoch_msg = False\n","      # print(\"evaluating\")\n","    model.eval()\n","    with torch.no_grad():\n","      _, _, output, predicted_class = model(X_test)\n","\n","      # Calculate accuracy\n","      accuracy_temp = accuracy_score(y_test.numpy(), predicted_class.cpu().numpy())\n","    if epoch == 0:\n","      best_accuracy = accuracy_temp\n","      torch.save(model.state_dict(), cfg.PATH)\n","\n","    elif accuracy_temp > best_accuracy:\n","      #memorize best model\n","      torch.save(model.state_dict(), cfg.PATH)\n","      best_accuracy = accuracy_temp\n","      patience_counter = 0\n","\n","    elif patience_counter > cfg.patience:\n","      model.eval()\n","      print(\"patience exceeded, loading best model\")\n","      break\n","    else:\n","      patience_counter += 1\n","\n","  return best_accuracy, model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qPIxfcO-mG4t"},"outputs":[],"source":["accuracies = []\n","knn_accuracies = []\n","lmnn_accuracies = []\n","PATH = os.path.join(folder_name, f'checkpoints/classifier_{dataset_name}.h5')\n","cfg.PATH = PATH\n","k_fold = KFold(n_splits=10, shuffle=True, random_state = None)\n","enable_lmnn = True\n","\n","for train_index, test_index in k_fold.split(Xs):\n","  # Get training and testing data\n","  X_train, X_test = Xs[train_index], Xs[test_index]\n","  y_train, y_test = ys[train_index], ys[test_index]\n","  if(enable_lmnn):\n","    # https://contrib.scikit-learn.org/metric-learn/supervised.html#lmnn\n","    lmnn = LMNN(n_neighbors=5, learn_rate=1e-6)\n","    ##TODO, change here if you need to use a different one\n","    # lmnn = metric_learn.MLKR()\n","    # lmnn = metric_learn.NCA(max_iter=1000)\n","    lmnn.fit(X_train,y_train)\n","    knn = KNeighborsClassifier(n_neighbors=5,metric=lmnn.get_metric())\n","    knn.fit(X_train,y_train)\n","    # klmnn_accuracies.append( accuracy_score(knn.predict(X_test), y_test))\n","    lmnn_acc = accuracy_score(knn.predict(X_test), y_test)\n","    lmnn_accuracies.append(lmnn_acc)\n","\n","  knn =  KNeighborsClassifier(n_neighbors=cfg.top_k)\n","  knn.fit(X_train, y_train)\n","  knn_acc  = accuracy_score(knn.predict(X_test), y_test)\n","  knn_accuracies.append(knn_acc)\n","\n","  best_accuracy, model = train_cls(X_train,y_train, X_test, y_test, cfg)\n","  accuracies.append(best_accuracy)\n","\n","print(f\"Average accuracy:{np.mean(accuracies):.3f}\")\n","print(f\"KNN accuracy:{np.mean(knn_accuracies):.3f}\")\n","print(f\"LMNN/NCA accuracy:{np.mean(lmnn_accuracies):.3f}\")\n"]},{"cell_type":"markdown","metadata":{"id":"QVO3SDp9mG4u"},"source":["# Regression with NNKNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ll4n1HNmG4u"},"outputs":[],"source":["def train_reg(X_train,y_train, X_test, y_test, cfg:DictConfig):\n","  X_train = X_train.to(device)\n","  y_train = y_train.to(device)\n","  X_test = X_test.to(device)\n","\n","  train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train, y_train), batch_size=cfg.batch_size, shuffle=True)\n","  test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_test, y_test), batch_size=cfg.batch_size, shuffle=False)\n","\n","\n","    # Train model\n","  model = Rmodel.NN_k_NN_regression(X_train,\n","                                    y_train,\n","                                    cfg.ca_weight_sharing,\n","                                    cfg.top_case_enabled,\n","                                    cfg.top_k,\n","                                    cfg.discount,\n","                                    cfg.class_weight_sharing,\n","                                    device=device)\n","\n","  optimizer = torch.optim.Adam(model.parameters(), lr=cfg.learning_rate) #, weight_decay=1e-5)\n","\n","  patience_counter = 0\n","  for epoch in range(cfg.training_epochs):\n","    # break # no training\n","    epoch_msg = True\n","    for X_train_batch, y_train_batch in train_loader:\n","      model.train()\n","      _, _, _, predicted_number = model(X_train_batch)\n","      # break\n","      loss = criterion(predicted_number.squeeze(), y_train_batch)\n","      # Backward and optimize\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","      if epoch_msg and (epoch + 1) % 2 == 0:\n","        epoch_msg = False\n","        print(f'Epoch [{epoch + 1}/{cfg.training_epochs}], Loss: {loss.item():.4f}')\n","\n","    model.eval()\n","    with torch.no_grad():\n","      predicted_numbers = []\n","      for X_test_batch, _ in test_loader:\n","        X_test_batch = X_test_batch.to(device)\n","        _, _, _, predicted_number = model(X_test_batch)\n","        predicted_numbers.extend(predicted_number.squeeze().cpu().detach())\n","\n","      predicted_numbers = torch.Tensor(predicted_numbers)\n","      accuracy_temp = criterion(y_test, predicted_numbers)\n","\n","    if epoch == 0:\n","      best_accuracy = accuracy_temp\n","      torch.save(model.state_dict(), cfg.PATH)\n","    elif accuracy_temp < best_accuracy:\n","      torch.save(model.state_dict(), cfg.PATH)\n","      best_accuracy = accuracy_temp\n","      patience_counter = 0\n","    elif patience_counter > cfg.patience:\n","      model.eval()\n","      print(\"patience exceeded, loading best model\")\n","      break\n","    else:\n","      patience_counter += 1\n","\n","  _, case_activations, _, predicted_number = model(X_test)\n","\n","  top_case_indices = torch.topk(case_activations, 5, dim=1)[1].cpu()\n","\n","  accuracy = criterion(y_test, predicted_number.squeeze().cpu())\n","  y_train = y_train.cpu()\n","  top_k_average_accuracy = mean_squared_error(torch.mean(y_train[top_case_indices], dim=1), y_test)\n","\n","  return best_accuracy, accuracy, top_k_average_accuracy, model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DN8UlUVpmG4v"},"outputs":[],"source":["best_accuracies = []\n","accuracies = []\n","top_k_average_accuracies = []\n","knn_accuracies = []\n","PATH = os.path.join(folder_name, f'checkpoints/regression_{dataset_name}.h5')\n","cfg.PATH = PATH\n","k_fold = KFold(n_splits=10, shuffle = True,random_state = None)\n","\n","\n","for train_index, test_index in k_fold.split(Xs):\n","  # Get training and testing data\n","  X_train, X_test = Xs[train_index], Xs[test_index]\n","  y_train, y_test = ys[train_index], ys[test_index]\n","\n","  knn = KNeighborsRegressor(n_neighbors=cfg.top_k)\n","  knn.fit(X_train, y_train)\n","  knn_accuracies.append(mean_squared_error(knn.predict(X_test), y_test))\n","\n","  best_accuracy, accuracy, top_k_average_accuracy, model= train_reg(X_train, y_train, X_test, y_test, cfg)\n","  best_accuracies.append(best_accuracy)\n","  accuracies.append(accuracy)\n","  top_k_average_accuracies.append(top_k_average_accuracy)\n","\n","print(\"Average accuracy:\", np.mean([acc.detach().numpy() for acc in accuracies]))\n","print(\"Average top_k_average_accuracies\", np.mean(top_k_average_accuracies))\n","print(\"KNN accuracy:\", np.mean(knn_accuracies))"]},{"cell_type":"markdown","source":["# Results Interpretation"],"metadata":{"id":"aQMTPXLwaBVq"}},{"cell_type":"code","source":["def print_model_features(input_model):\n","  for n, p in model.named_parameters():\n","    print(n)\n","    print(p.data)"],"metadata":{"id":"sf23mP1UaIvx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print_model_features(model)"],"metadata":{"id":"MRO3tUPEbJUs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for regression only. for classification is different\n","#feature_activations, case_activations, predicted_number\n","model.eval()\n","feature_activations, case_activations, output, predicted_class = model(X_test)"],"metadata":{"id":"PkxAqSoldjML"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predicted_class"],"metadata":{"id":"PtwGRyMjeXtp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_test"],"metadata":{"id":"EvY5_WGkeaxg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#inspecting the case activations\n","top_case_indices = torch.topk(case_activations, 5, dim=1)[1]"],"metadata":{"id":"hjaUAY7Bkjyr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test[0]"],"metadata":{"id":"tfi-PKhokmev"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train[top_case_indices[0][0]]"],"metadata":{"id":"73NQbeJ_kpO_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["By comparing the following two blocks' outputs, you can see we are retrieving a good neighbor."],"metadata":{"id":"xMePSTR1lXbb"}},{"cell_type":"code","source":["#sum abs of X_test[0] and the top activated case\n","sum(abs(X_test[0] - X_train[top_case_indices[0][0]]))"],"metadata":{"id":"0izuKF6okrsc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: average sum abs of X_test[0] and X_train data\n","print(np.mean([sum(abs(X_test[0] - X_train[i])) for i in range(len(X_train))]))"],"metadata":{"id":"faYClHOVktuW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["TODO:: A better way is to show the distribution of ``X_test[0] - X_train[i]``"],"metadata":{"id":"zkYKvaP-lz_0"}},{"cell_type":"code","source":["y_train[top_case_indices[0]]"],"metadata":{"id":"xrwLY3gXmCLd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["knn.predict(X_test)[0]"],"metadata":{"id":"es5Kv85CmHMt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["indices = knn.kneighbors(X_test)[1][0]"],"metadata":{"id":"pxOcKMzHmJkS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train[indices]"],"metadata":{"id":"o4vuKW0rmNVi"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[],"collapsed_sections":["rxoHWNZEmG4g","oaKz8Ns3mG4q"],"machine_shape":"hm"}},"nbformat":4,"nbformat_minor":0}