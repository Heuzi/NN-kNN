{"cells":[{"cell_type":"markdown","metadata":{"id":"rxoHWNZEmG4g"},"source":["# Setup"]},{"cell_type":"markdown","source":["On google colab, you have to restart runtime after running the following line"],"metadata":{"id":"CsfLxAVaPOTf"}},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T3Y5CLhymG4l","executionInfo":{"status":"ok","timestamp":1718070259037,"user_tz":-480,"elapsed":3810,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"outputId":"65f51ac9-afdd-4495-edd3-c82ee6e5c9ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (2.3.0)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf) (4.9.3)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf) (6.0.1)\n"]}],"source":["!pip install omegaconf"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BxzI25zfmG4n","executionInfo":{"status":"ok","timestamp":1718070262714,"user_tz":-480,"elapsed":3686,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"outputId":"4c614b96-97d9-4183-ec0e-7a35aa1979ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive/\")\n","#\"/content/drive/My Drive/NN-kNN/\"\n","folder_name = \"/content/drive/Othercomputers/My MacBook Pro/GitHub/NN-kNN/\"\n","import sys\n","sys.path.insert(0,folder_name)"]},{"cell_type":"code","source":["##This is added because my Rdata uses Cdata for the covid data set.\n","##Rdata use Cdata function to load the data set, then convert it to regression problem\n","import os\n","import sys\n","sys.path.append('/content/drive/Othercomputers/My MacBook Pro/GitHub/NN-kNN/dataset')\n"],"metadata":{"id":"q-0ffsjpbDLE","executionInfo":{"status":"ok","timestamp":1718070349854,"user_tz":-480,"elapsed":651,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"joYfU4jLmG4o"},"outputs":[],"source":["# folder_name = os.getcwd()"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"oDGrACwVmG4o","executionInfo":{"status":"ok","timestamp":1718070352273,"user_tz":-480,"elapsed":624,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["import torch\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import accuracy_score\n","from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n","from sklearn.metrics import mean_squared_error\n","from tqdm import tqdm\n","from omegaconf import DictConfig, OmegaConf\n","\n","from dataset import cls_small_data as Cdata\n","import model.cls_model as Cmodel\n","from dataset import cls_medium_data\n","\n","from dataset import reg_data as Rdata\n","import model.reg_model as Rmodel"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"bzTxZZJnmG4p","executionInfo":{"status":"ok","timestamp":1718070365506,"user_tz":-480,"elapsed":1370,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["conf_file = OmegaConf.load(os.path.join(folder_name, 'config.yaml'))"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"yT3W4iqSmG4p","executionInfo":{"status":"ok","timestamp":1718070366142,"user_tz":-480,"elapsed":1,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"oaKz8Ns3mG4q"},"source":["# NCA and LMNN setup"]},{"cell_type":"code","source":["pip install metric-learn"],"metadata":{"id":"cWQ8I6icoU8X","executionInfo":{"status":"ok","timestamp":1718070373311,"user_tz":-480,"elapsed":4621,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"34d4535f-0efb-4f94-9c42-c789c83be6ee"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting metric-learn\n","  Downloading metric_learn-0.7.0-py2.py3-none-any.whl (67 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from metric-learn) (1.25.2)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from metric-learn) (1.11.4)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from metric-learn) (1.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->metric-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->metric-learn) (3.5.0)\n","Installing collected packages: metric-learn\n","Successfully installed metric-learn-0.7.0\n"]}]},{"cell_type":"code","execution_count":17,"metadata":{"id":"zmjbXrjQmG4q","executionInfo":{"status":"ok","timestamp":1718070373312,"user_tz":-480,"elapsed":6,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["import metric_learn\n","from metric_learn import LMNN,NCA"]},{"cell_type":"markdown","metadata":{"id":"46TjfSz-mG4q"},"source":["# Data Sets"]},{"cell_type":"markdown","metadata":{"id":"ZkDrsvjWmG4r"},"source":["Supported small dataset for classification:  \n","'zebra',\n","'zebra_special',\n","'bal',\n","'digits',\n","'iris',\n","'wine',\n","'breast_cancer',\n","\n","for regression:\n","'califonia_housing',\n","'abalone',\n","'diabets',\n","'body_fat',\n","'ziweifaces'\n","\n","\n","Newly added data sets for mental health (psychology):\n","\n","Classification:\n","'psych_depression_physical_symptons',\n","'covid_anxious',\n","'covid_depressed'\n"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"lxq-FY3FmG4r","executionInfo":{"status":"ok","timestamp":1718070485081,"user_tz":-480,"elapsed":12268,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d813b219-71ea-4c7c-82a7-c2eb45612290"},"outputs":[{"output_type":"stream","name":"stdout","text":["Columns in the dataset: Index(['SU_ID', 'P_PANEL', 'NATIONAL_WEIGHT', 'REGION_WEIGHT',\n","       'NATIONAL_WEIGHT_POP', 'REGION_WEIGHT_POP', 'NAT_WGT_COMB_POP',\n","       'REG_WGT_COMB_POP', 'P_GEO', 'SOC1',\n","       ...\n","       'REGION9', 'P_DENSE', 'MODE', 'LANGUAGE', 'MAIL50', 'RACE1_BANNER',\n","       'RACE2_BANNER', 'INC_BANNER', 'AGE_BANNER', 'HH_BANNER'],\n","      dtype='object', length=177)\n"]}],"source":["dataset_name = 'covid_anxious'\n","cfg = conf_file['dataset'][dataset_name]\n","\n","if dataset_name in ['covid_depressed','covid_anxious','psych_depression_physical_symptons',\n","                    'zebra','zebra_special','bal','digits','iris','wine','breast_cancer']:\n","    criterion = torch.nn.CrossEntropyLoss()\n","    Xs, ys = Cdata.Cls_small_data(dataset_name)\n","elif dataset_name in []:\n","    criterion = torch.nn.CrossEntropyLoss()\n","    Xs, ys = cls_medium_data.Cls_medium_data(dataset_name)\n","else:\n","    criterion = torch.nn.MSELoss()\n","    Xs, ys = Rdata.Reg_data(dataset_name)"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"aOIbeEfEmG4s","executionInfo":{"status":"ok","timestamp":1718070472231,"user_tz":-480,"elapsed":1,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c3b4ddf3-154c-4111-e0e8-b05735ebb7d0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<module 'dataset.cls_small_data' from '/content/drive/Othercomputers/My MacBook Pro/GitHub/NN-kNN/dataset/cls_small_data.py'>"]},"metadata":{},"execution_count":24}],"source":["# This section is used to reload the imported module.\n","# For example, if you made any changes in the model.cls_model, you should run importlib.reload(Cmodel) as long as you set import model.cls_model as Cmodel.\n","import importlib\n","importlib.reload(Cdata)"]},{"cell_type":"markdown","metadata":{"id":"EOEnGkKnmG4s"},"source":["# Classification with NNKNN"]},{"cell_type":"code","source":["# prompt: get the unique y values and their counts\n","\n","unique_values, counts = np.unique(ys, return_counts=True)\n","print(f\"Unique values: {unique_values}\")\n","print(f\"Counts: {counts}\")\n","print(f\"Xs.size(): {Xs.size()}\")\n"],"metadata":{"id":"fisqdp27w9fg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718070485082,"user_tz":-480,"elapsed":5,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"outputId":"bfe23f68-ec4e-4222-b9b6-d752de69d12b"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Unique values: [0 1 2 3]\n","Counts: [1651 1651 1651 1651]\n","Xs.size(): torch.Size([6604, 161])\n"]}]},{"cell_type":"code","execution_count":27,"metadata":{"id":"xOraZstjmG4t","executionInfo":{"status":"ok","timestamp":1718070485082,"user_tz":-480,"elapsed":3,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}}},"outputs":[],"source":["def train_cls(X_train,y_train, X_test, y_test, cfg:DictConfig):\n","  X_train = X_train.to(device)\n","  y_train = y_train.to(device)\n","  X_test = X_test.to(device)\n","\n","  train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train, y_train), batch_size=cfg.batch_size, shuffle=True)\n","\n","  # Train model\n","  model = Cmodel.NN_k_NN(X_train,\n","                         y_train,\n","                         cfg.ca_weight_sharing,\n","                         cfg.top_case_enabled,\n","                         cfg.top_k,\n","                         cfg.discount,\n","                         device=device)\n","\n","  optimizer = torch.optim.Adam(model.parameters(), lr=cfg.learning_rate) #, weight_decay=1e-5)\n","\n","  patience_counter = 0\n","  for epoch in range(cfg.training_epochs):\n","    epoch_msg = True\n","\n","    for X_train_batch, y_train_batch in train_loader:\n","      model.train()\n","      _, _, output, predicted_class = model(X_train_batch)\n","      loss = criterion(output, y_train_batch)\n","\n","      # Backward and optimize\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","      if epoch_msg and (epoch + 1) % 2 == 0:\n","        print(f'Epoch [{epoch + 1}/{cfg.training_epochs}], Loss: {loss.item():.4f}')\n","\n","        epoch_msg = False\n","      # print(\"evaluating\")\n","    model.eval()\n","    with torch.no_grad():\n","      _, _, output, predicted_class = model(X_test)\n","\n","      # Calculate accuracy\n","      accuracy_temp = accuracy_score(y_test.numpy(), predicted_class.cpu().numpy())\n","    if epoch == 0:\n","      best_accuracy = accuracy_temp\n","      torch.save(model.state_dict(), cfg.PATH)\n","\n","    elif accuracy_temp > best_accuracy:\n","      #memorize best model\n","      torch.save(model.state_dict(), cfg.PATH)\n","      best_accuracy = accuracy_temp\n","      patience_counter = 0\n","\n","    elif patience_counter > cfg.patience:\n","      model.eval()\n","      print(\"patience exceeded, loading best model\")\n","      break\n","    else:\n","      patience_counter += 1\n","\n","  return best_accuracy, model"]},{"cell_type":"code","source":["def load_model(X_train,y_train,cfg):\n","  # Define the model architecture\n","  model = Cmodel.NN_k_NN(\n","      X_train,\n","      y_train,\n","      cfg.ca_weight_sharing,\n","      cfg.top_case_enabled,\n","      cfg.top_k,\n","      cfg.discount,\n","      device=device\n","  )\n","  # Load the state dictionary\n","  model.load_state_dict(torch.load(cfg.path))\n","  model.to(device)\n","  model.eval()\n","  return model"],"metadata":{"id":"DMKsNhL3ItkK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qPIxfcO-mG4t","colab":{"base_uri":"https://localhost:8080/"},"outputId":"65c84a45-2a2c-4897-e477-f6469cc15db2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [2/1000], Loss: 1.3931\n","Epoch [4/1000], Loss: 1.3770\n","Epoch [6/1000], Loss: 1.3782\n","Epoch [8/1000], Loss: 1.3675\n","Epoch [10/1000], Loss: 1.3548\n","Epoch [12/1000], Loss: 1.3700\n","Epoch [14/1000], Loss: 1.3753\n","Epoch [16/1000], Loss: 1.3764\n","Epoch [18/1000], Loss: 1.3417\n","Epoch [20/1000], Loss: 1.3732\n","Epoch [22/1000], Loss: 1.3644\n","Epoch [24/1000], Loss: 1.3571\n","Epoch [26/1000], Loss: 1.3610\n","Epoch [28/1000], Loss: 1.3416\n","Epoch [30/1000], Loss: 1.3497\n","Epoch [32/1000], Loss: 1.3425\n","Epoch [34/1000], Loss: 1.3684\n","Epoch [36/1000], Loss: 1.3964\n","Epoch [38/1000], Loss: 1.3569\n","Epoch [40/1000], Loss: 1.3352\n","Epoch [42/1000], Loss: 1.3492\n","Epoch [44/1000], Loss: 1.3216\n","Epoch [46/1000], Loss: 1.3089\n","Epoch [48/1000], Loss: 1.3468\n","Epoch [50/1000], Loss: 1.3180\n","Epoch [52/1000], Loss: 1.3358\n","Epoch [54/1000], Loss: 1.3742\n","Epoch [56/1000], Loss: 1.3566\n","Epoch [58/1000], Loss: 1.3592\n","Epoch [60/1000], Loss: 1.3237\n","Epoch [62/1000], Loss: 1.3161\n","Epoch [64/1000], Loss: 1.3317\n","Epoch [66/1000], Loss: 1.2911\n"]}],"source":["accuracies = []\n","knn_accuracies = []\n","lmnn_accuracies = []\n","PATH = os.path.join(folder_name, f'checkpoints/classifier_{dataset_name}.h5')\n","cfg.PATH = PATH\n","k_fold = KFold(n_splits=10, shuffle=True, random_state = None)\n","enable_lmnn = True\n","\n","for train_index, test_index in k_fold.split(Xs):\n","  # Get training and testing data\n","  X_train, X_test = Xs[train_index], Xs[test_index]\n","  y_train, y_test = ys[train_index], ys[test_index]\n","  if(enable_lmnn):\n","    # https://contrib.scikit-learn.org/metric-learn/supervised.html#lmnn\n","    lmnn = LMNN(n_neighbors=5, learn_rate=1e-6)\n","    ##TODO, change here if you need to use a different one\n","    # lmnn = metric_learn.MLKR()\n","    # lmnn = metric_learn.NCA(max_iter=1000)\n","    lmnn.fit(X_train,y_train)\n","    knn = KNeighborsClassifier(n_neighbors=5,metric=lmnn.get_metric())\n","    knn.fit(X_train,y_train)\n","    # klmnn_accuracies.append( accuracy_score(knn.predict(X_test), y_test))\n","    lmnn_acc = accuracy_score(knn.predict(X_test), y_test)\n","    lmnn_accuracies.append(lmnn_acc)\n","\n","  knn =  KNeighborsClassifier(n_neighbors=cfg.top_k)\n","  knn.fit(X_train, y_train)\n","  knn_acc  = accuracy_score(knn.predict(X_test), y_test)\n","  knn_accuracies.append(knn_acc)\n","\n","  best_accuracy, model = train_cls(X_train,y_train, X_test, y_test, cfg)\n","  accuracies.append(best_accuracy)\n","\n","print(f\"Average accuracy:{np.mean(accuracies):.3f}\")\n","print(f\"KNN accuracy:{np.mean(knn_accuracies):.3f}\")\n","print(f\"LMNN/NCA accuracy:{np.mean(lmnn_accuracies):.3f}\")\n"]},{"cell_type":"markdown","metadata":{"id":"QVO3SDp9mG4u"},"source":["# Regression with NNKNN"]},{"cell_type":"code","source":["unique_values, counts = np.unique(ys, return_counts=True)\n","print(f\"Unique values: {unique_values}\")\n","print(f\"Counts: {counts}\")\n","print(f\"Xs.size(): {Xs.size()}\")"],"metadata":{"id":"x2uuoXv9ceJL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718030280321,"user_tz":-480,"elapsed":11,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"}},"outputId":"303403a7-82bf-4088-90ff-c9ab4f91ae27"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Unique values: [-1.3415393  -0.44717973  0.44717973  1.3415393 ]\n","Counts: [1651 1651 1651 1651]\n","Xs.size(): torch.Size([6604, 162])\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ll4n1HNmG4u"},"outputs":[],"source":["def train_reg(X_train,y_train, X_test, y_test, cfg:DictConfig):\n","  X_train = X_train.to(device)\n","  y_train = y_train.to(device)\n","  X_test = X_test.to(device)\n","\n","  train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train, y_train), batch_size=cfg.batch_size, shuffle=True)\n","  test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_test, y_test), batch_size=cfg.batch_size, shuffle=False)\n","\n","\n","    # Train model\n","  model = Rmodel.NN_k_NN_regression(X_train,\n","                                    y_train,\n","                                    cfg.ca_weight_sharing,\n","                                    cfg.top_case_enabled,\n","                                    cfg.top_k,\n","                                    cfg.discount,\n","                                    cfg.class_weight_sharing,\n","                                    device=device)\n","\n","  optimizer = torch.optim.Adam(model.parameters(), lr=cfg.learning_rate) #, weight_decay=1e-5)\n","\n","  patience_counter = 0\n","  for epoch in range(cfg.training_epochs):\n","    # break # no training\n","    epoch_msg = True\n","    for X_train_batch, y_train_batch in train_loader:\n","      model.train()\n","      _, _, _, predicted_number = model(X_train_batch)\n","      # break\n","      loss = criterion(predicted_number.squeeze(), y_train_batch)\n","      # Backward and optimize\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","      if epoch_msg and (epoch + 1) % 2 == 0:\n","        epoch_msg = False\n","        print(f'Epoch [{epoch + 1}/{cfg.training_epochs}], Loss: {loss.item():.4f}')\n","\n","    model.eval()\n","    with torch.no_grad():\n","      predicted_numbers = []\n","      for X_test_batch, _ in test_loader:\n","        X_test_batch = X_test_batch.to(device)\n","        _, _, _, predicted_number = model(X_test_batch)\n","        predicted_numbers.extend(predicted_number.squeeze().cpu().detach())\n","\n","      predicted_numbers = torch.Tensor(predicted_numbers)\n","      accuracy_temp = criterion(y_test, predicted_numbers)\n","\n","    if epoch == 0:\n","      best_accuracy = accuracy_temp\n","      torch.save(model.state_dict(), cfg.PATH)\n","    elif accuracy_temp < best_accuracy:\n","      torch.save(model.state_dict(), cfg.PATH)\n","      best_accuracy = accuracy_temp\n","      patience_counter = 0\n","    elif patience_counter > cfg.patience:\n","      model.eval()\n","      print(\"patience exceeded, loading best model\")\n","      break\n","    else:\n","      patience_counter += 1\n","\n","  _, case_activations, _, predicted_number = model(X_test)\n","\n","  top_case_indices = torch.topk(case_activations, 5, dim=1)[1].cpu()\n","\n","  accuracy = criterion(y_test, predicted_number.squeeze().cpu())\n","  y_train = y_train.cpu()\n","  top_k_average_accuracy = mean_squared_error(torch.mean(y_train[top_case_indices], dim=1), y_test)\n","\n","  return best_accuracy, accuracy, top_k_average_accuracy, model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DN8UlUVpmG4v","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b3559413-7cb2-41cd-de54-12c48b925881"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [2/1000], Loss: 1.1363\n","Epoch [4/1000], Loss: 1.0000\n","Epoch [6/1000], Loss: 0.9063\n","Epoch [8/1000], Loss: 0.9325\n","Epoch [10/1000], Loss: 1.0979\n","Epoch [12/1000], Loss: 1.0777\n","Epoch [14/1000], Loss: 1.0533\n","Epoch [16/1000], Loss: 1.0521\n","Epoch [18/1000], Loss: 0.9599\n","Epoch [20/1000], Loss: 1.2118\n","Epoch [22/1000], Loss: 1.0878\n","Epoch [24/1000], Loss: 1.0351\n","Epoch [26/1000], Loss: 0.9030\n","Epoch [28/1000], Loss: 0.9901\n","Epoch [30/1000], Loss: 1.0564\n","Epoch [32/1000], Loss: 1.0790\n","Epoch [34/1000], Loss: 1.1429\n","Epoch [36/1000], Loss: 1.1163\n","Epoch [38/1000], Loss: 1.1742\n","Epoch [40/1000], Loss: 0.9303\n","Epoch [42/1000], Loss: 0.8624\n","Epoch [44/1000], Loss: 0.9859\n","Epoch [46/1000], Loss: 0.9060\n","Epoch [48/1000], Loss: 0.9122\n","Epoch [50/1000], Loss: 0.9942\n","Epoch [52/1000], Loss: 0.8828\n","Epoch [54/1000], Loss: 0.8170\n","Epoch [56/1000], Loss: 0.8536\n","Epoch [58/1000], Loss: 0.9334\n","Epoch [60/1000], Loss: 1.0324\n","Epoch [62/1000], Loss: 0.8176\n","Epoch [64/1000], Loss: 0.9927\n","Epoch [66/1000], Loss: 0.9490\n","Epoch [68/1000], Loss: 0.9638\n","Epoch [70/1000], Loss: 0.9044\n","Epoch [72/1000], Loss: 0.8828\n","Epoch [74/1000], Loss: 0.9876\n","Epoch [76/1000], Loss: 0.9477\n","Epoch [78/1000], Loss: 0.9964\n","Epoch [80/1000], Loss: 1.0214\n","Epoch [82/1000], Loss: 0.9627\n","Epoch [84/1000], Loss: 0.8952\n","Epoch [86/1000], Loss: 0.9636\n","Epoch [88/1000], Loss: 1.0634\n","Epoch [90/1000], Loss: 1.0189\n","Epoch [92/1000], Loss: 1.0198\n","Epoch [94/1000], Loss: 0.9149\n","Epoch [96/1000], Loss: 0.9520\n","Epoch [98/1000], Loss: 0.8442\n","Epoch [100/1000], Loss: 0.9710\n","Epoch [102/1000], Loss: 0.8851\n","Epoch [104/1000], Loss: 0.9123\n","Epoch [106/1000], Loss: 0.9527\n","Epoch [108/1000], Loss: 1.0136\n","Epoch [110/1000], Loss: 1.0594\n","Epoch [112/1000], Loss: 0.9364\n","Epoch [114/1000], Loss: 0.9083\n","Epoch [116/1000], Loss: 0.9705\n","Epoch [118/1000], Loss: 0.9445\n","Epoch [120/1000], Loss: 0.7700\n","Epoch [122/1000], Loss: 0.9020\n","Epoch [124/1000], Loss: 0.8349\n","Epoch [126/1000], Loss: 0.9365\n","Epoch [128/1000], Loss: 0.7908\n","Epoch [130/1000], Loss: 0.9038\n","Epoch [132/1000], Loss: 0.7511\n","Epoch [134/1000], Loss: 0.9384\n","Epoch [136/1000], Loss: 0.8652\n","Epoch [138/1000], Loss: 0.8901\n","Epoch [140/1000], Loss: 0.8922\n","Epoch [142/1000], Loss: 1.0104\n","Epoch [144/1000], Loss: 0.9920\n","Epoch [146/1000], Loss: 0.8590\n","Epoch [148/1000], Loss: 0.8270\n","Epoch [150/1000], Loss: 0.9487\n","Epoch [152/1000], Loss: 0.7550\n","Epoch [154/1000], Loss: 0.8155\n","Epoch [156/1000], Loss: 0.7090\n","Epoch [158/1000], Loss: 0.8791\n","patience exceeded, loading best model\n","Epoch [2/1000], Loss: 0.9721\n","Epoch [4/1000], Loss: 0.9677\n","Epoch [6/1000], Loss: 0.9601\n","Epoch [8/1000], Loss: 1.0770\n","Epoch [10/1000], Loss: 0.9559\n","Epoch [12/1000], Loss: 0.9252\n","Epoch [14/1000], Loss: 0.9744\n","Epoch [16/1000], Loss: 0.8873\n","Epoch [18/1000], Loss: 1.0513\n","Epoch [20/1000], Loss: 0.9355\n","Epoch [22/1000], Loss: 1.1105\n","Epoch [24/1000], Loss: 0.8810\n","Epoch [26/1000], Loss: 0.9743\n","Epoch [28/1000], Loss: 1.1503\n","Epoch [30/1000], Loss: 0.8799\n","Epoch [32/1000], Loss: 0.9647\n","Epoch [34/1000], Loss: 1.0035\n","Epoch [36/1000], Loss: 0.8736\n","Epoch [38/1000], Loss: 1.0486\n","Epoch [40/1000], Loss: 1.0993\n","Epoch [42/1000], Loss: 1.0190\n","Epoch [44/1000], Loss: 0.9811\n","Epoch [46/1000], Loss: 0.9634\n","Epoch [48/1000], Loss: 0.9781\n","Epoch [50/1000], Loss: 0.8991\n","Epoch [52/1000], Loss: 0.9092\n","Epoch [54/1000], Loss: 0.7983\n","Epoch [56/1000], Loss: 0.8570\n","Epoch [58/1000], Loss: 0.8798\n","Epoch [60/1000], Loss: 1.0531\n","Epoch [62/1000], Loss: 0.9737\n","Epoch [64/1000], Loss: 0.9430\n","Epoch [66/1000], Loss: 0.9947\n","Epoch [68/1000], Loss: 0.9585\n","Epoch [70/1000], Loss: 1.0348\n","Epoch [72/1000], Loss: 0.8601\n","Epoch [74/1000], Loss: 0.9319\n","Epoch [76/1000], Loss: 0.9692\n","Epoch [78/1000], Loss: 0.9182\n","Epoch [80/1000], Loss: 0.8813\n","Epoch [82/1000], Loss: 1.0754\n","Epoch [84/1000], Loss: 0.7520\n","Epoch [86/1000], Loss: 0.9413\n","Epoch [88/1000], Loss: 0.9710\n","Epoch [90/1000], Loss: 0.9976\n","Epoch [92/1000], Loss: 0.9958\n","Epoch [94/1000], Loss: 0.9614\n","Epoch [96/1000], Loss: 0.9412\n","Epoch [98/1000], Loss: 0.7783\n","Epoch [100/1000], Loss: 0.9005\n","Epoch [102/1000], Loss: 0.8201\n","Epoch [104/1000], Loss: 0.8775\n","Epoch [106/1000], Loss: 0.8230\n","Epoch [108/1000], Loss: 0.9441\n","Epoch [110/1000], Loss: 0.8613\n","Epoch [112/1000], Loss: 0.9721\n","Epoch [114/1000], Loss: 0.8721\n","Epoch [116/1000], Loss: 0.8974\n","Epoch [118/1000], Loss: 0.8704\n","Epoch [120/1000], Loss: 0.9014\n","Epoch [122/1000], Loss: 0.9047\n","Epoch [124/1000], Loss: 0.8194\n","Epoch [126/1000], Loss: 0.8291\n","Epoch [128/1000], Loss: 0.8794\n","Epoch [130/1000], Loss: 0.8466\n","Epoch [132/1000], Loss: 0.9006\n","Epoch [134/1000], Loss: 0.8467\n","Epoch [136/1000], Loss: 0.8879\n","Epoch [138/1000], Loss: 0.8559\n","Epoch [140/1000], Loss: 1.0030\n","Epoch [142/1000], Loss: 0.9740\n","Epoch [144/1000], Loss: 0.8986\n","Epoch [146/1000], Loss: 0.8532\n","Epoch [148/1000], Loss: 0.8729\n","Epoch [150/1000], Loss: 0.8194\n","Epoch [152/1000], Loss: 0.9440\n","Epoch [154/1000], Loss: 0.9343\n","Epoch [156/1000], Loss: 0.9656\n","Epoch [158/1000], Loss: 0.9705\n","Epoch [160/1000], Loss: 0.8974\n","Epoch [162/1000], Loss: 0.8025\n","Epoch [164/1000], Loss: 0.9601\n","Epoch [166/1000], Loss: 0.9187\n","Epoch [168/1000], Loss: 0.9692\n","Epoch [170/1000], Loss: 0.8910\n","Epoch [172/1000], Loss: 0.8596\n","Epoch [174/1000], Loss: 0.9700\n","Epoch [176/1000], Loss: 0.7567\n","Epoch [178/1000], Loss: 0.9075\n","Epoch [180/1000], Loss: 0.9189\n","Epoch [182/1000], Loss: 0.8663\n","Epoch [184/1000], Loss: 0.9137\n","Epoch [186/1000], Loss: 0.9867\n","Epoch [188/1000], Loss: 0.9109\n","Epoch [190/1000], Loss: 0.8026\n","Epoch [192/1000], Loss: 1.0009\n","Epoch [194/1000], Loss: 0.7459\n","Epoch [196/1000], Loss: 0.8772\n","Epoch [198/1000], Loss: 0.9296\n","Epoch [200/1000], Loss: 0.9322\n","Epoch [202/1000], Loss: 0.9908\n","Epoch [204/1000], Loss: 0.7381\n","Epoch [206/1000], Loss: 0.8486\n","Epoch [208/1000], Loss: 1.0004\n","Epoch [210/1000], Loss: 0.9051\n","Epoch [212/1000], Loss: 0.7902\n","Epoch [214/1000], Loss: 0.7164\n","Epoch [216/1000], Loss: 0.9519\n","Epoch [218/1000], Loss: 0.7675\n","Epoch [220/1000], Loss: 0.8855\n","Epoch [222/1000], Loss: 0.8120\n","Epoch [224/1000], Loss: 0.9640\n","Epoch [226/1000], Loss: 1.0039\n","Epoch [228/1000], Loss: 0.8539\n","Epoch [230/1000], Loss: 0.7411\n","Epoch [232/1000], Loss: 1.0118\n","Epoch [234/1000], Loss: 0.7424\n","Epoch [236/1000], Loss: 0.9778\n","Epoch [238/1000], Loss: 0.9633\n","Epoch [240/1000], Loss: 0.9549\n","Epoch [242/1000], Loss: 0.8178\n","Epoch [244/1000], Loss: 0.9205\n","Epoch [246/1000], Loss: 0.9445\n","Epoch [248/1000], Loss: 0.8601\n","Epoch [250/1000], Loss: 0.7791\n","Epoch [252/1000], Loss: 0.8435\n","Epoch [254/1000], Loss: 0.8354\n","patience exceeded, loading best model\n","Epoch [2/1000], Loss: 0.8891\n","Epoch [4/1000], Loss: 1.0837\n","Epoch [6/1000], Loss: 1.1299\n","Epoch [8/1000], Loss: 1.0403\n","Epoch [10/1000], Loss: 1.0357\n","Epoch [12/1000], Loss: 1.0874\n","Epoch [14/1000], Loss: 0.8647\n","Epoch [16/1000], Loss: 0.9033\n","Epoch [18/1000], Loss: 1.0461\n","Epoch [20/1000], Loss: 1.0044\n","Epoch [22/1000], Loss: 0.8281\n","Epoch [24/1000], Loss: 0.9882\n","Epoch [26/1000], Loss: 0.9223\n","Epoch [28/1000], Loss: 1.0525\n","Epoch [30/1000], Loss: 0.8648\n","Epoch [32/1000], Loss: 0.8515\n","Epoch [34/1000], Loss: 0.9214\n","Epoch [36/1000], Loss: 0.8436\n","Epoch [38/1000], Loss: 0.8445\n","Epoch [40/1000], Loss: 0.9575\n","Epoch [42/1000], Loss: 1.0782\n","Epoch [44/1000], Loss: 0.9502\n","Epoch [46/1000], Loss: 0.8984\n","Epoch [48/1000], Loss: 0.8832\n","Epoch [50/1000], Loss: 0.9105\n","Epoch [52/1000], Loss: 0.9315\n","Epoch [54/1000], Loss: 0.8026\n","Epoch [56/1000], Loss: 0.9254\n","Epoch [58/1000], Loss: 1.0068\n","Epoch [60/1000], Loss: 0.9777\n","Epoch [62/1000], Loss: 0.9377\n","Epoch [64/1000], Loss: 0.9595\n","Epoch [66/1000], Loss: 0.9338\n","Epoch [68/1000], Loss: 0.9704\n","Epoch [70/1000], Loss: 1.0395\n","Epoch [72/1000], Loss: 0.8719\n","Epoch [74/1000], Loss: 0.8838\n","Epoch [76/1000], Loss: 0.9515\n","Epoch [78/1000], Loss: 0.8893\n","Epoch [80/1000], Loss: 0.9895\n","Epoch [82/1000], Loss: 0.9367\n","Epoch [84/1000], Loss: 0.8336\n","Epoch [86/1000], Loss: 0.8708\n","Epoch [88/1000], Loss: 0.9278\n","Epoch [90/1000], Loss: 0.8815\n","Epoch [92/1000], Loss: 1.1025\n","Epoch [94/1000], Loss: 0.7971\n","Epoch [96/1000], Loss: 0.7989\n","Epoch [98/1000], Loss: 0.9443\n","Epoch [100/1000], Loss: 1.0279\n","Epoch [102/1000], Loss: 0.8754\n","Epoch [104/1000], Loss: 0.8935\n","Epoch [106/1000], Loss: 0.9260\n","Epoch [108/1000], Loss: 1.0850\n","Epoch [110/1000], Loss: 0.9094\n","Epoch [112/1000], Loss: 1.0094\n","Epoch [114/1000], Loss: 0.8972\n","Epoch [116/1000], Loss: 0.9341\n","Epoch [118/1000], Loss: 0.8927\n","Epoch [120/1000], Loss: 0.9072\n","patience exceeded, loading best model\n","Epoch [2/1000], Loss: 0.9944\n","Epoch [4/1000], Loss: 0.9232\n","Epoch [6/1000], Loss: 0.9051\n","Epoch [8/1000], Loss: 1.0977\n","Epoch [10/1000], Loss: 0.9868\n","Epoch [12/1000], Loss: 1.0563\n","Epoch [14/1000], Loss: 0.9863\n","Epoch [16/1000], Loss: 1.0063\n","Epoch [18/1000], Loss: 1.0311\n","Epoch [20/1000], Loss: 1.1126\n","Epoch [22/1000], Loss: 0.8819\n","Epoch [24/1000], Loss: 1.0239\n","Epoch [26/1000], Loss: 0.8860\n","Epoch [28/1000], Loss: 0.8062\n","Epoch [30/1000], Loss: 0.9754\n","Epoch [32/1000], Loss: 1.0325\n","Epoch [34/1000], Loss: 0.9725\n","Epoch [36/1000], Loss: 0.9321\n","Epoch [38/1000], Loss: 0.9741\n","Epoch [40/1000], Loss: 0.9297\n","Epoch [42/1000], Loss: 0.8381\n","Epoch [44/1000], Loss: 1.0154\n","Epoch [46/1000], Loss: 0.8901\n","Epoch [48/1000], Loss: 0.9896\n","Epoch [50/1000], Loss: 0.9795\n","Epoch [52/1000], Loss: 0.9314\n","Epoch [54/1000], Loss: 1.0167\n","Epoch [56/1000], Loss: 0.9732\n","Epoch [58/1000], Loss: 1.0449\n","Epoch [60/1000], Loss: 0.8708\n","Epoch [62/1000], Loss: 0.9842\n","Epoch [64/1000], Loss: 0.9447\n","Epoch [66/1000], Loss: 0.8014\n","Epoch [68/1000], Loss: 0.9576\n","Epoch [70/1000], Loss: 0.9876\n","Epoch [72/1000], Loss: 0.9279\n","Epoch [74/1000], Loss: 1.0194\n","Epoch [76/1000], Loss: 0.8266\n","Epoch [78/1000], Loss: 0.9412\n","Epoch [80/1000], Loss: 0.9520\n","Epoch [82/1000], Loss: 0.8439\n","Epoch [84/1000], Loss: 0.8787\n","Epoch [86/1000], Loss: 0.9254\n","Epoch [88/1000], Loss: 0.9077\n","Epoch [90/1000], Loss: 0.9388\n","Epoch [92/1000], Loss: 0.9479\n","Epoch [94/1000], Loss: 0.7427\n","Epoch [96/1000], Loss: 0.9430\n","Epoch [98/1000], Loss: 0.9427\n","Epoch [100/1000], Loss: 0.8617\n","Epoch [102/1000], Loss: 1.0769\n","Epoch [104/1000], Loss: 0.9208\n","Epoch [106/1000], Loss: 0.9357\n","Epoch [108/1000], Loss: 0.9413\n","Epoch [110/1000], Loss: 0.9067\n","Epoch [112/1000], Loss: 0.8759\n","Epoch [114/1000], Loss: 0.8274\n","Epoch [116/1000], Loss: 0.9823\n","Epoch [118/1000], Loss: 0.9861\n","Epoch [120/1000], Loss: 0.8973\n","Epoch [122/1000], Loss: 1.1643\n","Epoch [124/1000], Loss: 0.8799\n","patience exceeded, loading best model\n","Epoch [2/1000], Loss: 1.0161\n","Epoch [4/1000], Loss: 1.0618\n","Epoch [6/1000], Loss: 0.9789\n","Epoch [8/1000], Loss: 0.8551\n","Epoch [10/1000], Loss: 1.1045\n","Epoch [12/1000], Loss: 0.9971\n","Epoch [14/1000], Loss: 0.9292\n","Epoch [16/1000], Loss: 1.0075\n","Epoch [18/1000], Loss: 0.9785\n","Epoch [20/1000], Loss: 0.8606\n","Epoch [22/1000], Loss: 0.9354\n","Epoch [24/1000], Loss: 0.9762\n","Epoch [26/1000], Loss: 0.9600\n","Epoch [28/1000], Loss: 0.9124\n","Epoch [30/1000], Loss: 0.9879\n","Epoch [32/1000], Loss: 0.9602\n","Epoch [34/1000], Loss: 1.0421\n","Epoch [36/1000], Loss: 1.0148\n","Epoch [38/1000], Loss: 1.0585\n","Epoch [40/1000], Loss: 0.9761\n","Epoch [42/1000], Loss: 0.8624\n","Epoch [44/1000], Loss: 0.7628\n","patience exceeded, loading best model\n","Epoch [2/1000], Loss: 0.9918\n","Epoch [4/1000], Loss: 0.9410\n","Epoch [6/1000], Loss: 1.0446\n","Epoch [8/1000], Loss: 0.9602\n","Epoch [10/1000], Loss: 0.9749\n","Epoch [12/1000], Loss: 0.9197\n","Epoch [14/1000], Loss: 0.9749\n","Epoch [16/1000], Loss: 0.7911\n","Epoch [18/1000], Loss: 0.9999\n","Epoch [20/1000], Loss: 0.7534\n","Epoch [22/1000], Loss: 0.9283\n","Epoch [24/1000], Loss: 0.9787\n","Epoch [26/1000], Loss: 0.9738\n","Epoch [28/1000], Loss: 1.0913\n","Epoch [30/1000], Loss: 0.9520\n","Epoch [32/1000], Loss: 0.8902\n","Epoch [34/1000], Loss: 0.9817\n","Epoch [36/1000], Loss: 0.9741\n","Epoch [38/1000], Loss: 0.8798\n","Epoch [40/1000], Loss: 1.0804\n","Epoch [42/1000], Loss: 1.0804\n","Epoch [44/1000], Loss: 1.0404\n","Epoch [46/1000], Loss: 1.0590\n","Epoch [48/1000], Loss: 1.0708\n","Epoch [50/1000], Loss: 0.9628\n","Epoch [52/1000], Loss: 0.8789\n","Epoch [54/1000], Loss: 1.0582\n","Epoch [56/1000], Loss: 0.9612\n","Epoch [58/1000], Loss: 1.0478\n","Epoch [60/1000], Loss: 0.9318\n","Epoch [62/1000], Loss: 1.0101\n","Epoch [64/1000], Loss: 1.0653\n","Epoch [66/1000], Loss: 0.8216\n","Epoch [68/1000], Loss: 0.9094\n","Epoch [70/1000], Loss: 0.9377\n","Epoch [72/1000], Loss: 0.8307\n","Epoch [74/1000], Loss: 1.0390\n","Epoch [76/1000], Loss: 0.9851\n","Epoch [78/1000], Loss: 0.9403\n","Epoch [80/1000], Loss: 0.8761\n","Epoch [82/1000], Loss: 0.8096\n","Epoch [84/1000], Loss: 0.9801\n","Epoch [86/1000], Loss: 1.1063\n","Epoch [88/1000], Loss: 0.9666\n","Epoch [90/1000], Loss: 0.9943\n","Epoch [92/1000], Loss: 0.9329\n","Epoch [94/1000], Loss: 0.7803\n","Epoch [96/1000], Loss: 1.0507\n","patience exceeded, loading best model\n","Epoch [2/1000], Loss: 1.1674\n"]}],"source":["best_accuracies = []\n","accuracies = []\n","top_k_average_accuracies = []\n","knn_accuracies = []\n","PATH = os.path.join(folder_name, f'checkpoints/regression_{dataset_name}.h5')\n","cfg.PATH = PATH\n","k_fold = KFold(n_splits=10, shuffle = True,random_state = None)\n","\n","\n","for train_index, test_index in k_fold.split(Xs):\n","  # Get training and testing data\n","  X_train, X_test = Xs[train_index], Xs[test_index]\n","  y_train, y_test = ys[train_index], ys[test_index]\n","\n","  knn = KNeighborsRegressor(n_neighbors=cfg.top_k)\n","  knn.fit(X_train, y_train)\n","  knn_accuracies.append(mean_squared_error(knn.predict(X_test), y_test))\n","\n","  best_accuracy, accuracy, top_k_average_accuracy, model= train_reg(X_train, y_train, X_test, y_test, cfg)\n","  best_accuracies.append(best_accuracy)\n","  accuracies.append(accuracy)\n","  top_k_average_accuracies.append(top_k_average_accuracy)\n","\n","print(\"Average accuracy:\", np.mean([acc.detach().numpy() for acc in accuracies]))\n","print(\"Average top_k_average_accuracies\", np.mean(top_k_average_accuracies))\n","print(\"KNN accuracy:\", np.mean(knn_accuracies))"]},{"cell_type":"markdown","source":["# Results Interpretation"],"metadata":{"id":"aQMTPXLwaBVq"}},{"cell_type":"code","source":["def print_model_features(input_model):\n","  for n, p in model.named_parameters():\n","    print(n)\n","    print(p.data)"],"metadata":{"id":"sf23mP1UaIvx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print_model_features(model)"],"metadata":{"id":"MRO3tUPEbJUs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for regression only. for classification is different\n","#feature_activations, case_activations, predicted_number\n","model.eval()\n","feature_activations, case_activations, output, predicted_class = model(X_test)"],"metadata":{"id":"PkxAqSoldjML"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predicted_class"],"metadata":{"id":"PtwGRyMjeXtp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_test"],"metadata":{"id":"EvY5_WGkeaxg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#inspecting the case activations\n","top_case_indices = torch.topk(case_activations, 5, dim=1)[1]"],"metadata":{"id":"hjaUAY7Bkjyr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test[0]"],"metadata":{"id":"tfi-PKhokmev"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train[top_case_indices[0][0]]"],"metadata":{"id":"73NQbeJ_kpO_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["By comparing the following two blocks' outputs, you can see we are retrieving a good neighbor."],"metadata":{"id":"xMePSTR1lXbb"}},{"cell_type":"code","source":["#sum abs of X_test[0] and the top activated case\n","sum(abs(X_test[0] - X_train[top_case_indices[0][0]]))"],"metadata":{"id":"0izuKF6okrsc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: average sum abs of X_test[0] and X_train data\n","print(np.mean([sum(abs(X_test[0] - X_train[i])) for i in range(len(X_train))]))"],"metadata":{"id":"faYClHOVktuW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["TODO:: A better way is to show the distribution of ``X_test[0] - X_train[i]``"],"metadata":{"id":"zkYKvaP-lz_0"}},{"cell_type":"code","source":["y_train[top_case_indices[0]]"],"metadata":{"id":"xrwLY3gXmCLd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["knn.predict(X_test)[0]"],"metadata":{"id":"es5Kv85CmHMt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["indices = knn.kneighbors(X_test)[1][0]"],"metadata":{"id":"pxOcKMzHmJkS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train[indices]"],"metadata":{"id":"o4vuKW0rmNVi"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[],"machine_shape":"hm","toc_visible":true}},"nbformat":4,"nbformat_minor":0}