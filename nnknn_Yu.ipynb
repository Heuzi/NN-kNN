{"cells":[{"cell_type":"markdown","metadata":{"id":"6MEBduUKpGrg"},"source":["Introduction for Psychologists:\n","\n","Hello. This is a demo of our model on predicting depression risk and explaining with features and cases. It is trained on a data set of cases.\n","\n","**Case**: a survey participant who answered 102 questions of depression screening survey (self-reporting). Each participant has a depression risk score 0,1,2 (judged by a psychologist, based on number of depression-related physical symptoms)\n","\n","**Feature**: Answers to survey questions (yes/no)\n","\n","**Query**: the new client who we are making a prediction on.\n","\n","**How does it work:**\n"," Our model learns about important features and cases during training. Given a new query (a new client), our model makes a prediction by retrieving the most relevant cases. It can explain in two main ways: highlighting (non-)important features, or highlighting (non-)important cases.\n","\n","**Goal**: The Goal of this demo is not to show you how good or how bad our model performs but more to open up a discussion about what you feel about using such models (part 2 of the interview). Please ignore the non-existing User-experience (UI) and the software code aspects because it is just a prototype. I will do my best to show you only the relevant parts."]},{"cell_type":"markdown","metadata":{"id":"rxoHWNZEmG4g"},"source":["# 1 Setup"]},{"cell_type":"markdown","metadata":{"id":"CsfLxAVaPOTf"},"source":["On google colab, you have to restart runtime after running the following line"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T3Y5CLhymG4l"},"outputs":[],"source":["# !pip install omegaconf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kaWqLJ3GbJWe"},"outputs":[],"source":["folder_name = './'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q-0ffsjpbDLE"},"outputs":[],"source":["##This is added because my Rdata uses Cdata for the covid data set.\n","##Rdata use Cdata function to load the data set, then convert it to regression problem\n","import os\n","import sys\n","sys.path.append(folder_name + 'dataset')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":32026,"status":"ok","timestamp":1736957669384,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":300},"id":"oDGrACwVmG4o","outputId":"5dce9b07-491f-4b5e-f56c-4701d61f50df"},"outputs":[{"name":"stderr","output_type":"stream","text":["/nfs/nfs8/home/research/ml/ego4d.NOBACKUP/wang/dlenv/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n","  from pandas.core import (\n","/nfs/nfs8/home/research/ml/ego4d.NOBACKUP/wang/dlenv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n","  warn(f\"Failed to load image Python extension: {e}\")\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import accuracy_score\n","from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n","from sklearn.metrics import mean_squared_error\n","from tqdm import tqdm\n","from omegaconf import DictConfig, OmegaConf\n","\n","from dataset import cls_small_data as Cdata\n","from dataset import cls_medium_data\n","\n","from dataset import reg_data as Rdata"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bzTxZZJnmG4p"},"outputs":[],"source":["conf_file = OmegaConf.load(os.path.join(folder_name, 'config.yaml'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yT3W4iqSmG4p"},"outputs":[],"source":["device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1736957670350,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":300},"id":"KcsdY45IjhSV","outputId":"808f7838-dea6-46e3-fed8-87ed83b60fd4"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.is_available()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"54RUct06Mugc"},"outputs":[],"source":["random_seed = 43"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dp9ZZ76YJfzy"},"outputs":[],"source":["debug_print = False\n","def dprint(*args):\n","  global debug_print\n","  if debug_print:\n","    print(*args)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Onosd6ibJWh"},"outputs":[],"source":["import importlib\n","# importlib.reload(Rdata)\n","# importlib.reload(Cdata)\n","importlib.reload(cls_medium_data)"]},{"cell_type":"markdown","metadata":{"id":"46TjfSz-mG4q"},"source":["# 2 Data Sets"]},{"cell_type":"markdown","metadata":{"id":"ZkDrsvjWmG4r"},"source":["Supported small dataset for classification:  \n","'zebra',\n","'zebra_special',\n","'bal',\n","'digits',\n","'iris',\n","'wine',\n","'breast_cancer',\n","\n","for regression:\n","'califonia_housing',\n","'abalone',\n","'diabets',\n","'body_fat',\n","'ziweifaces'\n","\n","\n","Newly added data sets for mental health (psychology):\n","\n","Classification:\n","'psych_depression_physical_symptons',\n","'covid_anxious',\n","'covid_depressed'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":71799,"status":"ok","timestamp":1736957742147,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":300},"id":"lxq-FY3FmG4r","outputId":"e8750248-26de-4638-b925-3a9ae52e6d91"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using downloaded and verified file: ./dataset/svhn/train_32x32.mat\n","Using downloaded and verified file: ./dataset/svhn/test_32x32.mat\n","Computed Mean: 0.4514187276363373, Computed Std: 0.12285319715738297\n"]}],"source":["dataset_name = 'svhn'\n","cfg = conf_file['dataset'][dataset_name]\n","if dataset_name in ['covid_anxious','covid_depressed','covid_physical','covid_lonely','covid_hopeless',\n","                    'psych_depression_physical_symptons',\n","                    'zebra','zebra_special','bal','digits','iris','wine','breast_cancer']:\n","    criterion = torch.nn.CrossEntropyLoss()\n","    Xs, ys = Cdata.Cls_small_data(dataset_name, folder_name)\n","elif dataset_name in ['mnist','cifar10', 'svhn']:\n","    criterion = torch.nn.CrossEntropyLoss()\n","    X_train, y_train, X_test, y_test = cls_medium_data.Cls_medium_data(dataset_name)\n","\n","    # if dataset_name == 'mnist':\n","    #     X_train, y_train, X_test, y_test = cls_medium_data.Cls_medium_data(dataset_name)\n","    # else:\n","    #     X_train, y_train, X_test, y_test, classes = cls_medium_data.Cls_medium_data(dataset_name)\n","else:\n","    criterion = torch.nn.MSELoss()\n","    Xs, ys = Rdata.Reg_data(dataset_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cNPWBqvve8v6"},"outputs":[],"source":["#for reloading config file, in case you modified it for experimenting\n","# conf_file = OmegaConf.load(os.path.join(folder_name, 'config.yaml'))\n","# cfg = conf_file['dataset'][dataset_name]"]},{"cell_type":"markdown","metadata":{"id":"NK9RJK0lKZw9"},"source":["## SST"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fDozSlabbJWi"},"outputs":[],"source":["dataset_name = \"sst2\""]},{"cell_type":"markdown","metadata":{"id":"vNitbaEcS6et"},"source":["Version 1, 5 labels\n","\n","Version 2, 2 labels, take out neutral"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nYHIHWi0bJWi"},"outputs":[],"source":["train_data, val_data, test_data = cls_medium_data.Cls_medium_data(dataset_name)"]},{"cell_type":"markdown","metadata":{"id":"nxSpBPTBsRfR"},"source":["# GO"]},{"cell_type":"markdown","metadata":{"id":"Q9Z9vzQI8bdu"},"source":["## Feature Extractor"]},{"cell_type":"markdown","metadata":{"id":"lwXjK_AZeISx"},"source":["### For MNIST"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"16ImNRZGeJ_p"},"outputs":[],"source":["# prompt: a classifier with conv layers for MNIST\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class MNISTClassifier(nn.Module):\n","    def __init__(self):\n","        super(MNISTClassifier, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc1 = nn.Linear(64 * 7 * 7, 128)  # Adjust input size based on image dimensions\n","        self.fc2 = nn.Linear(128, 10)  # Output size is 10 for 10 digits\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = x.view(-1, 64 * 7 * 7)  # Flatten the tensor\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","# Example usage\n","model = MNISTClassifier()\n","model"]},{"cell_type":"markdown","metadata":{"id":"-9vjp7Bidqnw"},"source":["### For Cifar10"]},{"cell_type":"markdown","metadata":{"id":"nP3nK-hABUb_"},"source":["https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZAUuZwchK12v"},"outputs":[],"source":["# prompt: a classifier with conv layers for cifar10\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class CIFAR10Classifier(nn.Module):\n","    def __init__(self):\n","        super(CIFAR10Classifier, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc1 = nn.Linear(64 * 8 * 8, 128)  # Adjust input size based on image dimensions and pooling\n","        self.fc2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = x.view(-1, 64 * 8 * 8) # Adjust input size based on image dimensions and pooling\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","# Example usage\n","model = CIFAR10Classifier()\n","# Dummy input (replace with your actual CIFAR-10 data)\n","dummy_input = torch.randn(1, 3, 32, 32)  # Batch size 1, 3 color channels, 32x32 image\n","output = model(dummy_input)\n","output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GafHQ4gubJWj"},"outputs":[],"source":["X_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-kbbDlF9bJWj","outputId":"5e52d907-27ef-413f-d082-aecadfbed678"},"outputs":[{"data":{"text/plain":["tensor([[-0.0539,  0.0018, -0.1152,  0.2323,  0.0956,  0.0884, -0.1379,  0.1676,\n","         -0.0819,  0.0108]], grad_fn=<AddmmBackward0>)"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["# prompt: a classifier with conv layers for svhn\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class SVHNClassifier(nn.Module):\n","    def __init__(self):\n","        super(SVHNClassifier, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc1 = nn.Linear(64 * 8 * 8, 128)  # Adjust input size based on image dimensions and pooling\n","        self.fc2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = x.view(-1, 64 * 8 * 8) # Adjust input size based on image dimensions and pooling\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","# Example usage"]},{"cell_type":"markdown","metadata":{"id":"NfrMkpGvl_dG"},"source":["### Set up Feature Extractor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TCBCBAJ2l_AB"},"outputs":[],"source":["def iniitialize_feature_extractor(model):\n","    # model = SVHNClassifier()\n","    feature_extractor = torch.nn.Sequential(\n","      model.conv1,\n","      nn.ReLU(),   # Add ReLU here\n","      model.pool,\n","      model.conv2,\n","      nn.ReLU(),   # Add ReLU here\n","      model.pool,\n","      torch.nn.Flatten(),\n","      model.fc1\n","    )\n","    feature_extractor.feature_dim = model.fc1.out_features\n","    feature_extractor.to(device)\n","    return feature_extractor"]},{"cell_type":"markdown","metadata":{"id":"dK0TeR-_mS3Y"},"source":["If you don't want feature extractor\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qbQJsY5tLb2L"},"outputs":[],"source":["feature_extractor = iniitialize_feature_extractor(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rfddObEC0q4K"},"outputs":[],"source":["# prompt: freeze parameters in feature_extractor\n","\n","# Freeze the parameters of the feature extractor\n","for param in feature_extractor.parameters():\n","  param.requires_grad = False"]},{"cell_type":"markdown","metadata":{"id":"L_RvkFavIgmc"},"source":["# Text Classification Task"]},{"cell_type":"markdown","metadata":{"id":"zet7XwfjlcH0"},"source":["https://arxiv.org/pdf/1408.5882"]},{"cell_type":"markdown","metadata":{"id":"v7bVs5TdlcgJ"},"source":["https://github.com/Impavidity/kim_cnn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ft6r9bPNNqV"},"outputs":[],"source":["# Create vocabulary and tokenizer\n","# ... (Code to create or load tokenizer) ...\n","# Example using a simple tokenizer and vocabulary\n","from nltk.tokenize import word_tokenize  # Example tokenizer\n","from collections import defaultdict\n","import nltk\n","nltk.download('punkt')\n","nltk.download('punkt_tab')\n","def create_vocab(dataset):\n","    vocab = defaultdict(lambda: len(vocab))  # Auto-incrementing index\n","    vocab[\"<pad>\"] = 0  # Special token for padding\n","\n","    for example in dataset:\n","        for token in word_tokenize(example[\"sentence\"]):  # Tokenize sentence\n","            vocab[token]  # Add token to vocabulary\n","\n","    return vocab\n","\n","vocab = create_vocab(train_data)  # Create vocab using training data\n","tokenizer = word_tokenize"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PXLFDdUaMygL"},"outputs":[],"source":["import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.model_selection import train_test_split\n","from torch.nn.utils.rnn import pad_sequence\n","\n","# Tokenize and convert sentences to numerical format\n","def prepare_dataset(data, vocab, tokenizer):\n","    texts = data[\"sentence\"]\n","    labels = data[\"label\"]\n","    tokenized_texts = [\n","        torch.tensor([vocab[token] for token in tokenizer(text)], dtype=torch.long)\n","        for text in texts\n","    ]\n","    padded_texts = pad_sequence(tokenized_texts, batch_first=True, padding_value=vocab[\"<pad>\"])\n","    labels = torch.tensor(labels, dtype=torch.long)\n","    return padded_texts, labels\n","\n","# Prepare train, validation, and test datasets\n","X_train, y_train = prepare_dataset(train_data, vocab, tokenizer)\n","X_val, y_val = prepare_dataset(val_data, vocab, tokenizer)\n","X_test, y_test = prepare_dataset(test_data, vocab, tokenizer)\n","\n","# Create TensorDataset and DataLoader\n","train_dataset = TensorDataset(X_train, y_train)\n","val_dataset = TensorDataset(X_val, y_val)\n","test_dataset = TensorDataset(X_test, y_test)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ew0vVPu5vSFn"},"outputs":[],"source":["# prompt: check the number of classes in y_train and their balance\n","\n","from collections import Counter\n","\n","# Assuming y_train is defined and accessible in your code.  Replace this with your actual y_train variable.\n","# Example:\n","# y_train = [0, 1, 0, 2, 1, 0, 1, 2, 0, 0, 1, 1] # replace this with the real y_train\n","\n","class_counts = Counter(y_train.tolist())\n","num_classes = len(class_counts)\n","print(f\"Number of classes: {num_classes}\")\n","print(\"Class distribution:\", class_counts)\n","\n","# Calculate class proportions\n","total_samples = len(y_train)\n","for class_label, count in class_counts.items():\n","    proportion = count / total_samples\n","    print(f\"Class {class_label}: {proportion:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"2brzhaOcN1cl"},"source":["Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bg22h24xODjs"},"outputs":[],"source":["class KimCNNClassifier(nn.Module):\n","    def __init__(self, feature_extractor, num_classes):\n","        super(KimCNNClassifier, self).__init__()\n","        self.feature_extractor = feature_extractor\n","        self.dropout = nn.Dropout(0.5)\n","        self.fc = nn.Linear(feature_extractor.convs[0].out_channels * len(feature_extractor.convs), num_classes)\n","\n","    def forward(self, x):\n","        features = self.feature_extractor(x)\n","        x = self.dropout(x)\n","        return self.fc(features)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EnOQ8Q-1i9y3"},"outputs":[],"source":["\n","# Device configuration\n","# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Initialize Kim's CNN model\n","vocab_size = len(vocab)\n","embed_dim = 300\n","num_filters = 100\n","filter_sizes = [3, 4, 5]\n","num_classes = 5\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D-DE2VVCTMzi"},"outputs":[],"source":["feature_extractor = KimCNNFeatureExtractor(vocab_size, embed_dim, num_filters, filter_sizes)\n","feature_extractor.feature_dim = num_filters * len(filter_sizes)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"chzbvCIlN1BX"},"outputs":[],"source":["import torch.nn as nn\n","import torch.optim as optim\n","\n","\n","model = KimCNNClassifier(feature_extractor, num_classes).to(device)\n","\n","# Define hyperparameters\n","\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","num_epochs = 1000\n","patience = 100\n","best_loss = float('inf')\n","patience_counter = 0\n","\n","# Training loop with early stopping\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_loss = 0\n","    for texts, labels in train_loader:\n","        texts, labels = texts.to(device), labels.to(device)\n","\n","        # Forward pass\n","        outputs = model(texts)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    # Validation phase\n","    model.eval()\n","    val_loss = 0.0\n","    with torch.no_grad():\n","        for texts, labels in val_loader:\n","            texts, labels = texts.to(device), labels.to(device)\n","            outputs = model(texts)\n","            loss = criterion(outputs, labels)\n","            val_loss = loss.item()\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {total_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n","\n","    # Early stopping logic\n","    if val_loss < best_loss:\n","        best_loss = val_loss\n","        patience_counter = 0\n","        torch.save(model.state_dict(), 'best_model.pth')  # Save the best model\n","    else:\n","        patience_counter += 1\n","\n","    if patience_counter >= patience:\n","        print(f\"Early stopping triggered after {epoch+1} epochs.\")\n","        model.load_state_dict(torch.load('best_model.pth'))  # Restore the best model\n","        break\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6XbLIkLxUrBJ"},"outputs":[],"source":["feature_extractor.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zsklSxvqPbE8"},"outputs":[],"source":["def evaluate_model(model, data_loader):\n","    model.eval()\n","    correct, total = 0, 0\n","\n","    with torch.no_grad():\n","        for texts, labels in data_loader:\n","            texts, labels = texts.to(device), labels.to(device)\n","            outputs = model(texts)\n","            predictions = outputs.argmax(1)\n","            correct += (predictions == labels).sum().item()\n","            total += labels.size(0)\n","\n","    accuracy = correct / total\n","    return accuracy\n","\n","# Load the best model and evaluate on the test set\n","model.load_state_dict(torch.load('best_model.pth'))\n","test_accuracy = evaluate_model(model, test_loader)\n","print(f\"Test Accuracy: {test_accuracy:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"75YsqbCQjFUR"},"source":["DO NOT RUN THIS if you want to keep your feature extractor after training.\n","\n","RUN THIS if you want to wipe the parameters back to blank state"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kWv-t37akKwU"},"outputs":[],"source":["#re-create the feature_extractor, to be retrained by nn-knn\n","feature_extractor = KimCNNFeatureExtractor(vocab_size, embed_dim, num_filters, filter_sizes)\n","feature_extractor.feature_dim = num_filters * len(filter_sizes)\n","feature_extractor.to(device)"]},{"cell_type":"markdown","metadata":{"id":"vxFFP2wGd_Cj"},"source":["# Sanity Check\n","Sanity check with a standard NN classifier using the feature extractor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YKZTDygbbJWq","outputId":"5911af5d-545a-4bb5-a3ed-79dd36f8395f"},"outputs":[{"data":{"text/plain":["(torch.Size([73257, 3, 32, 32]), torch.Size([26032, 3, 32, 32]))"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["X_train.shape, X_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":479705,"status":"ok","timestamp":1736959411638,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":300},"id":"aQPpN2NYLJv8","outputId":"4cf8a684-a93d-4d5f-c943-1c6537313cb4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/25], Validation Loss: 0.6661\n","Epoch [2/25], Validation Loss: 0.6008\n","Epoch [3/25], Validation Loss: 0.5490\n","Epoch [4/25], Validation Loss: 0.5125\n","Epoch [5/25], Validation Loss: 0.4883\n","Epoch [6/25], Validation Loss: 0.4691\n","Epoch [7/25], Validation Loss: 0.4509\n","Epoch [8/25], Validation Loss: 0.4343\n","Epoch [9/25], Validation Loss: 0.4451\n","Epoch [10/25], Validation Loss: 0.4355\n","Epoch [11/25], Validation Loss: 0.4292\n","Epoch [12/25], Validation Loss: 0.4187\n","Epoch [13/25], Validation Loss: 0.4361\n","Epoch [14/25], Validation Loss: 0.4263\n","Epoch [15/25], Validation Loss: 0.4251\n","Epoch [16/25], Validation Loss: 0.4515\n","Epoch [17/25], Validation Loss: 0.4457\n","Epoch [18/25], Validation Loss: 0.4494\n","Epoch [19/25], Validation Loss: 0.4580\n","Epoch [20/25], Validation Loss: 0.4776\n","Epoch [21/25], Validation Loss: 0.4884\n","Epoch [22/25], Validation Loss: 0.5127\n","Epoch [23/25], Validation Loss: 0.5196\n","Epoch [24/25], Validation Loss: 0.5356\n","Epoch [25/25], Validation Loss: 0.5404\n"]}],"source":["import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","model = SVHNClassifier()\n","# Dummy input (replace with your actual CIFAR-10 data)\n","dummy_input = torch.randn(1, 3, 32, 32)  # Batch size 1, 3 color channels, 32x32 image\n","output = model(dummy_input)\n","\n","model.to(device)\n","\n","# Define hyperparameters\n","learning_rate = 1e-4\n","num_epochs = 25  # Extend epochs since early stopping will halt earlier if needed\n","patience = 100\n","best_loss = float('inf')\n","patience_counter = 0\n","batch_size = 32  # Mini-batch size\n","\n","# Define optimizer\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Prepare the DataLoader for batching (Training Data)\n","train_dataset = TensorDataset(X_train, y_train)\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","# Prepare the DataLoader for validation/testing (Validation Data)\n","val_dataset = TensorDataset(X_test, y_test)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    # Train the model for one epoch\n","    model.train()\n","    for images, labels in train_loader:\n","        optimizer.zero_grad()  # Zero the gradients\n","        # Move images and labels to the same device as the model\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        # if(dataset_name == 'mnist'):\n","        #   # Reshape images to add channel dimension (for CNN models on MNIST)\n","        #   images = images.unsqueeze(1)  # Adds channel dimension (B, 1, H, W)\n","\n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward pass and optimization\n","        loss.backward()\n","        optimizer.step()\n","\n","    # Calculate average loss on validation set after each epoch\n","    model.eval()\n","    val_loss = 0.0\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            # if(dataset_name == 'mnist'):\n","            #   images = images.unsqueeze(1)\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","\n","    avg_epoch_loss = val_loss / len(val_loader)  # Average loss over the validation set\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {avg_epoch_loss:.4f}\")\n","\n","    # Early stopping based on validation loss\n","    if val_loss < best_loss:\n","        best_loss = val_loss\n","        patience_counter = 0\n","        torch.save(model.state_dict(), 'best_model.pth')  # Save the best model\n","    else:\n","        patience_counter += 1\n","\n","    if patience_counter >= patience:\n","        print(f\"Early stopping triggered after {epoch+1} epochs.\")\n","        model.load_state_dict(torch.load('best_model.pth'))  # Restore best model\n","        break\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1736959411638,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":300},"id":"ln9HpOuYnld-","outputId":"16276030-317a-4b92-b54b-c229195fb56e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy of the model on the test images: 88.11%\n"]}],"source":["import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","# Define batch size for testing\n","test_batch_size = 128  # Adjust based on memory capacity\n","\n","# Prepare the DataLoader for batching the test set\n","test_dataset = TensorDataset(X_test, y_test)\n","test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n","\n","correct = 0\n","total = 0\n","\n","# Evaluation loop using DataLoader\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        # Reshape for CNNs (e.g., MNIST)\n","        # if dataset_name == 'mnist':\n","        #     images = images.unsqueeze(1)  # Add channel dimension (B, 1, H, W)\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        # Forward pass over the mini-batch\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs, 1)  # Get predicted class (max along dim=1)\n","\n","        # Accumulate correct predictions\n","        correct += (predicted == labels).sum().item()\n","        total += labels.size(0)\n","\n","# Calculate and print accuracy\n","accuracy = 100 * correct / total\n","print(f\"Accuracy of the model on the test images: {accuracy:.2f}%\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2SJd829ybJWq","outputId":"ce7fe822-c828-46de-b0d4-f5453cf3cd51"},"outputs":[{"data":{"text/plain":["tensor([[[[-0.0563, -0.1588,  0.1131],\n","          [-0.1981,  0.0149,  0.1029],\n","          [-0.2386, -0.0229, -0.0579]],\n","\n","         [[-0.2616,  0.0847, -0.0306],\n","          [ 0.0177, -0.1106,  0.2081],\n","          [-0.2164,  0.1091, -0.0608]],\n","\n","         [[ 0.1246,  0.0902,  0.2780],\n","          [-0.0596,  0.2253,  0.2036],\n","          [-0.2660, -0.1333,  0.2691]]]], device='cuda:1')"]},"execution_count":103,"metadata":{},"output_type":"execute_result"}],"source":["model.state_dict()['conv1.weight'][:1]"]},{"cell_type":"markdown","metadata":{"id":"GNraq7Y-bJWr"},"source":[]},{"cell_type":"markdown","metadata":{"id":"i7UiTvpzbJWr"},"source":["## Pretrained Feature for KNN (Pretrained Conv + KNN)"]},{"cell_type":"markdown","metadata":{"id":"VmIRcBiHjnFj"},"source":["Run the following if you want to transform the features for vanilla knn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yaby7Ru7qUN6"},"outputs":[],"source":["# Step 1: Freeze the feature extractor's weights\n","for param in feature_extractor.parameters():\n","    param.requires_grad = False\n","\n","# Step 2: Convert X_train and X_test\n","def transform_dataset(X, feature_extractor, batch_size=128, device='cuda'):\n","    \"\"\"\n","    Transform a dataset using the feature extractor.\n","\n","    Args:\n","        X (torch.Tensor): Input dataset of shape (num_samples, channels, height, width).\n","        feature_extractor (nn.Module): Feature extractor model.\n","        batch_size (int): Batch size for processing.\n","        device (str): Device to perform computations ('cuda' or 'cpu').\n","\n","    Returns:\n","        torch.Tensor: Transformed dataset of shape (num_samples, feature_dim).\n","    \"\"\"\n","    feature_extractor.eval()  # Ensure the feature extractor is in evaluation mode\n","    X = X.to(device)\n","    transformed_features = []\n","\n","    with torch.no_grad():  # Disable gradient computation for efficiency\n","        for i in range(0, X.size(0), batch_size):\n","            batch = X[i:i + batch_size]\n","            features = feature_extractor(batch)  # Extract features\n","            transformed_features.append(features)\n","\n","    return torch.cat(transformed_features, dim=0)\n","\n","# Transform the datasets\n","X_train_transformed = transform_dataset(X_train, feature_extractor, batch_size=128, device=device)\n","X_test_transformed = transform_dataset(X_test, feature_extractor, batch_size=128, device=device)\n","\n","# Print shapes to verify\n","print(f\"Transformed X_train shape: {X_train_transformed.shape}\")\n","print(f\"Transformed X_test shape: {X_test_transformed.shape}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ycSFx7yGqXTn"},"outputs":[],"source":["# X_train = X_train_transformed\n","# X_test = X_test_transformed"]},{"cell_type":"markdown","metadata":{"id":"aIH5bd_O3eg3"},"source":["Sanity check using a vanilla knn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DD4hFap-tQ1Y"},"outputs":[],"source":["# prompt: knn on the train and test data set\n","\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","# Assuming X_train, y_train, X_test, and y_test are defined from the previous code\n","# and contain the training and testing data.\n","\n","# Initialize the k-NN classifier\n","knn = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors\n","\n","# Reshape X_train and X_test to 2D arrays before fitting the k-NN model\n","X_train_reshaped = X_train_transformed.reshape(X_train_transformed.shape[0], -1)  # Reshape to (num_samples, height * width)\n","X_test_reshaped = X_test_transformed.reshape(X_test_transformed.shape[0], -1)    # Reshape to (num_samples, height * width)\n","\n","# Train the classifier on the reshaped training data\n","knn.fit(X_train_reshaped.cpu(), y_train)\n","\n","# Make predictions on the reshaped test data\n","y_pred = knn.predict(X_test_reshaped.cpu())\n","\n","# Evaluate the model (example: accuracy)\n","accuracy = accuracy_score(y_test.cpu().numpy(), y_pred)\n","print(f\"k-NN Accuracy: {accuracy}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ntHguVqbJWs"},"outputs":[],"source":["del X_test_transformed, X_train_transformed"]},{"cell_type":"markdown","metadata":{"id":"xZUXibQNLGTj"},"source":["# Param Setup\n"]},{"cell_type":"markdown","metadata":{"id":"yLr1V5cGBSVb"},"source":["### Shared Param Setup"]},{"cell_type":"markdown","metadata":{"id":"ZsGYH0p1bJWs"},"source":["Must run!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_3YnWoOwLHs6"},"outputs":[],"source":["def get_feature_dim(case, feature_extractor):\n","        if feature_extractor is None:\n","            return torch.prod(torch.tensor(case.shape)).item()\n","        else:\n","            return feature_extractor.feature_dim"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YZHloHXQLMBK"},"outputs":[],"source":["#if Xs is not defined, use X_train\n","if 'Xs' not in locals():\n","    Xs = X_train\n","    ys = y_train\n","\n","feature_dim = get_feature_dim(Xs[0], feature_extractor)# Xs.shape[1]\n","glocal_fw_set_num = 4;\n","\n","sampling_cases_flag = False\n","use_sampling_cases_divisor = False\n","sampling_cases_divisor = 100\n","\n","#DESIGN DECISION\n","case_activation_by_top_k_average = True\n","top_k_for_case_activation = 5\n","num_samples=5000\n","\n","#if case_activation_by_top_k_average = False, following will be used\n","case_activation_default_percentage = 0.1  #this might require enabling top k\n","top_case_enabled = False\n","\n","bias_manual_set = False\n","bias_manual_value = 6.0\n","\n","model_path = 'best_model.pth'\n","feature_weightor_path = 'best_fw.pth'"]},{"cell_type":"markdown","metadata":{"id":"TmTmWAaqBWjz"},"source":["### Non-shared setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gbVb-x-dZnp_"},"outputs":[],"source":["#For MNIST\n","glocal_fw_set_num = 1\n","sampling_cases_flag = True\n","top_k_for_case_activation = 20\n","num_samples=500"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dxpbi5ISiyI7"},"outputs":[],"source":["#For Cifar 10\n","\n","glocal_fw_set_num = 1\n","sampling_cases_flag = True\n","top_k_for_case_activation = 20\n","num_samples=500"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XqnBBTzMbJWt"},"outputs":[],"source":["#For SVHN\n","\n","glocal_fw_set_num = 1\n","sampling_cases_flag = True\n","top_k_for_case_activation = 20\n","num_samples=500"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QS33BQbPiSYH"},"outputs":[],"source":["#For SST\n","\n","glocal_fw_set_num = 4\n","sampling_cases_flag = True\n","top_k_for_case_activation = 10\n","num_samples=500"]},{"cell_type":"markdown","metadata":{"id":"qaLfyfrYbJWt"},"source":["# MUST RUN"]},{"cell_type":"markdown","metadata":{"id":"vHknYLrK33ES"},"source":["## Glocal Feature Weight"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lOL2WF2x4Ug3"},"outputs":[],"source":["class GlocalFeatureWeight(nn.Module):\n","    def __init__(self, feature_dim, set_num):\n","        \"\"\"\n","        Glocal feature weighting module for batched operations.\n","\n","        Args:\n","            feature_dim: Dimensionality of the features.\n","            set_num: Number of glocal weight sets.\n","        \"\"\"\n","        super(GlocalFeatureWeight, self).__init__()\n","        self.feature_dim = feature_dim\n","\n","        # Initialize feature weights\n","        self.feature_weights = nn.Parameter(torch.rand((set_num, feature_dim)), requires_grad=True)\n","        if glocal_fw_set_num == 1:\n","            self.feature_weights = nn.Parameter(torch.ones((set_num, feature_dim)), requires_grad=True)  # Shape: (set_num, feature_dim)\n","\n","    def forward(self, case_distance, glocal_weights):\n","        \"\"\"\n","        Apply feature weighting to the case distance in a batched manner.\n","\n","        Args:\n","            case_distance: Tensor of shape (batch_size, sample_num, feature_dim).\n","            glocal_weights: Tensor of shape (sample_num, set_num).\n","\n","        Returns:\n","            weighted_distance: Weighted case distance, shape (batch_size, sample_num, feature_dim).\n","        \"\"\"\n","        global debug_print\n","        debug_print = False\n","\n","        # Ensure positive feature weights using LeakyReLU\n","        pos_feature_weights = F.leaky_relu(self.feature_weights, negative_slope=0.001)  # Shape: (set_num, feature_dim)\n","        glocal_weights = F.leaky_relu(glocal_weights, negative_slope=0.001)  # Shape: (sample_num, set_num)\n","\n","        # Compute weight factors for all cases\n","        # Resulting shape: (sample_num, feature_dim)\n","        weight_factors = torch.matmul(glocal_weights, pos_feature_weights)  # Shape: (sample_num, feature_dim)\n","\n","        # Expand weight_factors to match batch size and elementwise multiply\n","        weighted_distance = case_distance * weight_factors.unsqueeze(0)  # Shape: (batch_size, sample_num, feature_dim)\n","\n","        if debug_print:\n","            print(\"case_distance:\", case_distance)\n","            print(\"glocal_weights:\", glocal_weights)\n","            print(\"feature_weights:\", self.feature_weights)\n","            print(\"weighted_distance:\", weighted_distance)\n","\n","        return weighted_distance\n"]},{"cell_type":"markdown","metadata":{"id":"vr-zruqOgsQJ"},"source":["## Case Bias Setup and others"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qBMS10DHoWVW"},"outputs":[],"source":["# prompt: a class recording a case's How often it is activated, how often it is sampled, how often it correctly classifies a query.\n","\n","class CaseRecord:\n","    def __init__(self, case_id = None):\n","        self.case_id = case_id\n","        self.activation_count = 0\n","        self.sample_count = 0\n","        self.correct_classification_count = 0\n","\n","    def activate(self):\n","        self.activation_count += 1\n","\n","    def sample(self):\n","        self.sample_count += 1\n","\n","    def correct_classification(self):\n","        self.correct_classification_count += 1\n","\n","    def get_activation_rate(self):\n","        return self.activation_count / (self.sample_count + 1e-10) # avoid division by zero\n","\n","    def get_sampling_rate(self):\n","      return self.sample_count\n","\n","    def get_accuracy(self):\n","        return self.correct_classification_count / (self.sample_count + 1e-10) # avoid division by zero"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Ge7LLx-f0mm"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","\n","def find_default_bias(X, feature_extractor = None,num_samples=500, case_activation_default_percentage=0.1):\n","    \"\"\"\n","    Estimates the default bias for CaseNets by randomly comparing pairwise distances.\n","    Handles both image (e.g., MNIST) and tabular data.\n","\n","    Args:\n","        X: The feature tensor. Shape can be (num_cases, feature_dim) or (num_cases, 1, H, W).\n","        num_samples: The number of random case pairs to compare.\n","        case_activation_default_percentage: Percentage of sorted distances to select.\n","\n","    Returns:\n","        The estimated default bias.\n","    \"\"\"\n","    num_cases = X.shape[0]\n","    distances = []\n","\n","    # Flatten if data is image-like (e.g., (num_cases, 1, 28, 28))\n","    if len(X.shape) > 2:\n","        X_flat = X.view(num_cases, -1)  # Flatten to (num_cases, feature_dim)\n","    else:\n","        X_flat = X  # Already in tabular form\n","    if feature_extractor is not None:\n","        # Extract features using the feature extractor\n","        with torch.no_grad():  # Disable gradient computation for efficiency\n","            X_flat = feature_extractor(X).view(X.shape[0], -1)  # Flatten to (num_cases, feature_dim)\n","\n","    # Compute random pairwise distances\n","    for _ in range(num_samples):\n","        idx1, idx2 = torch.randint(0, num_cases, (2,))\n","\n","        # Calculate the pairwise distance\n","        distance = F.pairwise_distance(X_flat[idx1].unsqueeze(0), X_flat[idx2].unsqueeze(0))\n","        distances.append(distance.item())\n","\n","    # Sort distances and select top 10% based on case_activation_default_percentage\n","    distances.sort()\n","    percentile_index = int(len(distances) * case_activation_default_percentage)\n","    default_bias = distances[percentile_index]\n","\n","    return default_bias\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fv3FXZfghhf3"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","\n","def find_default_bias_knn(X, feature_extractor=None, k=5, num_samples=500, batch_size=64):\n","    \"\"\"\n","    Efficiently estimates the default bias for CaseNets by computing the average distance\n","    to the k-th nearest neighbor for each case, using a randomly sampled subset of cases.\n","\n","    Args:\n","        X: The feature tensor, shape (num_cases, channels, height, width) for MNIST or CIFAR-10.\n","        feature_extractor: Optional feature extractor to transform the input tensor.\n","        k: The number of nearest neighbors to consider.\n","        num_samples: Number of random cases to compare against.\n","        batch_size: Batch size for processing cases.\n","\n","    Returns:\n","        The estimated default bias (average distance to the k-th nearest neighbor).\n","    \"\"\"\n","    num_cases = X.shape[0]\n","    all_kth_distances = []\n","\n","    # Extract features using the feature extractor, if provided\n","    if feature_extractor is not None:\n","        feature_list = []\n","        with torch.no_grad():\n","            for i in range(0, num_cases, batch_size):\n","                batch = X[i:i + batch_size]  # Shape: (batch_size, channels, height, width)\n","                batch_features = feature_extractor(batch)  # Shape: (batch_size, feature_dim)\n","                feature_list.append(batch_features)\n","        X = torch.cat(feature_list, dim=0)  # Concatenate all batches\n","\n","    # Flatten the features for distance computation\n","    X_flat = X.view(X.shape[0], -1)  # Shape: (num_cases, feature_dim)\n","\n","    # Randomly sample `num_samples` cases to form the comparison set\n","    sampled_indices = torch.randperm(num_cases)[:num_samples]\n","    sampled_cases = X_flat[sampled_indices]  # Shape: (num_samples, feature_dim)\n","\n","    # Process cases in batches to reduce memory usage\n","    for i in range(0, num_cases, batch_size):\n","        # Get the batch of cases\n","        batch = X_flat[i:i + batch_size]  # Shape: (batch_size, feature_dim)\n","\n","        # Compute pairwise distances with the sampled cases\n","        distances = torch.cdist(batch, sampled_cases)  # Shape: (batch_size, num_samples)\n","\n","        # Set self-distances to infinity for sampled cases\n","        batch_indices = torch.arange(i, min(i + batch_size, num_cases))\n","        mask = (batch_indices.unsqueeze(1) == sampled_indices.unsqueeze(0))  # Match indices in the batch\n","        distances[mask] = float('inf')\n","\n","        # Get the k-th smallest distance for each case in the batch\n","        k_actual = min(k, num_samples)  # Ensure k does not exceed the number of samples\n","        kth_distances = torch.topk(distances, k=k_actual, largest=False).values[:, -1]\n","        all_kth_distances.extend(kth_distances.tolist())\n","\n","    # Return the average k-th neighbor distance as the default bias\n","    return sum(all_kth_distances) / len(all_kth_distances)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U79sZXV9gNLp"},"outputs":[],"source":["case_default_bias = 0\n","if bias_manual_set:\n","  case_default_bias = bias_manual_value\n","elif case_activation_by_top_k_average:\n","  case_default_bias = find_default_bias_knn(Xs.to(device), feature_extractor, top_k_for_case_activation, num_samples)\n","else:\n","  case_default_bias = find_default_bias(Xs)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1736959412654,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":300},"id":"njMPzLMbhQKj","outputId":"87f6a734-4dc6-4c95-d7f1-f7bfafccc986"},"outputs":[{"data":{"text/plain":["82.34364818095646"]},"execution_count":113,"metadata":{},"output_type":"execute_result"}],"source":["case_default_bias"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q6VKiDPGwQT3"},"outputs":[],"source":["# Initialize case_default_bias as a GLOBAL trainable parameter\n","# case_default_bias = nn.Parameter(torch.tensor(find_default_bias(Xs), dtype=torch.float32, device=device), requires_grad=True)\n"]},{"cell_type":"markdown","metadata":{"id":"2MNAEUwC30I0"},"source":["## Case Network"]},{"cell_type":"markdown","metadata":{"id":"DC6Xhx6t19y1"},"source":["### Custom Case Activation Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"74B8d3Xtz1vt"},"outputs":[],"source":["import torch\n","from functools import partial\n","\n","def scaled_sigmoid(x):\n","    \"\"\"\n","    Scaled and shifted sigmoid as a PyTorch operation.\n","\n","    Args:\n","        x: The input tensor.\n","        A: The value at which the output should be close to 1.\n","\n","    Returns:\n","        The scaled and shifted sigmoid output tensor.\n","    \"\"\"\n","    A = case_default_bias\n","    s = 8 / A  # Scaling factor\n","    b = 0 - 4      # Shift value\n","    return torch.sigmoid(s * x + b)\n","\n","\n","# Now you can use sigmoid_with_preset_A with variable x\n","x = torch.randn(10)*5  # Example input tensor\n","output = scaled_sigmoid(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7CVkE7Kmczzj"},"outputs":[],"source":["def mirrored_leaky_relu(x, negative_slope= 0.01, threshold = case_default_bias):\n","    \"\"\"\n","    Custom Leaky ReLU with mirrored behavior above a threshold.\n","\n","    Args:\n","        x: Input tensor.\n","        negative_slope: Slope for x < 0.\n","        threshold: Upper bound where the mirroring begins.\n","\n","    Returns:\n","        Transformed tensor.\n","    \"\"\"\n","    # Leaky ReLU for x < 0\n","    leaky_part = torch.where(x < 0, negative_slope * x, x)\n","\n","    # Mirroring effect for x > threshold\n","    mirror_part = torch.where(x > threshold,\n","                              threshold + negative_slope * (x - threshold),\n","                              leaky_part)\n","\n","    return mirror_part\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bhWmPPKfbJWv","outputId":"8e80933e-2ad5-40ed-b73f-50b75eeb474d"},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_232512/2926130680.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  ys = torch.tensor(ys) # Assuming ys is a NumPy array or a list\n"]}],"source":["# prompt: one hot encode ys\n","\n","import torch\n","ys = torch.tensor(ys) # Assuming ys is a NumPy array or a list\n","num_classes = len(torch.unique(ys))\n","ys_onehot = torch.nn.functional.one_hot(ys, num_classes=num_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k5L0NhRgbJWv"},"outputs":[],"source":["Xs = Xs.to(device)\n","ys_onehot = ys_onehot.to(device)\n","ys = ys.to(device)"]},{"cell_type":"markdown","metadata":{"id":"je4SsvHEbB7Z"},"source":["### Real Case Network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PzRjELQbbJWw"},"outputs":[],"source":["cfg.batch_size = 100"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sVTM16Y4gwww"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class CaseNetsClassifier(nn.Module):\n","    def __init__(self, cases, labels, feature_extractor=None, glocal_weightor=None, sampling_cases=sampling_cases_flag, top_k=4):\n","        \"\"\"\n","        A combined class that replaces both `CaseNet` and `CaseNetsClassifier`.\n","\n","        Args:\n","            cases (torch.Tensor): Tensor containing all cases (e.g., images or sequences).\n","            labels (torch.Tensor): Tensor of one-hot encoded labels for each case.\n","            feature_extractor (nn.Module): Feature extractor (e.g., CNN for images or embedding for text).\n","            glocal_weightor (nn.Module): Global-local weightor for feature weighting.\n","            sampling_cases (bool): Whether to use sampling for case selection.\n","            top_k (int): Number of top cases to retrieve for explanation.\n","        \"\"\"\n","        super(CaseNetsClassifier, self).__init__()\n","        self.cases = cases  # Shape: [num_cases, *case_shape]\n","        self.labels = labels  # Shape: [num_cases, num_classes]\n","        self.feature_extractor = feature_extractor\n","        self.glocal_weightor = glocal_weightor\n","\n","        # Group cases by class\n","        self.class_to_cases = {}\n","        for i, label in enumerate(self.labels):\n","            class_label = torch.argmax(label).item()  # Extract class label\n","            if class_label not in self.class_to_cases:\n","                self.class_to_cases[class_label] = []\n","            self.class_to_cases[class_label].append(i)\n","\n","        self.sampling_cases = sampling_cases\n","        self.sample_num = num_samples\n","        self.top_k = top_k\n","\n","        # Parameters specific to each case\n","        self.biases = nn.Parameter(torch.full((len(cases),), case_default_bias))  # Shape: [num_cases]\n","        self.weights = nn.Parameter(torch.ones(len(cases)))  # Shape: [num_cases]\n","        self.glocal_weights = nn.Parameter(\n","            torch.softmax(torch.ones(len(cases), glocal_fw_set_num), dim=-1)\n","        )  # Shape: [num_cases, set_dim]\n","\n","        # Precompute feature dimensions if feature extractor exists\n","        self.feature_dim = None\n","        if feature_extractor is not None:\n","            with torch.no_grad():\n","                dummy_input = cases[0].unsqueeze(0).to(device)\n","                self.feature_dim = feature_extractor(dummy_input).shape[-1]\n","        else:\n","            self.feature_dim = cases.shape[-1]\n","        self.cached_features = None  # To cache features during evaluation mode\n","\n","        self.explanation_mode = False\n","    def _extract_features(self, case_indices):\n","        \"\"\"\n","        Extract features for selected cases using the feature extractor.\n","\n","        Args:\n","            case_indices (torch.Tensor): Indices of cases to process.\n","\n","        Returns:\n","            extracted_features (torch.Tensor): Features for the selected cases.\n","        \"\"\"\n","        selected_cases = self.cases[case_indices]  # Shape: [num_selected_cases, *case_shape]\n","\n","        if self.feature_extractor is not None:\n","            if self.training:\n","                # Always compute features during training\n","                extracted_features = self.feature_extractor(selected_cases)  # Shape: [num_selected_cases, feature_dim]\n","                #wipe cache because feature extractor will be updated\n","                self.cached_features = None\n","            else:\n","                # During evaluation, update cache only for processed indices\n","                if self.cached_features is None:\n","                    # Initialize cache on the first evaluation pass\n","                    self.cached_features = torch.zeros(\n","                        (len(self.cases), self.feature_dim), dtype=torch.float32, device=selected_cases.device\n","                    )\n","\n","                # Check which indices need to be computed\n","                uncached_indices = [idx.item() for idx in case_indices if self.cached_features[idx].sum() == 0]\n","                if uncached_indices:\n","                    uncached_cases = self.cases[uncached_indices]\n","                    uncached_features = self.feature_extractor(uncached_cases)  # Extract features for uncached cases\n","                    self.cached_features[uncached_indices] = uncached_features\n","\n","                # Retrieve features from the cache\n","                extracted_features = self.cached_features[case_indices]\n","        else:\n","            # No feature extraction; use raw cases as features\n","            extracted_features = selected_cases\n","\n","        return extracted_features\n","\n","\n","    def forward(self, query):\n","        \"\"\"\n","        Perform forward pass and optionally provide explanations.\n","\n","        Args:\n","            query (torch.Tensor): Query tensor of shape [batch_size, *query_shape].\n","            explanation_mode (bool): Whether to provide explanations (top-k cases).\n","\n","        Returns:\n","            final_predictions (torch.Tensor): Predicted probabilities/logits for each class.\n","            predicted_class (torch.Tensor): Predicted class indices.\n","            most_activated_cases (list, optional): List of top-k most activated cases (if explanation_mode=True).\n","            most_activated_activations (torch.Tensor, optional): Activations of the top-k most activated cases.\n","        \"\"\"\n","        batch_size = query.size(0)\n","        num_cases = len(self.cases)\n","        case_indices = torch.arange(num_cases).to(query.device)  # Default: use all case_nets\n","        # Sampling cases (optional)\n","        if self.sampling_cases:\n","          sampled_indices = []\n","          each_class_sample_num = max(1, self.sample_num // len(self.class_to_cases))\n","\n","          for class_label, case_indices in self.class_to_cases.items():\n","              if len(case_indices) >= each_class_sample_num:\n","                  # Sample directly from global indices\n","                  sampled_indices.extend(torch.tensor(case_indices)[torch.randperm(len(case_indices))[:each_class_sample_num]].tolist())\n","              else:\n","                  # If fewer cases, sample with replacement\n","                  sampled_indices.extend(\n","                      torch.tensor(case_indices)[torch.randint(0, len(case_indices), (each_class_sample_num,))].tolist()\n","                  )\n","          case_indices = torch.tensor(sampled_indices).to(query.device)\n","\n","        # Extract features\n","        query_features = self.feature_extractor(query) if self.feature_extractor is not None else query\n","        case_features = self._extract_features(case_indices)\n","\n","        # Compute distances\n","        query_expanded = query_features.unsqueeze(1).expand(-1, len(case_indices), -1)  # [batch_size, num_selected_cases, feature_dim]\n","        case_expanded = case_features.unsqueeze(0).expand(batch_size, -1, -1)  # [batch_size, num_selected_cases, feature_dim]\n","        elementwise_distance = (query_expanded - case_expanded) ** 2  # Shape: [batch_size, num_selected_cases, feature_dim]\n","\n","        # Apply global-local weighting if applicable\n","        if self.glocal_weightor is not None:\n","            glocal_weights = self.glocal_weights[case_indices]  # [num_selected_cases, set_dim]\n","            elementwise_distance = self.glocal_weightor(elementwise_distance, glocal_weights)  # Weighted distances\n","\n","        distances = torch.sqrt(torch.relu(torch.sum(elementwise_distance, dim=-1)))  # [batch_size, num_selected_cases]\n","        # Convert distances to activations\n","        activations = self.biases[case_indices] - torch.sqrt(distances)  # [batch_size, num_selected_cases]\n","        activations = scaled_sigmoid(activations) * self.weights[case_indices]  # Scale by case-specific weights\n","\n","        # Multiply activations by labels\n","        selected_labels = self.labels[case_indices]  # [num_selected_cases, num_classes]\n","        weighted_activations = activations.unsqueeze(2) * selected_labels.unsqueeze(0)  # [batch_size, num_selected_cases, num_classes]\n","\n","        # Sum over cases to produce predictions\n","        final_predictions = weighted_activations.sum(dim=1)  # [batch_size, num_classes]\n","        predicted_class = final_predictions.argmax(dim=1)  # [batch_size]\n","\n","        # Explanation (Top-k cases)\n","        most_activated_cases, most_activated_case_labels, most_activated_activations = None, None, None\n","        if self.explanation_mode:\n","            top_k_activations, top_k_indices = torch.topk(activations, self.top_k, dim=1)  # [batch_size, top_k]\n","            most_activated_cases = [self.cases[case_indices[idx]] for idx in top_k_indices]\n","            most_activated_case_labels = [self.labels[case_indices[idx]] for idx in top_k_indices]\n","            most_activated_activations = top_k_activations\n","\n","        return final_predictions, predicted_class, most_activated_cases, most_activated_case_labels, most_activated_activations\n"]},{"cell_type":"markdown","metadata":{"id":"LpR7hv0_HIsD"},"source":["Debugging code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Z16yaz5hVfG"},"outputs":[],"source":["# CNs = CaseNetsClassifier([exampleCN0])\n","# CNs = CaseNetsClassifier([exampleCN0, exampleCN1])\n","# CNs = CaseNetsClassifier([exampleCN0, exampleCN1], top_case_enabled=True)\n","# CNs.eval()\n","# example_queries = Xs[0:2]\n","# final_predictions, predicted_class = CNs(example_queries)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S_hxHspW_nF3"},"outputs":[],"source":["# final_predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f3GEIoYi_pHn"},"outputs":[],"source":["# predicted_class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HBBhj1VvDDlo"},"outputs":[],"source":["# for name, param in CNs.named_parameters():\n","#     print(f\"Parameter name: {name}\")\n","#     print(f\"Parameter data: {param.data}\")\n","#     print(f\"Requires gradient: {param.requires_grad}\")\n","#     print(\"------\")\n"]},{"cell_type":"markdown","metadata":{"id":"GFNIcN8hbJWw"},"source":["# MANUAL RUN"]},{"cell_type":"markdown","metadata":{"id":"jmbLMmPmvupr"},"source":["## Training Case Network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C0IG_41dbJWx"},"outputs":[],"source":["# feature_extractor = iniitialize_feature_extractor()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"twO0QVu0bJWx","outputId":"a44363ce-c3e6-4a53-eb53-fb3f2a5a3bfa"},"outputs":[{"data":{"text/plain":["100"]},"execution_count":125,"metadata":{},"output_type":"execute_result"}],"source":["cfg.batch_size"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6pk1qdXrbJWx","outputId":"a0d60d69-8087-414f-a08c-76a064ffb5da"},"outputs":[{"data":{"text/plain":["{'ca_weight_sharing': False, 'top_case_enabled': False, 'training_epochs': 1000, 'learning_rate': 0.01, 'batch_size': 100, 'top_k': 5, 'class_weight_sharing': True, 'patience': 7, 'discount': 100, 'PATH': './checkpoints/classifier_svhn.h5'}"]},"execution_count":126,"metadata":{},"output_type":"execute_result"}],"source":["cfg.PATH = os.path.join(folder_name, f'checkpoints/classifier_{dataset_name}.h5')\n","cfg.patience = 7\n","cfg"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1736959413019,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":300},"id":"GS1vkeXb-W49","outputId":"e3bd747e-c64f-4183-a35c-471a454363a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["False\n","False\n","False\n","False\n","False\n","False\n"]}],"source":["for param in feature_extractor.parameters():\n","    print(param.requires_grad)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f_c97vQpbJWx","outputId":"fc604ae6-0264-4480-b437-1d3f66a91604"},"outputs":[{"data":{"text/plain":["tensor([[[[-0.0563, -0.1588,  0.1131],\n","          [-0.1981,  0.0149,  0.1029],\n","          [-0.2386, -0.0229, -0.0579]],\n","\n","         [[-0.2616,  0.0847, -0.0306],\n","          [ 0.0177, -0.1106,  0.2081],\n","          [-0.2164,  0.1091, -0.0608]],\n","\n","         [[ 0.1246,  0.0902,  0.2780],\n","          [-0.0596,  0.2253,  0.2036],\n","          [-0.2660, -0.1333,  0.2691]]]], device='cuda:1')"]},"execution_count":128,"metadata":{},"output_type":"execute_result"}],"source":["feature_extractor.state_dict()['0.weight'][:1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ELS7DMrCCvVK"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from sklearn.model_selection import KFold, train_test_split\n","from sklearn.metrics import accuracy_score\n","import os\n","import numpy as np\n","\n","def train_model(X_train, y_train, X_val, y_val, cfg, glocal_fw_set_num=glocal_fw_set_num):\n","    global debug_print\n","    \"\"\"\n","    Train the NN-kNN model using the provided train/validation split.\n","\n","    Args:\n","        X_train: Training feature tensor.\n","        y_train: Training labels.\n","        X_val: Validation feature tensor.\n","        y_val: Validation labels.\n","        cfg: Configuration object with training hyperparameters.\n","        glocal_fw_set_num: Number of sets for the global feature weightor.\n","\n","    Returns:\n","        best_accuracy: The best accuracy achieved during training.\n","        glocal_weightor: The trained global feature weightor.\n","    \"\"\"\n","    # Move data to the appropriate device\n","    X_train = X_train.to(device)\n","    y_train = y_train.to(device)\n","    # X_val = X_val.to(device)\n","    # y_val = y_val.to(device)\n","\n","    # DataLoader for batching\n","    train_loader = torch.utils.data.DataLoader(\n","        torch.utils.data.TensorDataset(X_train, y_train),\n","        batch_size=cfg.batch_size,\n","        shuffle=True\n","    )\n","    val_loader = torch.utils.data.DataLoader(\n","        torch.utils.data.TensorDataset(X_val, y_val),\n","        batch_size=cfg.batch_size,\n","        shuffle=False\n","    )\n","\n","    # Initialize the global feature weightor\n","    glocal_weightor = GlocalFeatureWeight(feature_dim, glocal_fw_set_num)\n","    glocal_weightor.to(device)\n","\n","    print(glocal_weightor.state_dict())\n","    # Initialize CaseNet instances for the training set\n","    # case_nets = [CaseNet(X_train[i], ys_onehot[i], feature_weightor=glocal_weightor) for i in range(len(X_train))]\n","    # model = CaseNetsClassifier(case_nets, glocal_weightor, feature_extractor)\n","\n","    model = CaseNetsClassifier(X_train, ys_onehot, feature_extractor, glocal_weightor)\n","    model.to(device)\n","\n","    print(model.feature_extractor.state_dict()['0.weight'][:1])\n","    # Separate parameters for different learning rates\n","    feature_extractor_params = list()\n","    if(feature_extractor is not None):\n","        feature_extractor_params = list(feature_extractor.parameters())\n","    glocal_weightor_params = list(model.glocal_weightor.parameters())\n","    #print out number of parameters here\n","\n","    shared_params_ids = {id(param) for param in feature_extractor_params + glocal_weightor_params}\n","    # case_net_params = [param for case_net in model.case_nets for param in case_net.parameters() if id(param) not in shared_params_ids]\n","    case_net_params = [param for param in model.parameters() if id(param) not in shared_params_ids]\n","    print(\"Number of feature extractor parameters:\", len(feature_extractor_params))\n","    for param in feature_extractor_params:\n","        print(param.shape)\n","    print(\"Number of glocal weightor parameters:\", len(glocal_weightor_params))\n","    for param in glocal_weightor_params:\n","        print(param.shape)\n","    print(\"Number of case_net_params:\", len(case_net_params))\n","    for param in case_net_params:\n","        print(param.shape)\n","    print(\"*****************\")\n","    # print(model.state_dict())\n","\n","\n","    optimizer = torch.optim.Adam([\n","        # {'params': feature_extractor_params, 'lr': 1e-3},\n","        {'params': glocal_weightor_params, 'lr': 1e-4}, #I tried 1e-3 here, this is better.\n","        {'params': case_net_params, 'lr': 1e-4}\n","    ], weight_decay=1e-6)\n","\n","    patience_counter = 0\n","    best_accuracy = 0\n","    best_val_loss = float('inf')\n","    best_found = False\n","    best_epoch = 0\n","    print(f\"Training started for {cfg.training_epochs} epochs with batch size {cfg.batch_size}\")\n","\n","    for epoch in range(cfg.training_epochs):\n","        if best_found:\n","            break\n","        running_loss = 0.0\n","        total_batches = len(train_loader)\n","\n","        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n","            model.train()\n","            # break\n","            optimizer.zero_grad()\n","            # print(X_batch.shape)\n","            final_predictions, _, _, _,_= model(X_batch)\n","            # print(\"Checking final pred\")\n","            # print(final_predictions)\n","            # print(\"Checking y_batch\")\n","            # print(y_batch)\n","            loss = criterion(final_predictions, y_batch)\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","            # if batch_idx % 10 == 0 or batch_idx == total_batches - 1:\n","            #     # avg_loss = running_loss / (batch_idx + 1)\n","            #     # print(f\"[Epoch {epoch+1}/{cfg.training_epochs}] Batch {batch_idx+1}/{total_batches} - Loss: {avg_loss:.4f}\")\n","            #     print(f\"[Epoch {epoch+1}/{cfg.training_epochs}] Batch {batch_idx+1}/{total_batches} - Loss: {loss.item():.4f}\")\n","            #     # Evaluate on the validation set\n","        print(f\"[Epoch {epoch+1}/{cfg.training_epochs}] - Loss: {loss.item():.4f}\")\n","\n","        model.eval()\n","        with torch.no_grad():\n","            final_predictions = torch.empty((0, 10))\n","            predicted_classes = torch.empty((0,))\n","            for batch_idx, (X_batch, _) in enumerate(val_loader):\n","                X_batch = X_batch.to(device)\n","\n","                final_prediction, predicted_class,_,_, _ = model(X_batch)\n","\n","                final_predictions = torch.cat((final_predictions, final_prediction.cpu()), dim=0)\n","                predicted_classes = torch.cat((predicted_classes, predicted_class.cpu()), dim=0)\n","\n","            accuracy = accuracy_score(y_val, predicted_classes.cpu().numpy())\n","            val_loss = criterion(final_predictions, y_val).item()\n","\n","        print(f\"Epoch {epoch+1} - Validation Accuracy: {accuracy:.4f}\")\n","        print(f\"Epoch {epoch+1} - Validation Loss: {val_loss:.4f}\")\n","\n","        # Early stopping and model saving\n","        # if epoch == 0 or accuracy > best_val_loss:\n","        #     best_accuracy = accuracy\n","        #     torch.save(model.state_dict(), cfg.PATH)\n","        #     print(f\"New best accuracy {accuracy:.4f} - Model saved.\")\n","        #     patience_counter = 0\n","        # else:\n","        #     patience_counter += 1\n","        if epoch == 0 or best_accuracy < accuracy:\n","            #Note: shouldn't use val_loss here because it's the validation set. we are training on training loss, not validation loss.\n","            #  or (val_loss < best_val_loss and  best_accuracy == accuracy) : #or val_loss < best_val_loss or best_accuracy < accuracy:\n","            best_val_loss = val_loss\n","            best_accuracy = accuracy\n","            # best_accuracy = accuracy_score(y_val.cpu().numpy(), predicted_class.cpu().numpy())\n","            torch.save(model.state_dict(), cfg.PATH)\n","            print(f\"New best loss {val_loss:.4f} - Model saved.\")\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","            print(f\"so far, best loss: {best_val_loss:.4f}\")\n","            print(f\"so far, best acc: {best_accuracy:.4f}\")\n","        if patience_counter > cfg.patience:\n","            print(\"Patience exceeded. Loading best model.\")\n","            model.load_state_dict(torch.load(cfg.PATH))\n","            best_found = True\n","            break\n","\n","    print(\"Training completed. Best Acc: \", best_accuracy)\n","    print(\"Final global feature weights:\", glocal_weightor.feature_weights)\n","    return best_accuracy, glocal_weightor, model\n","\n","\n","def cross_validate(Xs, ys, cfg, k_folds=10):\n","    \"\"\"\n","    Perform k-fold cross-validation using the train_model function.\n","\n","    Args:\n","        Xs: Feature tensor.\n","        ys: Labels.\n","        cfg: Configuration object.\n","        k_folds: Number of cross-validation folds.\n","\n","    Returns:\n","        best_accuracies: List of best accuracies for each fold.\n","    \"\"\"\n","    k_fold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n","    best_accuracies = []\n","    last_model = None\n","    for train_index, test_index in k_fold.split(Xs):\n","        X_train, X_test = Xs[train_index], Xs[test_index]\n","        y_train, y_test = ys[train_index], ys[test_index]\n","\n","        best_accuracy, _, last_model = train_model(X_train, y_train, X_test, y_test, cfg)\n","        best_accuracies.append(best_accuracy)\n","        # break\n","\n","    print(\"Cross-validation results:\", best_accuracies)\n","    print(f\"Average accuracy: {np.mean(best_accuracies):.3f}\")\n","    print(f\"Standard deviation: {np.std(best_accuracies):.3f}\")\n","    print(f\"{np.mean(best_accuracies):.3f} ({np.std(best_accuracies):.3f})\")\n","    return best_accuracies, last_model\n","\n","\n","def train_with_given_split(X_train, y_train, X_test, y_test, cfg):\n","    \"\"\"\n","    Train NN-kNN directly with a provided train/test split.\n","\n","    Args:\n","        X_train: Training feature tensor.\n","        y_train: Training labels.\n","        X_test: Test feature tensor.\n","        y_test: Test labels.\n","        cfg: Configuration object.\n","    \"\"\"\n","    best_accuracy, glocal_weightor, model = train_model(X_train, y_train, X_test, y_test, cfg)\n","    print(f\"Accuracy on provided split: {best_accuracy:.3f}\")\n","    #print(\"Final global feature weights:\", glocal_weightor.feature_weights)\n","    return best_accuracy, glocal_weightor, model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fFUYUU6NJos7"},"outputs":[],"source":["\n","# # Option 1: Cross-validation\n","# feature_extractor = iniitialize_feature_extractor()\n","# best_accuracies, last_model = cross_validate(Xs, ys, cfg)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VpjoGCMMbJWy"},"outputs":[],"source":["import gc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FuG2l9NGbJWy","outputId":"08fc1dcd-707a-4467-812d-3e95d80dc04b"},"outputs":[{"name":"stdout","output_type":"stream","text":["OrderedDict([('feature_weights', tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","         1., 1.]], device='cuda:1'))])\n","tensor([[[[-0.0563, -0.1588,  0.1131],\n","          [-0.1981,  0.0149,  0.1029],\n","          [-0.2386, -0.0229, -0.0579]],\n","\n","         [[-0.2616,  0.0847, -0.0306],\n","          [ 0.0177, -0.1106,  0.2081],\n","          [-0.2164,  0.1091, -0.0608]],\n","\n","         [[ 0.1246,  0.0902,  0.2780],\n","          [-0.0596,  0.2253,  0.2036],\n","          [-0.2660, -0.1333,  0.2691]]]], device='cuda:1')\n","Number of feature extractor parameters: 6\n","torch.Size([32, 3, 3, 3])\n","torch.Size([32])\n","torch.Size([64, 32, 3, 3])\n","torch.Size([64])\n","torch.Size([128, 4096])\n","torch.Size([128])\n","Number of glocal weightor parameters: 1\n","torch.Size([1, 128])\n","Number of case_net_params: 3\n","torch.Size([73257])\n","torch.Size([73257])\n","torch.Size([73257, 1])\n","*****************\n","Training started for 1000 epochs with batch size 100\n","[Epoch 1/1000] - Loss: 2.1931\n","Epoch 1 - Validation Accuracy: 0.3565\n","Epoch 1 - Validation Loss: 2.1956\n","New best loss 2.1956 - Model saved.\n","[Epoch 2/1000] - Loss: 2.1034\n","Epoch 2 - Validation Accuracy: 0.3455\n","Epoch 2 - Validation Loss: 2.1439\n","so far, best loss: 2.1956\n","so far, best acc: 0.3565\n","[Epoch 3/1000] - Loss: 2.1411\n","Epoch 3 - Validation Accuracy: 0.3468\n","Epoch 3 - Validation Loss: 2.1035\n","so far, best loss: 2.1956\n","so far, best acc: 0.3565\n","[Epoch 4/1000] - Loss: 2.0520\n","Epoch 4 - Validation Accuracy: 0.3321\n","Epoch 4 - Validation Loss: 2.0792\n","so far, best loss: 2.1956\n","so far, best acc: 0.3565\n","[Epoch 5/1000] - Loss: 2.1457\n","Epoch 5 - Validation Accuracy: 0.3257\n","Epoch 5 - Validation Loss: 2.0666\n","so far, best loss: 2.1956\n","so far, best acc: 0.3565\n","[Epoch 6/1000] - Loss: 2.1204\n","Epoch 6 - Validation Accuracy: 0.3156\n","Epoch 6 - Validation Loss: 2.0586\n","so far, best loss: 2.1956\n","so far, best acc: 0.3565\n","[Epoch 7/1000] - Loss: 2.0316\n","Epoch 7 - Validation Accuracy: 0.3068\n","Epoch 7 - Validation Loss: 2.0504\n","so far, best loss: 2.1956\n","so far, best acc: 0.3565\n","[Epoch 8/1000] - Loss: 1.9788\n","Epoch 8 - Validation Accuracy: 0.3102\n","Epoch 8 - Validation Loss: 2.0431\n","so far, best loss: 2.1956\n","so far, best acc: 0.3565\n","[Epoch 9/1000] - Loss: 1.9896\n","Epoch 9 - Validation Accuracy: 0.2987\n","Epoch 9 - Validation Loss: 2.0380\n","so far, best loss: 2.1956\n","so far, best acc: 0.3565\n","Patience exceeded. Loading best model.\n","Training completed. Best Acc:  0.3564843269821758\n","Final global feature weights: Parameter containing:\n","tensor([[0.9386, 0.9313, 1.0657, 1.0677, 0.9334, 0.9325, 1.0650, 0.9327, 1.0423,\n","         1.0676, 0.9335, 1.0677, 0.9365, 1.0631, 0.9323, 1.0675, 0.9333, 0.9337,\n","         1.0668, 1.0513, 0.9340, 0.9363, 0.9349, 1.0672, 0.9353, 1.0647, 0.9343,\n","         0.9347, 1.0653, 1.0606, 0.9544, 0.9320, 1.0627, 0.9319, 1.0672, 0.9352,\n","         1.0652, 0.9473, 0.9327, 0.9341, 1.0670, 1.0649, 0.9340, 1.0644, 0.9344,\n","         1.0232, 0.9355, 1.0288, 0.9337, 1.0636, 0.9325, 1.0585, 0.9920, 1.0620,\n","         0.9330, 0.9330, 1.0600, 1.0637, 0.9324, 0.9322, 0.9328, 0.9327, 0.9323,\n","         0.9336, 1.0670, 0.9332, 1.0664, 1.0645, 0.9323, 1.0648, 0.9327, 0.9330,\n","         0.9335, 0.9346, 0.9337, 1.0654, 0.9332, 1.0665, 1.0626, 0.9341, 0.9347,\n","         1.0273, 0.9335, 0.9332, 0.9327, 0.9347, 0.9341, 0.9412, 0.9352, 0.9359,\n","         1.0615, 1.0634, 0.9391, 1.0647, 1.0305, 1.0330, 1.0649, 0.9348, 0.9320,\n","         0.9338, 0.9375, 1.0649, 0.9376, 1.0673, 0.9330, 1.0667, 1.0660, 0.9393,\n","         1.0588, 0.9343, 1.0657, 0.9340, 0.9343, 0.9382, 1.0666, 1.0547, 0.9324,\n","         0.9330, 1.0657, 0.9339, 0.9337, 0.9331, 0.9336, 0.9321, 0.9388, 0.9330,\n","         0.9338, 0.9604]], device='cuda:1', requires_grad=True)\n","Accuracy on provided split: 0.356\n","OrderedDict([('feature_weights', tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","         1., 1.]], device='cuda:1'))])\n","tensor([[[[-0.0563, -0.1588,  0.1131],\n","          [-0.1981,  0.0149,  0.1029],\n","          [-0.2386, -0.0229, -0.0579]],\n","\n","         [[-0.2616,  0.0847, -0.0306],\n","          [ 0.0177, -0.1106,  0.2081],\n","          [-0.2164,  0.1091, -0.0608]],\n","\n","         [[ 0.1246,  0.0902,  0.2780],\n","          [-0.0596,  0.2253,  0.2036],\n","          [-0.2660, -0.1333,  0.2691]]]], device='cuda:1')\n","Number of feature extractor parameters: 6\n","torch.Size([32, 3, 3, 3])\n","torch.Size([32])\n","torch.Size([64, 32, 3, 3])\n","torch.Size([64])\n","torch.Size([128, 4096])\n","torch.Size([128])\n","Number of glocal weightor parameters: 1\n","torch.Size([1, 128])\n","Number of case_net_params: 3\n","torch.Size([73257])\n","torch.Size([73257])\n","torch.Size([73257, 1])\n","*****************\n","Training started for 1000 epochs with batch size 100\n","[Epoch 1/1000] - Loss: 2.1783\n","Epoch 1 - Validation Accuracy: 0.3554\n","Epoch 1 - Validation Loss: 2.1935\n","New best loss 2.1935 - Model saved.\n","[Epoch 2/1000] - Loss: 2.0954\n","Epoch 2 - Validation Accuracy: 0.3545\n","Epoch 2 - Validation Loss: 2.1411\n","so far, best loss: 2.1935\n","so far, best acc: 0.3554\n","[Epoch 3/1000] - Loss: 2.0482\n","Epoch 3 - Validation Accuracy: 0.3345\n","Epoch 3 - Validation Loss: 2.0996\n","so far, best loss: 2.1935\n","so far, best acc: 0.3554\n","[Epoch 4/1000] - Loss: 2.0916\n","Epoch 4 - Validation Accuracy: 0.3259\n","Epoch 4 - Validation Loss: 2.0798\n","so far, best loss: 2.1935\n","so far, best acc: 0.3554\n","[Epoch 5/1000] - Loss: 2.1293\n","Epoch 5 - Validation Accuracy: 0.3244\n","Epoch 5 - Validation Loss: 2.0656\n","so far, best loss: 2.1935\n","so far, best acc: 0.3554\n","[Epoch 6/1000] - Loss: 2.0540\n","Epoch 6 - Validation Accuracy: 0.3063\n","Epoch 6 - Validation Loss: 2.0563\n","so far, best loss: 2.1935\n","so far, best acc: 0.3554\n","[Epoch 7/1000] - Loss: 2.1005\n","Epoch 7 - Validation Accuracy: 0.3022\n","Epoch 7 - Validation Loss: 2.0497\n","so far, best loss: 2.1935\n","so far, best acc: 0.3554\n","[Epoch 8/1000] - Loss: 2.0346\n","Epoch 8 - Validation Accuracy: 0.3045\n","Epoch 8 - Validation Loss: 2.0433\n","so far, best loss: 2.1935\n","so far, best acc: 0.3554\n","[Epoch 9/1000] - Loss: 1.9959\n","Epoch 9 - Validation Accuracy: 0.3017\n","Epoch 9 - Validation Loss: 2.0380\n","so far, best loss: 2.1935\n","so far, best acc: 0.3554\n","Patience exceeded. Loading best model.\n","Training completed. Best Acc:  0.3554087277197296\n","Final global feature weights: Parameter containing:\n","tensor([[0.9377, 0.9326, 1.0648, 1.0671, 0.9346, 0.9338, 1.0653, 0.9334, 1.0424,\n","         1.0676, 0.9338, 1.0676, 0.9377, 1.0633, 0.9338, 1.0688, 0.9336, 0.9354,\n","         1.0679, 1.0511, 0.9347, 0.9382, 0.9345, 1.0672, 0.9354, 1.0653, 0.9337,\n","         0.9365, 1.0668, 1.0611, 0.9589, 0.9330, 1.0647, 0.9326, 1.0661, 0.9361,\n","         1.0637, 0.9483, 0.9337, 0.9365, 1.0673, 1.0652, 0.9366, 1.0655, 0.9350,\n","         1.0228, 0.9375, 1.0316, 0.9354, 1.0666, 0.9367, 1.0611, 0.9914, 1.0649,\n","         0.9359, 0.9356, 1.0625, 1.0671, 0.9337, 0.9327, 0.9335, 0.9350, 0.9326,\n","         0.9367, 1.0669, 0.9346, 1.0646, 1.0666, 0.9339, 1.0654, 0.9346, 0.9346,\n","         0.9355, 0.9372, 0.9359, 1.0669, 0.9356, 1.0668, 1.0635, 0.9354, 0.9388,\n","         1.0261, 0.9340, 0.9351, 0.9356, 0.9370, 0.9370, 0.9420, 0.9365, 0.9378,\n","         1.0644, 1.0624, 0.9436, 1.0635, 1.0313, 1.0322, 1.0646, 0.9359, 0.9325,\n","         0.9358, 0.9389, 1.0651, 0.9389, 1.0672, 0.9347, 1.0664, 1.0676, 0.9368,\n","         1.0620, 0.9367, 1.0678, 0.9353, 0.9363, 0.9398, 1.0672, 1.0547, 0.9340,\n","         0.9358, 1.0642, 0.9355, 0.9332, 0.9352, 0.9355, 0.9334, 0.9371, 0.9342,\n","         0.9351, 0.9625]], device='cuda:1', requires_grad=True)\n","Accuracy on provided split: 0.355\n","OrderedDict([('feature_weights', tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","         1., 1.]], device='cuda:1'))])\n","tensor([[[[-0.0563, -0.1588,  0.1131],\n","          [-0.1981,  0.0149,  0.1029],\n","          [-0.2386, -0.0229, -0.0579]],\n","\n","         [[-0.2616,  0.0847, -0.0306],\n","          [ 0.0177, -0.1106,  0.2081],\n","          [-0.2164,  0.1091, -0.0608]],\n","\n","         [[ 0.1246,  0.0902,  0.2780],\n","          [-0.0596,  0.2253,  0.2036],\n","          [-0.2660, -0.1333,  0.2691]]]], device='cuda:1')\n","Number of feature extractor parameters: 6\n","torch.Size([32, 3, 3, 3])\n","torch.Size([32])\n","torch.Size([64, 32, 3, 3])\n","torch.Size([64])\n","torch.Size([128, 4096])\n","torch.Size([128])\n","Number of glocal weightor parameters: 1\n","torch.Size([1, 128])\n","Number of case_net_params: 3\n","torch.Size([73257])\n","torch.Size([73257])\n","torch.Size([73257, 1])\n","*****************\n","Training started for 1000 epochs with batch size 100\n","[Epoch 1/1000] - Loss: 2.2068\n","Epoch 1 - Validation Accuracy: 0.3555\n","Epoch 1 - Validation Loss: 2.1950\n","New best loss 2.1950 - Model saved.\n","[Epoch 2/1000] - Loss: 2.1685\n","Epoch 2 - Validation Accuracy: 0.3559\n","Epoch 2 - Validation Loss: 2.1389\n","New best loss 2.1389 - Model saved.\n","[Epoch 3/1000] - Loss: 2.0905\n","Epoch 3 - Validation Accuracy: 0.3436\n","Epoch 3 - Validation Loss: 2.1024\n","so far, best loss: 2.1389\n","so far, best acc: 0.3559\n","[Epoch 4/1000] - Loss: 2.1567\n","Epoch 4 - Validation Accuracy: 0.3252\n","Epoch 4 - Validation Loss: 2.0796\n","so far, best loss: 2.1389\n","so far, best acc: 0.3559\n","[Epoch 5/1000] - Loss: 2.0766\n","Epoch 5 - Validation Accuracy: 0.3203\n","Epoch 5 - Validation Loss: 2.0650\n","so far, best loss: 2.1389\n","so far, best acc: 0.3559\n","[Epoch 6/1000] - Loss: 2.0941\n","Epoch 6 - Validation Accuracy: 0.3074\n","Epoch 6 - Validation Loss: 2.0566\n","so far, best loss: 2.1389\n","so far, best acc: 0.3559\n","[Epoch 7/1000] - Loss: 2.0144\n","Epoch 7 - Validation Accuracy: 0.3055\n","Epoch 7 - Validation Loss: 2.0510\n","so far, best loss: 2.1389\n","so far, best acc: 0.3559\n","[Epoch 8/1000] - Loss: 2.0572\n","Epoch 8 - Validation Accuracy: 0.3010\n","Epoch 8 - Validation Loss: 2.0434\n","so far, best loss: 2.1389\n","so far, best acc: 0.3559\n","[Epoch 9/1000] - Loss: 2.0802\n"]}],"source":["# Option 2: Direct train-test split (when not using cross-validation)\n","best_accuracies = []\n","for i in range(8):\n","    # feature_extractor = iniitialize_feature_extractor()\n","    gc.collect()\n","    # For CUDA tensors\n","    if torch.cuda.is_available():\n","      torch.cuda.empty_cache()\n","    # X_train, X_test, y_train, y_test = train_test_split(Xs, ys, test_size=0.1, random_state=cfg.random_seed)\n","    best_accuracy, glocal_weightor, last_model = train_with_given_split(X_train, y_train, X_test, y_test, cfg)\n","    best_accuracies.append(best_accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xIiYtDICbJWy","outputId":"cd4b7f33-0345-4a21-da8a-6dc5c44fc116"},"outputs":[{"data":{"text/plain":["500"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["num_samples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jN6q55K8bJWy","outputId":"93fe74bf-a934-466f-b0c7-99c814cd8c81"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average accuracy across all folds: 0.2864839428395821\n","Standard deviation of accuracy: 0.11243832022691017\n"]}],"source":["# prompt: average of best_accuracies\n","\n","average_accuracy = np.mean(best_accuracies)\n","print(f\"Average accuracy across all folds: {average_accuracy}\")\n","print(f\"Standard deviation of accuracy: {np.std(best_accuracies)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2tOydWTHbJWy","outputId":"bf87462c-5261-44f4-c932-decaf664a719"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average accuracy:0.286\n"]}],"source":["print(f\"Average accuracy:{np.mean(best_accuracies):.3f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aZgrZ6s_bJWy","outputId":"c54fbb37-2db7-4f8c-c2db-012a0bad3c04"},"outputs":[{"data":{"text/plain":["(0.5820912722802705, 0.2329440688383528)"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["max(best_accuracies), min(best_accuracies)"]},{"cell_type":"markdown","metadata":{"id":"j9Ueijo6OGP1"},"source":["## Load Model From Checkpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cUuWejcPPEsn"},"outputs":[],"source":["# Updated to reflect the removal of CaseNet\n","def load_model_cns(X_train, y_train, cfg):\n","    \"\"\"\n","    Load a CaseNetsClassifier model with the provided training data and configuration.\n","\n","    Args:\n","        X_train (torch.Tensor): Tensor of training cases (e.g., images or sequences).\n","        y_train (torch.Tensor): Tensor of one-hot encoded labels for each case.\n","        cfg: Configuration object containing model parameters.\n","\n","    Returns:\n","        CaseNetsClassifier: The loaded model.\n","    \"\"\"\n","    # Define the global-local weightor\n","    glocal_weightor = GlocalFeatureWeight(feature_dim=feature_dim, set_dim=glocal_fw_set_num)\n","    # glocal_weightor.load_state_dict(torch.load(feature_weightor_path))  # Optional: Load pre-trained weights\n","    glocal_weightor.to(device)\n","\n","    # Initialize the CaseNetsClassifier directly with cases and labels\n","    model = CaseNetsClassifier(\n","        cases=X_train,\n","        labels=y_train,\n","        feature_extractor=feature_extractor,  # Pass the feature extractor\n","        glocal_weightor=glocal_weightor  # Pass the global-local weightor\n","    )\n","\n","    # Load the model's weights\n","    model.load_state_dict(torch.load(cfg.PATH))\n","    model.to(device)\n","    model.eval()\n","\n","    return model\n"]},{"cell_type":"markdown","metadata":{"id":"o9TiTSXbnoyn"},"source":["note: loading the cifar10 model takes about 1 hour"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"knVNy1AXOFw9"},"outputs":[],"source":["cfg.PATH = os.path.join(folder_name, f'checkpoints/classifier_{dataset_name}.h5')\n","\n","model = load_model_cns(X_train,y_train,cfg)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"geCINROvItc1"},"outputs":[],"source":["model.sample_num"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qhVk1AJBT-h1"},"outputs":[],"source":["model.state_dict()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9j5C3HOCJ_6_"},"outputs":[],"source":["# prompt: garbage collection\n","\n","import gc\n","\n","# Force garbage collection\n","gc.collect()\n","\n","# For CUDA tensors\n","if torch.cuda.is_available():\n","  torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fGbLX3AXbJWz"},"outputs":[],"source":["next(model.parameters()).is_cuda"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"crtSSc0RUFGM"},"outputs":[],"source":["from torch.utils.data import DataLoader, TensorDataset # Import TensorDataset\n","\n","\n","X_val = X_test.to(device)\n","y_val = y_test.to(device)\n","batch_size = 128  # Or an even smaller size if needed\n","\n","# Create a DataLoader for your validation data\n","val_dataset = TensorDataset(X_val, y_val)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","final_predictions_list = []\n","predicted_class_list = []\n","\n","with torch.no_grad():\n","    for batch_X, batch_y in val_loader:\n","        batch_final_predictions, batch_predicted_class,_,_ = model(batch_X)\n","        final_predictions_list.append(batch_final_predictions)\n","        predicted_class_list.append(batch_predicted_class)\n","\n","# Concatenate predictions from all batches\n","final_predictions = torch.cat(final_predictions_list, dim=0)\n","predicted_class = torch.cat(predicted_class_list, dim=0)\n","# final_predictions, predicted_class = model(X_val)\n","val_loss = criterion(final_predictions, y_val).item()\n","print(f\"Validation Loss: {val_loss:.4f}\")\n","best_accuracy = accuracy_score(y_val.cpu().numpy(), predicted_class.cpu().numpy())\n","print(f\"Validation Accuracy: {best_accuracy:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e_1vpOHFbJWz"},"outputs":[],"source":["from torch.utils.data import DataLoader, TensorDataset\n","import torch\n","from sklearn.metrics import accuracy_score\n","\n","# Move data to device\n","X_val = X_test.to(device)\n","y_val = y_test.to(device)\n","batch_size = 128  # Or an even smaller size if needed\n","\n","# Create a DataLoader for your validation data\n","val_dataset = TensorDataset(X_val, y_val)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","final_predictions_list = []\n","predicted_class_list = []\n","\n","with torch.no_grad():\n","    for batch_X, batch_y in val_loader:\n","        # Get predictions for the batch\n","        batch_final_predictions, batch_predicted_class, _, _, _ = model(batch_X)\n","        final_predictions_list.append(batch_final_predictions)\n","        predicted_class_list.append(batch_predicted_class)\n","\n","# Concatenate predictions from all batches\n","final_predictions = torch.cat(final_predictions_list, dim=0)\n","predicted_class = torch.cat(predicted_class_list, dim=0)\n","\n","# Compute validation loss\n","val_loss = criterion(final_predictions, y_val).item()\n","print(f\"Validation Loss: {val_loss:.4f}\")\n","\n","# Calculate accuracy for the top-1 predictions\n","best_accuracy = accuracy_score(y_val.cpu().numpy(), predicted_class.cpu().numpy())\n","print(f\"Validation Accuracy (Top-1): {best_accuracy:.4f}\")\n","\n","# Calculate Top-k Accuracies (Top-1, Top-2, Top-3)\n","top_k_values = [1, 2, 3]\n","top_k_correct_counts = {k: 0 for k in top_k_values}\n","\n","# Get top-k predictions for each sample\n","top_k_predictions = torch.topk(final_predictions, max(top_k_values), dim=1).indices  # Shape: [num_samples, max_k]\n","\n","for k in top_k_values:\n","    # Check if the correct class is within the top-k predictions\n","    correct_in_top_k = torch.any(top_k_predictions[:, :k] == y_val.unsqueeze(1), dim=1)\n","    top_k_correct_counts[k] = correct_in_top_k.sum().item()\n","\n","# Calculate percentages\n","num_samples = y_val.size(0)\n","for k in top_k_values:\n","    accuracy_k = top_k_correct_counts[k] / num_samples * 100\n","    print(f\"Top-{k} Accuracy: {accuracy_k:.2f}%\")\n"]},{"cell_type":"markdown","metadata":{"id":"aQMTPXLwaBVq"},"source":["# Results Interpretation"]},{"cell_type":"markdown","metadata":{"id":"FeyCa4Nitll8"},"source":["## Inspecting one case"]},{"cell_type":"markdown","metadata":{"id":"k3uBeaYMgI_G"},"source":["### Explanation for SST\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6euPutF8gNnR"},"outputs":[],"source":["query = X_test[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3HCLJLlXgOlM"},"outputs":[],"source":["query.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T01GFgBcghJw"},"outputs":[],"source":["def classify_and_explain_sst(model, query, case_nets, vocab, classes, device='cuda'):\n","    \"\"\"\n","    Classify a query sentence and provide the most activated case as an explanation.\n","\n","    Args:\n","        model (CaseNetsClassifier): Trained model for classification.\n","        query (torch.Tensor): Query tensor of shape [seq_len].\n","        case_nets (list): List of CaseNet objects.\n","        vocab (torchtext.vocab.Vocab): Vocabulary used for numericalization.\n","        classes (list): List of class names for the dataset.\n","        device (str): Device to run the inference on ('cuda' or 'cpu').\n","\n","    Returns:\n","        dict: Results containing predictions and explanation.\n","    \"\"\"\n","    model = model.to(device)\n","    query = query.unsqueeze(0).to(device)  # Add batch dimension [1, seq_len]\n","\n","    # Classify query and get explanation\n","    final_predictions, predicted_class, most_activated_cases, most_activated_activations = model(query)\n","\n","    # Get the most activated case and its label\n","    most_activated_case = most_activated_cases[0].case.cpu().squeeze()\n","    most_activated_label = torch.argmax(most_activated_cases[0].label).item()\n","    most_activated_activation = most_activated_activations[0].item()\n","\n","    # Decode query and most activated case from indices to tokens\n","    def decode(tokens, vocab):\n","        reverse_vocab = {idx: token for token, idx in vocab.items()}  # Create reverse mapping\n","        return \" \".join([reverse_vocab[token.item()] for token in tokens if token.item() != vocab[\"<pad>\"]])\n","\n","    query_text = decode(query.squeeze().cpu(), vocab)\n","    most_activated_case_text = decode(most_activated_case, vocab)\n","\n","    # Return detailed results\n","    return {\n","        \"query\": query_text,\n","        \"query_prediction\": classes[predicted_class.item()],\n","        \"most_activated_case\": most_activated_case_text,\n","        \"most_activated_case_label\": classes[most_activated_label],\n","        \"most_activated_activation\": most_activated_activation\n","    }\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"54dH0sPeg9-0"},"outputs":[],"source":["model = last_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q3DET2iBgqZL"},"outputs":[],"source":["# Example usage\n","# Assume you have a trained CaseNetsClassifier `model`, SST data, and case_nets\n","\n","# Select a query from the test dataset\n","query_idx = 3  # Example test query index\n","query = X_test[query_idx]  # No need to unsqueeze; function handles it\n","classes = [\"Negative\", \"Positive\"]  # SST binary classes\n","classes = [\"Negative\", \"Somewhat Negative\", \"Neutral\", \"Somewhat Positive\", \"Positive\"]\n","# Run the classify_and_explain_sst function\n","results = classify_and_explain_sst(model, query, model.case_nets, vocab, classes)\n","\n","# Print the classification results\n","print(\"Classification Results:\")\n","print(f\"Query Sentence: {results['query']}\")\n","print(f\"Predicted Class: {results['query_prediction']}\")\n","print(f\"Most Activated Case Sentence: {results['most_activated_case']}\")\n","print(f\"Most Activated Case Label: {results['most_activated_case_label']}\")\n","print(f\"Most Activated Activation: {results['most_activated_activation']:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r28NZrjYkszn"},"outputs":[],"source":["# model.sampling_cases = True\n","# model.sample_num = 500"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fY03_oK8Rrit"},"outputs":[],"source":["model.sampling_cases"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UC3GjdG8ssaC"},"outputs":[],"source":["model.sample_num"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3DLq8zuGjDJz"},"outputs":[],"source":["import random\n","random_indices = random.sample(range(len(X_test)), 20)\n","\n","# Loop through the randomly selected queries\n","for i, query_idx in enumerate(random_indices):  # Loop through the first 20 test queries\n","    query = X_test[query_idx]  # Get numericalized query tensor\n","    true_class = y_test[query_idx]  # Get true class label\n","    # Run the classify_and_explain_sst function\n","    results = classify_and_explain_sst(model, query, model.case_nets, vocab, classes)\n","\n","    # Print the classification results\n","    print(f\"--- Example {query_idx + 1} ---\")\n","    print(f\"Query Sentence: {results['query']}\")\n","    print(f\"True Class: {classes[true_class]}\")\n","    print(f\"Predicted Class: {results['query_prediction']}\")\n","    print(f\"Most Activated Case Sentence: {results['most_activated_case']}\")\n","    print(f\"Most Activated Case Label: {results['most_activated_case_label']}\")\n","    print(f\"Most Activated Activation: {results['most_activated_activation']:.4f}\")\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"zd23CxmQle91"},"source":["### 6.0 Explanation for CIFAR10"]},{"cell_type":"markdown","metadata":{"id":"XLS88En2lqdb"},"source":["For CIFAR10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dDKfKBiRlg2T"},"outputs":[],"source":["query = X_test[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1KhzwNellkK7"},"outputs":[],"source":["query.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_tykP0rplrlM"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import torchvision.transforms as transforms\n","\n","def classify_and_explain(model, query, case_nets, classes, device='cuda'):\n","    \"\"\"\n","    Classify a query and provide the most activated case as an explanation.\n","\n","    Args:\n","        model (CaseNetsClassifier): Trained model for classification.\n","        query (torch.Tensor): Query tensor of shape [1, channels, height, width].\n","        case_nets (list): List of CaseNet objects.\n","        classes (list): List of class names for the dataset.\n","        device (str): Device to run the inference on ('cuda' or 'cpu').\n","\n","    Returns:\n","        dict: Results containing predictions and explanation.\n","    \"\"\"\n","    model = model.to(device)\n","    query = query.to(device)\n","\n","    # Classify query and get explanation\n","    final_predictions, predicted_class, most_activated_cases, most_activated_activations = model(query)\n","\n","    # Get the most activated case and its label\n","    most_activated_case = most_activated_cases[0].case.cpu().squeeze()\n","    most_activated_label = torch.argmax(most_activated_cases[0].label).item()\n","    most_activated_activation = most_activated_activations[0].item()\n","\n","    # De-normalize the query and most activated case for visualization\n","    # Single mean and std for all channels\n","    mean, std = 0.4734, 0.2111  # Replace with your computed values\n","\n","    transform = transforms.Compose([\n","        transforms.Normalize(mean=[-mean / std], std=[1 / std]),  # Single value for all channels\n","        transforms.ToPILImage()\n","    ])\n","\n","    query_image = transform(query.cpu().squeeze())\n","    most_activated_image = transform(most_activated_case)\n","\n","    # Visualization\n","    plt.figure(figsize=(5, 2))\n","\n","    # Query Image\n","    plt.subplot(1, 2, 1)\n","    plt.imshow(query_image)\n","    plt.title(f\"Query (Predicted: {classes[predicted_class.item()]})\")\n","    plt.axis('off')\n","\n","    # Most Activated Case\n","    plt.subplot(1, 2, 2)\n","    plt.imshow(most_activated_image)\n","    plt.title(f\"Most Activated Case\\n(Label: {classes[most_activated_label]}, Activation: {most_activated_activation:.4f})\")\n","    plt.axis('off')\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","    # Return detailed results\n","    return {\n","        \"query_prediction\": classes[predicted_class.item()],\n","        \"most_activated_case_label\": classes[most_activated_label],\n","        \"most_activated_activation\": most_activated_activation\n","    }\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L6Z7vqIzlvek"},"outputs":[],"source":["# Example usage\n","# Assume you have a trained CaseNetsClassifier `model`, a CIFAR-10 query, and case_nets\n","\n","query_idx = 3  # Example test query index\n","query = X_test[query_idx].unsqueeze(0)  # Add batch dimension\n","classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]  # CIFAR-10 classes\n","\n","results = classify_and_explain(model, query, model.case_nets, classes)\n","\n","print(\"Classification Results:\")\n","print(f\"Predicted Class: {results['query_prediction']}\")\n","print(f\"Most Activated Case Label: {results['most_activated_case_label']}\")\n","print(f\"Most Activated Activation: {results['most_activated_activation']:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"dmY-zmsanS2G"},"source":["![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAdoAAAC+CAIAAAAdlFkAAAAgAElEQVR4Aey9B1gV19q/PSgCGgtYKRoQlV6kSlOsqCBFkS5FRYp02PQmvfdepSi9KYqoWII10USNJqbnJOeknBiPiTlJ1Kjz8Z15/TH/DW5NDCK4uO6LazF7Zs2aNQ/3fvaa2bMomvyQHiA9QHqA9MAr0APUK9AG0gTSA6QHSA+QHqCJjkkQkB4gPUB64JXoAaLjV+I0kEaQHiA9QHqA6JjEAOkB0gOkB16JHiA6fiVOA2kE6QHSA6QHiI5JDJAeID1AeuCV6AGi41fiNJBGkB4gPUB6gOiYxADpAdIDpAdeiR4gOn4lTgNpBOkB0gOkB4iOSQyQHhjbPeDs7CwpKfmKHMPevXspivryyy9fkfaMrWYQHY+t80Va+9d7gDEFRVFnzpxh1/L48eP58+dTFGViYsJe/hfK33zzTWxs7JUrV55n26KiIoqitLW1n2dlZp1h6/+7dPzrr7/GxsaeOnXq+dszdM3n0fGVK1ccHBzmz58vICAgIiKyZs2a6urqhw8fDq3tdVtCdPy6nfHX93gZUwgJCXl6erJ74dSpUxRFCQoKvriOL126RFHU3r172fU/raynpyclJUVR1Keffvq0dbiWD1v/gwcP7t27x7XmX/jz1q1bFEXFxsb+hW2xyTN1XFFRMXHiRHFx8dDQ0MrKypycnE2bNvHx8SUlJaGS17ZAdPzanvrX7sAZU2zZsmX27Nl//PEHjn/Xrl0aGhqSkpIvU8dffPEFRVEdHR1z5szZs2cPGsO7MKyOeW/y/K++BB1fuHBh4sSJBgYGd+/eZTfs0qVLz/kext5q/JWJjsffOSVHNHwPMDpubW3l4+Pr6elhVrp//76IiEhWVhaXjv/73/8GBgYyH6hlZGQyMjIeP36Meo8dO6avrz9jxow33nhDRkYmPDycpmkmy6ZYPzwUk5CQICIicv/+fU9PzyVLlqBmpnDnzh1/f39JSUkBAQEJCQlHR8dbt249rX4MVjx48EBERMTFxYVd288//ywoKBgUFETT9P3796Ojo9XV1adPnz5lyhQDA4OTJ08yK3/55Zeshv//RaTJN2/etLS0FBERERQU1NDQOHDgALv+GzdurFq1SkhISEJCIiEhoaqqisfY8YYNG/j5+b/66it2DVzljIwMXV3dmTNnCgkJqaurt7a2slcYtueZFe7duxcTE7No0SIBAYH58+cHBwf/LR8a2Hsf6TLR8Uj3MKn/VekBRseXLl3S09NzdHRkmtXV1TVhwoRvvvmGrePHjx+vXr2aj4/P1dW1sLDQ1NSUoih/f39mkxs3bggICGhqaubl5ZWWlnI4nBUrVtA0/f3338fHx1MU5ebmVv+/n88///xpBy8nJ7dz506apvv7+ymKeuedd7DmL7/8oqSkNHHixF27dpWUlCQkJGhpaV25cuVp9UPHNE3v2LFDWFj4/v37qK22tnZgWPzSpUs0Td+6dUtMTCwwMLCkpCQ9PV1WVnbSpEnMSPd///vfkpISiqI2b97MNP7atWs0Td+4cWPGjBkKCgppaWmFhYUrVqzg4+Pr6Ohg6v/uu+/mzJkjIiKyZ8+ejIyMJUuWqKioPE3Hv/7666RJk1avXo22DVuYP3/+7t27CwsLs7OztbW1KYo6dOgQs+bTep6m6UePHhkZGU2ZMsXf37+srMzb25ufn9/c3HzYXbyyC4mOX9lTQxr2N/cAdFxYWDht2rTffvuNpmkrK6tVq1bRNM3WcVdXF0VRiYmJaMHWrVv5+Pg+++wzmqZzcnIoirp16xZeReE5BxMuX75MUdTx48dpmmYuJPr5+aGSmJgYZhwDS5jVaJoetn62jo8ePUpRVHd3N7Y1NjaWlpZm/nz48CHb1Hfu3Jk3b96OHTuYV4cdrFizZo2ysjLSzMePH+vp6SGd9/f3pyjq7bffZmr44YcfZsyY8TQdX7t2jaIo9pGikewCc16YJQ8ePFBSUoLBefR8fX39hAkT2BdpS0tLKYo6d+4cu/JXvEx0/IqfINK8v60HoOMffviBn5+/paXl7t27kydPrqio4NKxm5vbxIkT2eObFy5coCiqoKBgYE2mnsrKykePHnE1blhdcq1D03RAQMC8efNwL0FQUBD7T0VFRVVV1aFbPY+O//jjj9mzZ2/bto3Z/D//+c+kSZOYsRR2hY8ePbp9+/atW7dMTEyWLl3KvDRUx7dv3+bj40tISLjF+omLi6Mo6l//+hdN0zIyMjo6Ouyad+/e/TQdnzlzhqKoqKgo9vo8yv/5z39u3brl6ekpLCzMrMaj583MzBQVFVnNvPXJJ59wvafy2Ncr8hLR8StyIkgzRrwHoGOapjds2GBhYVFTUyMgIHDnzh0uHa9fv37BggXsBv30008URXE4HJqmf/vtN319fYqiZs+ebWNj09zcDC8/j44fPnwoJiZma2v76ZOflpYWiqKOHj3K7FFISMjBwYG9d5SHrZ+dHdM07e7uPm3aNCafrayspCjq6tWrqKGmpkZZWXnSpEkYKV64cCHz6lAdv/3221iNq/Dee+/RNC0oKIhhH6aSvLy8p+n4ObPj7u7uZcuWCQoKYo98fHxM5Tx6Xl5eHuuzC76+vjj2V79AdPzqnyPSwr+nB9g6rqurExQU1NHRwfAie7CCt46Zkcq+vr6AgADGAqtXr2ZS3WF1ydX6Y8eOsX2BspOTE7PmC+qYueLX2dlJ07SRkZGcnBwaUF9fP2BnCwuLurq63t7e48ePr169Gl8hGapj5jMBh8M5PuSH+ejwp3T866+/8vPzY+QBrWIX+vv7+fj4DA0Nq6qqenp6jh8/bm9vP3BdEes8evRo2J6XlZVVVlYe0szjH330EbZ99QuDx/nqt5W0kPTAi/QAW8e//PLL5MmTKYpqbm5m6mTreOhgxcWLFzFYwdWGpKQkDAQzg8I8bqigadrZ2Xnu3Lmt/++PnZ0dhrN5DFYMWz9Xdvzo0SMm+7516xY/Pz9ukKBp2tzcXFpamn2LiJ6eHnT8448/sm+ooGn63//+N0VRQ8c60AN/arCCeXvg5+f/+uuvUQNXwc/Pb/LkyRiqpmmaS8fs9dk9b2xsLCEhwT409ppjpUx0PFbOFGnni/YAW8c0TdfU1OzZswcXjtg6Zi7lJScnY5c2Nja4lHf79m0sp2n68OHDuPp/8+ZNiqJycnLYK7DLv/3227Rp03D1DC+dO3eOoqimpqaBq3Y8LuUNWz+Xjmma9vHxeeONN7KzsymK+vDDD7GXLVu2SEtLY2jl4sWLfHx80PFvv/029FLbypUrZ86c+e2336ISmqZ/+OEH5s8/dSmPpulz585NnDjR0NDwl19+YVd4+fLlmpoamqYDAwOnTJky8P1A5tUvv/xyypQpyI559PzA2aQoqqysjF3tb7/99t///pe95BUvEx2/4ieINO9v6wEuHXPVy9bxo0ePVq1axcfH5+bmVlRUZG5uzr7Rzc/PT01NLSoqqqKiIikpSUJCYv78+T/99BNN0w8ePBAWFpaVla2srGxsbPziiy+49tLU1ERRVFdXF9fyR48ezZkzx9TUlKbpX375RUFBgbnRrbS0NDk5WUdHhxn/Hbb+oTo+e/YsRVHTpk1TVlZm76i6upqiKDMzs7KysrCwMGFhYUVFReiYpmkFBQVRUdGioqLGxsbr168P3HnywQcfiIiIzJo1KywsrLy8PCEhwdjYWEVFhan222+/nTVr1nPe6MZsUlpaOmHCBAkJibCwsKqqqtzcXAsLiwkTJjBvfidOnKAoavny5SUlJXFxcXPnzmXunGO25dHzjx49MjY25uPjs7W1LSgoyM3N9fDwmDlzJnOHH7sTXuUy0fGrfHZI2/7OHnh+HTNODAgIEBcXnzRp0pIlS9hfAzlx4oS5ubm4uLiAgIC4uLidnd0nn3yChh44cEBBQYGfn3/Yb0ubmpoKCQkh+8NWNE27uLhMmjTpxx9/HEhvb9++7e3tLSEhwXyjwdnZmVlO0/TQ+ofq+PHjxwsWLBh6X8Hjx4+Tk5MlJSUFBQXV1NQOHTrEte358+c1NDQEBATYoxaff/65k5OTqKjopEmTJCQkNm3a1NbWhpa///77hoaGz/k1EGard999197enulb5pkVtbW1yNmrqqqWLFkiKCgoJyc3MOwTGxuL7Jh3zz948CAtLU1RUVFQUFBERERDQyMuLu7nn39GU1/9AtHxq3+OSAtJD5AeeC16gOj4tTjN5CBJD5AeePV7gOj41T9HpIWkB0gPvBY9QHT8WpxmcpCkB0gPvPo9QHT86p8j0kLSA6QHXoseIDp+LU4zOUjSA6QHXv0eIDp+9c8RaSHpAdIDr0UPjDcdb9y40dXV9aWdOsP//TC7Yx7gzfsLsn9jw9i7/hurfZ6qSkpKFixYwP4m6zO3SktLk5WVxb2lz1z/aSsYGhoqKio+7dVnLpeUlHR2dn7mak9bgblzeYzOyzmiAcN1//LTOvA1XB4aGvr80yE+r45v3Ljh4ODA3PouJibm4ODwwQcfvGqde/bs2YkTJ2LmMfbsCfz8/AsXLnR0dOTxRPC/cDjsEH9+HQ88gzU2NpZ5kNhf2CmzCXvXf7mS59kwKSmJeR4NVv7999/nzZuXl5eHJbwLP//888yZM6urq7HawPOCvby88OfzF15DHQcHBw9819na2vr5e2ngfzM2NpbrbePvCpgRnT71OY/x3r17ISEhYmJiQkJC2trax44d47Fhe3u7tbX1woULJ0+eLCMjExgYyPWvJykpiQc5MQV3d3d2hcwUJJMnTxYWFra0tOTqWKz52WefMQ+iY38V8Lvvvhv40g3XFCrYhKvwXDpub28XEBAQFRWNjIysrKyMiooSExMTFBQc+l1Prtpf8p/m5uZGRkbYKaNjX1/f+vr66upqb29vAQGBmTNnDsQT1nnBAjvEHz9+/Pvvv+MhtjxqzsjIeNpDCHlsxfUSe9dcL/29f77xxhtDM8qQkBBJScnnfGJLTk7O9OnTf//9dzSM6BhdwbvAPJxeSkpq8uTJ7Ocv896qtbWVoiiuOaHv/++H94bP8+qwT637u6ZPfZ4G0DRta2vLz8/P4XDKysp0dXX5+fnZD57nqmTWrFnKysrR0dEVFRW+vr4CAgJycnJ4VgnzbNWlS5cyc6Awv/FAfZqmu7u7J0yYwEz+kpCQMHv2bAkJCTy1g70vU1PTN954A3Ov4CVra+vly5fjTx6FZ+v4s88+mzJlipycHLsFt27dkpOTmzp16tBv5fPY2fO/NOy3SHlv/u9//5ufn7+yshKrMTpmz7WVn59PURT70TBY+a89auSvOXEc6Jh5tNiJEyfQgTwKKioqeCA6sxrRMY/uYr908uRJiqJOnjw5adIk5iE77FefVh5Wx09b+c8uH1bHf7aSF1mfeQpzRkYGU8nvv/++aNEiXV3dp9XJ9bbEzFbFzDnAbMJ+XMnQShQUFBYvXoxZVK5evTphwoTAwECuNXt7ewUEBKKioobquK2tjY+P73k+lz9bx+7u7hRF9ff3c+3+rbfeoigKc6QPHTxif9mc2ba+vl5dXV1ISEhERMTGxob9nD3mQ+jly5eXL18+efJkPz8/JyenWbNmPXjwgL3fdevWycjIsJegzDwe5R//+AeWDNXxjRs3KIratWvXwDpM8z744AM7OzthYWHMicCjkTRNl5WVSUtLCwkJaWlp9ff3s3U8dLDi5s2bVlZWs2fPFhISkpGRiYiIwH7ZH47w2ecv75qm6a+++urmzZs49qGFgeQ0NjaWeRqAqKjo5s2bmamGaJrmMVkku50DGT07TZ45c+bzPNubmTKZSyU8dNzV1WVsbCwmJiYgICAtLR0fH8/+wIE40dXVFRISkpKSKikpYR8s7/krucaOP/vfD3tzrvIz5+UsKipSUFAQEBAQExPbvXs316fgwsLChQsXDhstXDt62p87d+5UUFCgaXrjxo3r1q3jWu1f//rXjh07mL6SkpLy8PC4f/8+M8DNPnGMjxCr33///cSJE7mmr/7oo4/wBNHbt28HBQUpKSm98cYb06ZNG3hUPx5gzx4AZHbBXCzh+vfnPfErc/Y7OzsVFRUFBAQUFBSOHDnCPrSbN2/ymN40ODh44sSJ7IdRJCcnUxTF9gm7Nq7y3bt3KYpi+5TR8f3794fmZLdv36YoKjg4mF2JoqKiuLg4e8mDBw9kZWWDg4OHfS7KTz/9xMfHl52dzd5k2PKzdSwuLi4lJTXsxlJSUvPnz2de4jofAwu5dJyYmMjHx2djY1NcXBwXFzd79mwpKSmEr6Gh4cCjpObMmePj41NWVtbV1XX8+HGuWb++++67iRMnxsfHD9sYV1fXWbNmsV8aquMDBw5QFBUWFobmKSgomJubFxcXFxUV0TTNu5HM3Ap6enr5+fn+/v7CwsLS0tKGhobMTrl0fO3atenTp8+aNSs8PLysrCwkJIR5vNa1a9fs7OyYxzAyn4yYIHiRXQ9MY2xoaIgnrbA7gSk/fPhwzZo1FEXZ2toWFhampKSsXr0aY008Jousr68XFBRcvnw509Tz58+j8rVr12poaODPpxX27dtHUdT777/PXoGHji0sLKytrTMyMkpKSqysrDAHB7O5oaGhuLj43Llzvb298/PzDQwMKIqqqqpiXn3m/JVcOpb83w+7YezyM+flZCJ87dq1BQUF3t7eEydO1NLSQgJRXFzMPJwsPz8/MDBw5syZixYtQrSwd/S08r1794SFhRMSEmiarqurmzhx4nfffYeVv/nmG3FxcWayztLS0ujoaHl5+Tt37nz++ee+vr4URUVERDBn7fvvv2ciBHtfvXo1Y3nUFhcXN3HiRGbNS5cuLVq0KCwsrKysLD4+XkJCYsaMGcwQ3/NMn8p74leapimKUlVVFRMTS0hIyM3NlZaWnjJlCp6RxKyApqKFKKxdu1ZeXh5/0jTd19dHUdTBgwfZC59WZiZtYn9ElpSUnDx58sBb1MBTnyQlJXNzc7Htt99+S1FUTEwMlgw8UlVLS4uiKPa5SE9Pnzt37s8//zysjmmaXrx4saWlJbuSYcvP0DEzJw1mTOCqwszMbOB9hhnS4q3jf/zjHxMnTkxKSkIN169f5+fnxxLGJqWlpVjh0aNH8+fPt7GxwZLs7Gw+Pr6nDY8YGBhw2YHRcXV19a1bt7799tvDhw9LSUnx8fExA+3M/5KdnR3q593IBw8ezJ07d+nSpfjYUl5ePjBCh7jh0vGKFSumTZvGfpPHSOvQwYoX3PUzdcx8dOB6f0Z72ONoXJNFDuTOw44d0zTt5uY2efJk9N7TCszHN67n2/LQMbsxzFRDU6ZMwV0cTJxkZWUxu7t///7SpUvnzp3LSPCZ81f+KR3zfpjvDz/8ICAgYGRkhNtFCgsLKYpirljev39/1qxZWlpaf/zxB9NU5oG8iJandRd7eVtbG0VRzKXpu3fvCgkJsZ+k7OTkNGHCBPZVI8xwOuxgBbJj5kMeRVHMIzSZPSooKGCejnv37uGgBp6X/+WXXwoKCiINGnawgv3vz3viV8a2AgIC+HDGTNrEzEPINIb9b8XuEKasqKiIpjJLPvjgA4qi2PYYuhWW7Ny5c+LEieyH8JmamqalpXV1dVVVVS1fvpyiqJCQEGb9R48eCQsLr1mzBpv/+OOPzADx5cuXmYXffffdtGnTmEctP03HRkZGXG8hqJBdeIaO//nPf1IUxTXwh+0dHBwGPvszb5vs88GswM6OGZN++umn7LkF5eXl165dy6xsaGgoKCgI0zELQ0ND2VcwNDQ09PX1sXeuArs25qWhH6zmzJlTV1fHvMo076233kI9vBt5/vx5rlP+4MGDGTNm4B+MreMffvhh6JO8saOhOn7BXaPmpxVMTExmz54NNTxttaGTRfLQcWho6MDnuGeO8nt6eg7MScG1Rx46xpp37969desWk1zjw7KhoeHANRz2h0pmOvoLFy7QNP3M+Su5dIx9DVvgPdVFQ0MDRVE9PT3Y9v79+9OnT2eSIOZx8uXl5Xj1jz/+EBERQbRgOY/C5s2bNTU1sYKlpSX+fPTo0fTp05+WJz1Tx8xEIZhF9Pr160Of3U7T9MOHD3/88cdbt26pqKhYWFgwLXmmjofOpcKe+JXRsbGxMY6Lpunp06cHBASwl/AoS0tLb9y4kb3C559/zvup/1h5//79bNtiOQqPHz9ev349Pz//P//5T2YhE+dhYWGffPLJ5cuXV69ezcw0iIuHTk5OqqqqzBvY03RsY2MzZ84c7OVphWfo+JnZMR8fH+NQ3jr29PRkD2ahjOdYGxoaYvpxtJV506utrR24lsqMbfF4A5SXl2e/iQ0kjIyOY2Jijh8/fvLkyffff5/tI0bH7PEm3o1sbGwc+OzJdfFKTU0N/2BsHTNz+bAvF+CgmLFarjsrXnDX7MqHLcvJyfF4J+MxWSQPHYeEhAxENlcyO3Tvf1bHN27csLCwmD59OoKEoii8axoaGr755pvsvTAPLG9sbKRp+pnzV/4pHfOeCC4lJYWiKK7rM0uXLmWMycj65MmT7Kayo4W9fNjynTt3BAUFg4KCnkxw+ikzu8fHH39M0/T3339PUVRkZOSw2z5TxzRNr1+/HpdhoqKi+Pn5b926xdQ24Prs7OzFixczn9+ZE7Fq1Srm1Wfq+JkzDVIU5eHhwW65pKSki4sLewmP8l/Ojvv7+4WEhNavX8/2wNAd9fb2UhRVX1/PvHT//v2dO3dOmDCB6QcjIyMPDw+Koq5cuTLQjRcuXODj48OJfpqOra2t586dO3RfXEueoWOapsXFxTHXLNfGUlJSmHDXxcWFPa3AwFsr8ymV2cTd3Z2Pj4+ZLZE9vSCT1DCftYe9vV9DQ4O5ghEVFSUgIPCf//yHqw3408DAQF1dHX9Cx+w7K9ivMjpGCDKfi3k0ckR1zLt/nrlr9nENW+ah42dOFvm0wYpdu3ZNmTJl2N2xFzJhwHWT1tOy4zt37syaNWvhwoW5ubnd3d3Hjx9PS0tj37PFW8fPnL9yDOmYGQpjvycxZWYc88V1zIiDcYqMjMz69etx1hISEgaujO3YsaOxsfHo0aPHjx9XVFRE2vG36JjrrvM/dV7+2tjx1atXhYWFNTU1ucbNcNQoMFkg123133//fX9/P/NeaGdnN2HCBKae5cuXr1ix4ssnP8wH34MHD7JHKQdmpVq3bh3XYD12xy48W8fMnRXIzLFxf38/+wJlQEDAjBkz8CpN046Ojri4lJ6eTlEUczDsdVB+2u39eXl5EydO/Pbbb6WlpTdv3oz1hxZcXV1FRETYy4deymO/OlTHvBs57GCFsLAwwpSdHfMerMjMzOTKjl9w1+zjGrbMDFbgKhN7nWdOFjl16lT2DRXY9k9dyrt27Ro2ZD6ucv1DMq92dnayc+GBbICxEu5V4j1Y8cz5K//Uv/1fGKyYMWPG3zVYYWhoqKSk9P9OcNq6du3axYsXM1NZ8xisYAad0WlM37LHjmmavnPnjoCAQFhY2JUrV7gmLlFVVUUuzGwrISGBOH/m9KlDByu4Jn4d+mb8p84Lh8PhurOCmcOU/UmXHWw0TX/22WeioqIyMjLsu3W51sGf3d3dFEU1NDRgCbvw8OFDMTEx3Fc39CskzLsmlwz/nkt5NE1/+umnU6ZMUVBQYF/6vH37toKCwvTp03FhjbmOgf+6b7/9durUqdDxZ599NjB8bm9vj8tHzGUH1Pk0Hf/www/8/PzMFfb29nZ2v3CVq6qquD48/lkd827kgwcP5syZ87dcymOGO5nEhDmKF9z1M29043Epj/dkkTRNz5s3b9gxypkzZ/r4+HCdhaF/MuN6uPmBWWHoPySz/ODBgxRFnT59mvmTuVLHlR0PzALHdSlvzpw5zDvNM+ev5Pq3532j2/NcytuwYQNCmrmV4m+5lPf111/z8fHh6hl6lRn6vHjxIk3TPC7lHTlyZODuBa7vUnLpmKZpU1NTaWnp0NBQAQEB3ONE07S6uvrKlSux05aWFva1tWdOn8p74tdh34y5zgvvG90YueO+43v37i1evHjZsmVoMNdNn9999520tLS4uDjuKMWazDxY7DspHzx4oK+vLyAgwL5xgr1+amoqRVGYnuro0aOdrB8fHx+KojIzMw8dOoStmBvdELRYPrTw7OyYpum2trZJkyaJiYlFRUVVVVVFR0eLi4tPnjyZ/c0/5oKjtLR0bm5ucnLyggUL1NXVoWOappmxNj09vfT09JKSkpCQEGYKMqZNT9MxTdObNm2iKEpYWBiX14ceBjOaxs/Pz55K9s/q+JmNLCsrG5jCXV9fPz8/PyAggPeNblevXp06dSpzo1t5eXlERISqqirT8nfeeYeiKGNj47q6usbGRubCFO/+4b3rZ95Z8fDhw5UrVzI3uhUVFaWnpxsZGTE3uvGeLJKmaWNj44H7T7OyshobGxkRDJwUJkXq6+sb9lxwLVRSUmLfwcL8Qy5btizh//05c+bMjz/+KCIiIikpmZWVlZ2draampqqqyqVj5kY3Hx+fgoIC5kY3XDF75vyVXP/2vG90e+a8nMwHLCMjo8LCQh8fH64b3QoKCpgb3QoKCoKCgmbNmrVo0SK25njcm8j8z+MCJvrzzp07/Pz8zLvgv/71L1FRUeZGt4Hw2LNnj6KiImNV5pZQHR2dmpqaxsbGf//730yEIMNlKmQuk06bNo2ZMhV7YaaydnFxKS8v9/HxmTlzJvuGzmdOn8p74tfn0THb/mgVu2BlZcXPzx8cHFxWVqanp8fPz4+rC0P/F5gQCgkJYW77Y37je9V79+5dtGhRaGgoM0uskpIS1zfF6uvrBy5mZGdnl5eXW1tbUxTF46k4w44dMx9WcCcJ+0C4ys+lY5qmr1+/bm9vLyoqygxpCwkJDX1mxbFjx5SUlAQEBGRlZfft28cEK3t/7e3tBgYGb/zvR05OzsvLC8MXPHTMvDm7ubmxq2eN+3wAACAASURBVBq2bGZmxr6a9xd0TNM0j0bSNF1cXLxw4UJBQUFNTc1nfg3kxo0bmzdvFhYWFhISGniATnR0NJqdkJAgISHBdCbetP/yroeGIHaEwm+//RYZGblw4cJJkyaJiopu3boVl6F4TBbJXERdsWLF5MmT2V8DCQ0NffPNN5EYYi/DFrKzs6dOncq+6Dd0SJSiKOYG23Pnzuno6EyePFlcXDwkJOTo0aNcOlZUVLx8+TLzNRBJScnCwkL2TnnPX/mndEzT9DPn5SwsLJSTk5s0adK8efM8PT3ZOSZN0/n5+cw8odra2ufOndPQ0NiwYQNaq6GhISoqij/ZBWVlZa4rlnh15cqVc+fOZS5GffXVV05OTnPmzBEUFJSWlvby8sK9SRUVFdLS0sy1OK6vgaCqu3fvMqd14L8VC2mavnfvXlBQkJiY2OTJk/X19S9cuMCVWT9z+tRffvnlaRO//i06/v333zkcjqioqKCgoJaWVm9vL7v9XO9zwwYb3pkuX75samrKzBI7depUAwODlpYWdm1vv/32ihUrREREhISEVFVVS0tLeYT9sDq2sbExMDBg1/m08vPqmL19bW3twHf+HB0d2QtHrsx89hn6tcChe+zv758wYQL7jsKh65AlL94D9+7dExUVZd8tz7vOn376aebMmezvr/Nef1y++ujRo5kzZyKxunv3Lj8/P9d7ybg88Nf8oL777jshISF85Yp3b/wVHdM0zXyYCg8P51373/KqiYmJtLQ0j3ck9l42bNiAiGcvJ+W/sQf+wgM2U1NT/5YHbP6NRzHSVf3+++/soGXyJuShhw4dkpSURDI70o0h9Y9WD4SGhmppaT3n3v+ijp+z9hdcrbGxMTw8nKIorptOXrBasjnpgZfQA6dOnVq6dGlSUlJpaSlzs4GSkhLx70vo+bG7i1daxwPXKKdOnbpz507et22P3d4nLR/HPfDll1+amprOmzePGVnevn07c0ltHB8yObQX7IFXWscveGxkc9IDpAdID4yhHiA6HkMnizSV9ADpgfHcA0TH4/nskmMjPUB6YAz1ANHxGDpZpKmkB0gPjOceGAUdV/urgb1+qmA/RwM0hGiBGn8VUOkjD+qCVMHeAGVQ7acE9gbIg1qOPKjx0wS1fmqgIVgeNAcrg5ZQJYbGYDlQFyADavxkB/FXrHlCpY8SKPJSBsVeyqBwtyIo8lICObtkQeYORZC1XR7kbJcBac6LQYzDYsCxWgjGcyyP8LEpLZYCBuqqwMRoFbC0MAVrVi8H+ksWgdWiooPMm70aiImtfoLewoVAU04aLJUVB7oK4mCVygJga6gM3Ix1GYy1FgMPM41B1i/2eIKvmRzwslACHps1wCadRWCDrjJQWigORGcJg2lTp4EZ06aCZcqyIMbVHqTu3g7SPV3ACJ/bV6V6omNNuLjWTw0ubgiWh4ubg5WJjl+VgB29dsDFSoul4GIDdVW42MRoFVxsaWEKF69ZvRwu1l+yaNDFoqKDLp43Gy5eLSYGF+stXAgXa8pJw8VLZQddrKsgDhevUlkAF9saKhMdj168/JU9Ex0THf+VuHkNtyE69tisgdR4k84ipMYbdJWRGistFEdqLDpLGKnxtKnTkBrPmDYVqfEyZVmkxjGu9kiNU3dvR2qc7vm8j0Ie62FJdEx0PNZj+CW1n+iY6HikQ20UdFzqrwFKfOXA3kBl0MDRAXX+aqAmQBHsC1YFdYHKoJ6jAip9ZUCFnzzY66sN6gM0QUuoPGgNlhskaGHr/2gOehPU+C0E5f7yoCRIHeT5aoEMj2Ug000TZLkuBUWe6qDATQXkuSmD7O0yIGeHNEh1lgTRDlIg1FYajHQ8jeP6tWSkgNWaFaAgNQ5kxEaCLRtWDaKhsuUJRrOFwcZZwsBIZCbQnicK1GWlgbLMfKAtOx/oykqADepLgLmOAsNqlcVgvfpisE55HnAzUwae5irAw1QNWC2XAY7rtYGJjgLQlp8PpMWEgYG6HAjdZQNSvZ1AmpczyPJxBeM4rtiHRnSsDRfXB2jCxS2h8oMuDpZjXNwatBAubg56Ey6u8VsIF5f7y8PFJUHqcHGerxZcnOGxDC7OdNOEi7Ncl8LFRZ7qcHGBmwpcnOemDBdnb5eBi3N2SMPFqc6ScHG0gxRcHGorzT73pPynegAu1pKRgout1qyAiwtS4+DijNjIQRdvWAUXb9FQgYuNZg+6eOMsYbjYSGQmXKw9TxQuVpeVhouVZQZdrC07Hy7WlZWAizeoLyE6/lOneNRXJjomOh71IBwbDSA69jBVQ2pstVwGqbHjem2kxiY6CkiNteXnIzWWFhNGamygLofUOHSXDVLjVG8npMZpXs5IjbN8XMdGiLxwK4mOiY5fOIhejwqIjomORzrSR0HHJb6qg/gsLHlCtd9i0Oi3FNTsVgD1QUpgf7DysNQHKYK6IEVQHbgUVPnoglo/DdAQJAMaA5eA5oBFDC0cWbA3UBXk+WmDcBc14GuvCXaYqYNdpqog0EodhFkvBckuy0COuwbI3CkLsncuAhk7pEG8szQIs1sIRjqexnH9mvPngOXSC4CJtgrQkJIAihKzgYWSLNg0WwSYzp0N9KfOAMoiM4GmjCRYJD4dLBYTBuoy88EqTVmwRluOYZWmIlCTeRPoKEsBqw1qYJeFBvCz0gG+VnqAs20NCHJYDXZvXQ5czA1AzG5rkMVxBJnediBttwPI8t8FxnFcsQ+N6FgXLq7104CLG4Jk4OLGwCVEx+ygeT3LcLHm/Dlw8XLpBXCxibYKXKwhJQEXK0rMhostlGTh4k2zReBi07mz4WL9qTPgYmWRmXCxpowkXLxIfDpcvFhMGC5Wl5kPF6/SlCU6HluxSnRMdDy2InbUWkt07Gelg9TY10oPqTFn2xqkxkEOq5Ea7966HKmxi7kBUuOY3dZIjbM4jkiNM73tkBqn7XZAapzlv2vUzvrL3THRMdHxy424Mbs3omOi45EO3lHQcYWX3CC+UhVPqPGRBB3+SqDRV3GQYJXGJzSHLR0kdGnzE/YHKQ3CGl9ujNQFp/KdwYF4E1DlJw/wQIy6INV9gdoM1f56oMhvDfCwUAXuNqvADvtNYJv9VmBhshoYG6oDayNNYLlCFgRYKYPEHSog001xkF2ymU9I3SkLYp0Wg5GOp3Fcv67ELGAgMRvovjkHqMybDWTmzAQrJcSA05IlYKO4BFgiOA1oS0sDJ9PVYKPWQmC9UgG4b9YFfvaGINx1PUOUmzEI3GEMQjwtQbSXBUjw3Qwyw+xAdpgdyAm3BSXR20BppOMgMa6lTygI2wZy/beAHF8bkOphDdJ9XMA4jiv2oREdO8PFB+JN4OIqP3miY3agkDJcrCsxCy42kJgNF+u+OQcuVpk3Gy6WmTMTLl4pIQYXOy1ZAhdvFJeAi5cIToOLtaWl4WIn09Vw8UathXCx9UoFuNh9sy5c7GdvSHQ8tuKW6JjoeGxF7Ki1lug4k5UaZ4fZITXOCbdFalwSvW0wNY50RGpcGuOK1LggbBtS41z/LUiNc3xtkBqnelgjNU73Ic+sGLGwHxyp8JLDSEWFrxRGKmp8JDFS0eGvNDhS4auIkYrGYJXBkYqwwZGK5tClgyMVQUrsO+EwUtEYqYuRilP5RMcjdqbHV8VEx0THIx3Ro5Idy1d4/R+VgUtBbZAaaAlUBc2BiqA+QA40h6mCBo4S2BcgPwhHYd8T2vfog98+3AfOVHqBkkAdkO9nALK91zP4WagDMy1JYLVOBwS47wD+vn5gd2AI2O7mCRydHIHxhjVgq5kRsNqoCjwtlcEel6UgfZcKSHJaDOIcF4ORjqdxXL+O5ExgsEh0kIViBk9YKj4HLJkrDMx1tMCR8nJQnZYCglxdQHakH2jOiwJNmX6gMckFVERsBSVhm0F5lBVDVbQVqIyxAw3pbqC7wAccq4kGfU3p4Mi+ZHCgJgF018SDnpoE0F2ZANoLw0FTli+oS/QGJREeoHJPMBjHccU+NKLjfXDxmUovuLgkUAcuzvczIDpmB83rWYaLdSRnDrp4kShcbLBQDC5eKj4HLl4yVxguNtfRgouPlJfDxdVpKXBxkKsLXJwd6QcXN+dFwcVNmX5wcWOSC1xcEbEVLi4J20x0PLZileiY6HhsReyotZbouK8pHanxkX3JSI0P1CQgNe6uiUdq3FMzmBp3VyYgNW4vDEdq3JTli9S4LtEbqXFJhAdS48o9waN21l/ujomOiY5fbsSN2b0RHRMdj3TwjoKOC320QZLHShDvqgsK/LVAbZAS2B8gCxo58oMEyTc+od5vCdjPkQX1IQrgULoVqIowA3vc9MB2E0WwWl2SYZ2eIlitowzsLDeBkABfEBEeBkIjIkAghwOcXFzATtftwMHBGujpqYI1ekuA91Y1kOmpB9J3KIFkZzkw0vE0juvXlBIG2ktEge5CMaApOQ8sEZ0OttuYgy8+ug5uffMF+OhyH7jSuxe825kHzuxPBr3FgWB/4naQ5WcOEt03MGT6moCS0C2gPt4eHM7zABeaEsGl7kJw8VAZeOtgOTh9qAL0tReCQ3VZ4HBtCmgrCQN1Kd6gJHIXyOfsAuM4rtiHRnRsBRdXRZjBxXvc9ODi7SaKRMfsoHk9y3CxppQwXKy9RBQu1l0oBhdrSs6Di5eIToeLt9uYw8VffHQdLr71zRdw8UeX++DiK7174eJ3O/Pg4jP7k+Hi3uJAuHh/4na4OMvPnOh4bMUq0THR8diK2FFrLdHxpe5CpMYXD5UhNX7rYDlS49OHKpAa97UXIjU+VJeF1PhwbQpS47aSMKTGdSneSI1LIgdT43wOeWbFiIU9RioKfbQxUpHksRIjFfGuuhipKPDXwkhFbZASRir2B8gOjlRwBkcqGoPkMVJR77cEIxX7ObIYqagPUcBIxaF0ouMRO9Pjq2KiY6LjkY7oUciOY111gY+zBVBdIgJsjeeDsuCloCVEETQFyQEsbAlRbA5WAA2cJWBfmCwo8NIEcTv0Qay3CXC1MQJr1+gymFluABtMVgLLrcYgMT4c5GcngqgQb+C50x54uTmBID93YGVpCgzXrwMqqrLAfPlikLhDD2TtXAqSHWXBSMfTOK5fa4HwIJKztJ6g8+YcoCsjATRkJICnkyU4d+wA+OTKWXDzfPcgfbU3n3CpNQscr4wFjam+IDvAFgTbrwU+lisYonYagdxgK7A3zgW0ZnqAU7XR4FpPEbhytAJcOFwBzh+uAP0HSkBvYy5oLYkGNaluoDzaHhSH2YLcACswjuOKfWhEx5pwcdwOfbg41tsELna1MSI6ZgfN61kedPECYbhYS3IWXKzz5hy4WJflYg0ZCbjY08kSLj537ABc/MmVs4MuPt8NF9/sq4WLL7VmwcXHK2Ph4sZUX7g4O8AWLg62X0t0PLZileiY6HhsReyotZbo+FpPEVLjK0cHU+MLrNT4/OEKpMb9B0qQGvc25iI1bi2JRmpck+qG1Lg82h6pcXGYLVLj3ACrUTvrL3fHRMdExy834sbs3oiOiY5HOnhHQccJQfZgp8s2oKAoA4xWyoMcPx3QGKwA9gcuBk0cWdAaqgZqAzRApo8GCHNSA/G+piA3wQtwdjsCWxtzBgdnW2BluwWYmq4DUSFeoL4sE6RG+QM3x81g9w5b4Oq4FVhtNgbaBnpATUsN6KpKAS9LdZDurgFSt8uCkY6ncVy/lvgMoC85G5hpyAI3q/UgNtAV1BQkgnNHmsHNC4fB5+fbwc0jpeBSUyo4VhEDmjOCQWXsbpDu5wgSd9sy5IRsA2Wx20Fjuhc4VhEJ3qqNApfaUsFn/XXgg1N14L2jVYB998WxllxQnx0IqmIdQUOS41Nwbkj6P8ZxXLEPjehYDS6O9zWFi3MTvOBizm5HomN20LyeZbhYS3wGXKwvORsuNtOQhYvdrNbDxbGBrnBxTUEiXHzuSDNcfPPCYbj48/PtcPHNI6Vw8aWmVLj4WEUMXNycEQwXV8buhovT/RyJjsdWrBIdEx2PrYgdtdYSHV9qS0Vq/Fn/YGr8wak6pMbvHa0i2fFfjlGiY6Ljvxw8r9eGRMdExyMd8aOg45baXODu6Qm09fRBVHgAKIvaAmoDFEF9sDxoiFAH+8NXg44UZxBgpw+iPc1AVVY4qMzZA8L9dgFrC2OGLZtNwVarLcDCbCPYvH45SI/2B/kpkSDA3RHYmBsBS9N1wHrLJrB+4xqgo6sF5BZJAGP9RSBptz5Ic1cGIx1P47h+HbGZwFRJGgTZGoOCRA44sL8InD28D1w91QY+Pd8B3j9UAs7WxIAL++LB6Zo4cCg/FPQURYGWTA4oCHFmKI1wBuWRjqArxw9c3J8IztdFgb7yIPDJiXLw8elacKWnDLx9oBj0NGaA6nSvQaLsqp/QnroddGXuBB3pLmAcxxX70IiOzeDiqqxwuLgyZw9cHO63i+iYHTSvZxku1hGbCRebKknDxUG2xnBxQSIHLj6wvwguPnt4H1x89VQbXPzp+Q64+P1DJXDx2ZoYuPjCvni4+HRNHFx8KD8ULu4pioKLWzI5RMdjK1aJjomOx1bEjlpriY77yoOQGn9yohyp8cena5EaX+kpQ2r89oFipMY9jRmDqXG6F1Lj6ig7pMbtqduRGndl7kRq3JFO5sobsbDHSEVLbS5GKtw9PTFSoa2nj5GKqPAAjFSURW3BSEVtgCJGKuqD5TFS0RChjpGK/eGrMVLRkeKMkYoAO32MVER7Eh2P2JkeXxUTHRMdj3REj0J2fKirHiRn5AAnV09QXl4EOor8QTVHA1RyVEFZiAG4cigf3P7wPLhyqAFUJoSCjrI8UJgQDaJ9vYCjlTmD9VZzYGy8HujraoFNa/VAWrQ/yEmKAElRgWD3DjtgvdkY2FiZga1WZsBk03qgrqYI5N6cAZxNlECiuy4Y6Xgax/XrS8wBW9RkgY/VOlCYEgKOd1SBq6dawcfnOsDNE3WgvzYe9BX6g/eb48GV9izQmuEL9id6gq68MJAXZM9QGuYI8vy3gAPZvuBqSxLorwgCR4t9wSfHCsE/ztaAD49XgHcOFYMjzRmgPtsXVEfaguY9tqA13h40x9mCcRxX7EMjOg6FizvK8uDiwoRouDja14vomB00r2cZLtaXmAMXb1GThYt9rNbBxYUpIXDx8Y4quPjqqVa4+ONzHXDxzRN1cHF/bTxc3FfoDxe/3xwPF19pz4KLWzN84eL9iZ5wcVdeGNHx2IpVomOi47EVsaPWWqLjo8W+SI0/OVaI1PgfZ2uQGn94vAKp8TuHipEaH2nOQGpcn+2L1Lg6cjA1bt5ji9S4Nd4eqXFznO2onfWXu2OiY6LjlxtxY3ZvRMdExyMdvKOg4yNHOoE3JwJkl1SD/c1N4EBlBKjwVwd7QzRAhJ0q+OBcN7j9j6/BZ6f6wL6UBHBkbwWoTEsE0d4eIMzPg8Fs0zpgYWEKlJXkgIOVKejcXw6qCtJARUE68HLdBmwsTYG7mwuwtTUHZuYbgT7rR37xQqCvIgk8NquAkY6ncVy/wZvzgLHKIuBhYwRqixPB+d4G8MHZdvDpuVZwo7cC9NfEg2PZHuDj/WHgVFUsCHQ0AUm+jiA31B34Wq5hSPayBiGOa0FHXhC43p4I+op8QG+RH/jwUBb45mwl+PhkGbjYUwSONCaB5oJAUBVlB+pDNoH94WagIWoLGMdxxT40ouMEuPjI3gq4uDItES6O9v4/F4f5ecDFZpvWwcUWFqZwsbKSHFzsYGUKF3fuL4eLqwrS4OKKgnS42Mt1G1xsY2kKF7u7ucDFtrbmcLGZ+UaWjfXhYvnFC+FifRVJuNhjswr73JPyn+oBuNjgzXlwsbHKIrjYw8YILq4tToSLz/c2wMUfnG2Hiz891woX3+itgIv7a+Lh4mPZHnDxx/vD4OJTVbFwcaCjCVyc5OsIF+eGuhMd/6lTPOorEx0THY96EI6NBhAd9xb5ITX+8FAWUuNvzlYiNf74ZBlS44s9RUiNjzQmITVuLghEalwVZYfUuD5kE1Lj/eFmSI0boraMjRB54VYSHRMdv3AQvR4VEB0THY90pI+CjvtOnQCu3hyQklsGWjoPguONqaAhTB+0Ry4DyY5KINjZAvT39IELrftAS3YSOFpbAk607gXJobtBsJczg9sOO7B1qzmQkZEG0eEB4P23T4Oa0myQnxEPHO22AEsLE+DkaAs8PJyAlc1msNHEDCzTWgZWLFsKNumIg5GOp3Fcv7rEbGCipQiifJzBwYZCcPlkM/igvwV8fq4FvH+4FJysigM9mR6gL8MF5AbZA8fNRsBynT5Yq6EAViovYdiyWhvYGmmBJC8LcLE2DBzO8QCd2V7g7aZ48NXpYvDpyRJwqacI9DYkgdaiYFAfvwM0RG0GLXE2oD3ZCYzjuGIfGtFxElx8tLYELj7RuhcuTg7dTXTMDprXswwXq0vMhotNtBTh4igfZ7j4YEMhXHz5ZDNc/EH/oIs/P9cCF79/uBQuPlkVBxf3ZHrAxX0ZLnBxbpA9XOy42QgutlynDxev1VAgOh5bsUp0THQ8tiJ21FpLdNyZ7YXU+O2meKTGX50uRmr86ckSpMaXeoqQGvc2JCE1bi0KRmpcH78DqXFD1Gakxi1xNkiN25OdRu2sv9wdEx0THb/ciBuzeyM6Jjoe6eAdBR2f6O8H9i6eIDY5F3QeOgo6KpNAQ+RacDBSC+z1UQXb1yqBpvLSQXJjmp6QFugEjjUUgo/eOQJqiuJAZMAOhrBATxAU6APU1VVBcUEm6D9+EFQUZYLIED/gYGsJtlqaD7LVYusTnJ2tgLXNZrDVxg5sZP2YG68EG5eJgpGOp3Fcv7acNHDZYgxy4kPBgfp8cLG3DtzsbwJfXWwF73YVgO7iKNBXEgra4p0Ax8UUBAd4AU0VeSC/cAFQl13CoLRYCmy3NgXBLibgYJYnaEx0AfuS3UFvGQd80pszyPGCT55wtacQnGxOBW1FoaAuwW2QGOu6JzQnO4OWtJ1gHMcV+9CIjp3g4mMNhXDxR+8cgYtriuKIjtlB83qW4WJtOWm42GWLMVycEx8KFx+oz4eLL/bWwcU3+5vg4q8utsLF73YVwMXdxVFwcV9JKFzcFu8EF3NcTOHi4AAvuFhTRR4ull+4gOh4bMUq0THR8diK2FFrLdHxvmR3pMa9ZZzB1Lg3B6nxJ8cLkBpf7SlEanyyORWpcVtR6GBqnOCG1LguxhqpcXOyM1LjlrSdo3bWX+6OiY6Jjl9uxI3ZvREdEx2PdPCOho5Pv3XiCY7O7qC0vB4c7TsNQn13gNTdq0F7lB5o5KgD9w2yoCAxDORFu4PGolhwoqMCfP3RRXCorQpkJQQzxAR7geBAH7B+/VpQXloAjh3uAEW5qSDQ1wPYWFkAC4tNYMNGI2BhsQHsdHUCrrt2AnvbzWC73TrgtFEajHQ8jeP6bS3NgKuzLUiNDgZtVVngYk81+PRcC/j6QhO43JkPukpiwdGyaNCV5Qd2WG0AKw2XgzclxID20qXAQFOTYYnkm2DdCj3gaWcCcoNsQKbfFlCf5g1O1caA6wdSwWdHc8GNw/ngZGMyaCsKB/tTfEBtvCNoznQHrbk+YBzHFfvQiI5j4eITHRVw8dcfXYSLD7VVER2zg+b1LMPFtpZmcLGrsy1cnBodDBe3VWXBxRd7quHiT8+1wMVfX2iCiy935sPFXSWxcPHRsmi4uCvLDy7eYbUBLl5puBwuflNCDC7WXrqU6HhsxSrRMdHx2IrYUWst0XF9mjdS41O1MUiNrx9IRWr82dFcpMY3DucjNT7ZmIzUuK0oHKnx/hQfpMa18Y5IjZsz3ZEat+b6jNpZf7k7JjomOn65ETdm90Z0THQ80sE7CjruP3sWeHv5g6bGNnDsWB/w9PEBO+3WgMrQFaAxYhlwNZYGQbttQXqkOzh/tBmcPNQM2vbvBXmZmaA8J5khPzUauLs6g/XrjUBpaRHo7mwBaUmxIH5PBPD18QRW1pbAwdEBOLvYAx9fDxDE8QOuLhZgu5UWCHZWBSMdT+O4ficnB+DgYAWiAr1BZ3U2eO9YLfjqYjv4/HQtuNiSBborksDhsj2gLHI7MF6lAxTkZYC05HywYfVKYLJ6FYPiYmmweIEE2LRSB3jbrgPR7uYgP9IFvNORCd5tjQcfHkwF17oyQF/9HtCSHwoaszigPm0XaC/0B90VEWAcxxX70IiOB1188lAzXNy2fy9cnJeZSXTMDprXswwXOzk5wMUODlZwcVSgN1zcWZ0NF793rBYu/upiO1z8+elauPhiSxZc3F2RBBcfLtsDF5dFboeLjVfpwMUK8jJwsbTkfLh4w+qVRMdjK1aJjomOx1bEjlpriY7zI12QGr/TkYnU+N3WeKTGHx5MRWp8rSsDqXFf/R6kxi35oUiNG7M4SI3r03YhNW4v9Edq3F0RMWpn/eXumOiY6PjlRtyY3RvRMdHxSAfvKOj4HOsnMS4VtDV2gN6Dh0F8WjYwszQFmWG2oCLaFAQ5aYL4MEeQk8AB335+Hdz98VuQl54GUuLjQUK4P0O4/y7g7eEMnG1NQG5yCGjamw9KC9KBv/cugJuObaws1m9YC2xsbYCnx07g77MThPk6AndrbRDushSkeiwFIx1P47j+2D0xIDI8GOQmR4He/QXgw7568PWZRnCzpxycb8oER2syQEdhHMgMcAR6mkpAW1sNaKkpAYv1a4CViRGDjuZSoCovD9Yu0wTuVkYgNdgZJHhvBf0NqeBaRzq43BANrrYngJO1UaApLwjUZ3NAXaYX6CrhgGO1cWAcxxX70IiOr8PFd3/8Fi7OS0+Di1Pi44mO2UHzepbh4tg9MXBxZHgwXJybHAUX9+4vgIs/7KuHi78+0wgX3+wph4vPN2XCxUdrMuDijsI4uDgzwBEu1tNUgou1tdXgYi01JbjYYv0aouOxFatEx0THYyti37B0xgAAHSpJREFUR621RMcJ3luRGvc3pCI1vtaRjtT4ckM0UuOr7QlIjU/WRiE1bsoLQmpcn81BalyX6YXUuKuEg9T4WG3cqJ31l7vjUdDxpUuXQX5+DWjadxCc6ukDTS1twMzaHsREx4D0mIBBwrekP8HFYgkoz0kC7fUVoK40C2QmBoOA3bYs7AN2///s2rUNeO6yAf72eqA1xwNUpvuAwqwYkBIfAnw8twOzTRuAubkpcHJ0ArsctgAvy2Ug2lYZlHgvA7keKuDlRte42tue6EiQHBcByrJjwKnWYvDR8TrwRV81uNKRB96qTwEHy5NAV0kqqEnhgBXLVICamjJQUZID+lrqYMUyTQZtbU1gqK8PNq3QAXFedqA82R8k+NqC7pJIcONALjhZFgjO7wsHx6vDQFNBEKjNDRoky7f2CZ3FHHCsNh6Mq0h6+sEQHVfAxXWlWXBxZmIwy8W2jIuJjp8eSOP/Fbh4T3QkXJwcFwEXl2XHwMWnWovh4o+O18HFX/RVw8VXOvLg4rfqU+Dig+VJcHFXSSpcXJPCgYtXLFOBi9XUlOFiFSU5uFhfS53oeGzFJdEx0fHYithRay3RcYKvLVLj7pJIpMY3DuQiNT5ZFojU+Py+cKTGx6vDkBo3FbBS49wgpMa1Wb5IjTuLOUiNj9XGj9pZf7k7JjomOn65ETdm90Z0THQ80sE7Cjr+8OZNUN9wCOxr7AVHevtBV88x4OTmCVxc3EBlUR4oTPMDux2XgziOJwjxdAaBbnaA42kH3Bw2giDfHQzWDrZgl7szyN3jBkJcVoK1OlJgT5gnSIoJAibrlgMDHQ2gp6MF1hutAm6OZoDjtBLk+K8FxZyVINNXG4x0PI3j+iPDQ0BiQjgoywoHZzqKwfUjleBmTzF4ty0LnK5LAs0FseDovhLQV5cLdtmbAm2tpUBNVQmoKCoAJXl5Bg1NTaCrrQZ2bl0P9mdwQEthDMgM3wkaswLBe+1ZoDtnN+gp8gUHS4JAXY4fqC8MATXZ/qC9KBj01iSAcRxX7EMjOnaGiwPdBl3M8bSDi90cNhIds4Pm9SzDxZHhIXBxYsKgi8uywuHiMx3FcPH1I5Vw8c2eYrj43bYsuPh0XRJc3FwQCxcf3VcCF/fV5cLFu+xN4WJtraVwsZqqElysoqhAdDy2YpXomOh4bEXsqLWW6DgzfCdS48asQKTG77VnITXuztmN1LinyBep8cGSIKTGdTl+SI3rC0OQGtdk+yM1bi8KRmrcW5Mwamf95e6Y6Jjo+OVG3JjdG9Ex0fFIB+8o6PjG9XfBwd7ToLHzBGg//Bbo6u0DUQlJwNrWBWRl5ICywiyQsscPeNhbANOVy0ByuDeI8nMBccGuoCAnicFqmyPY5uIIijPCQGKwIwj22Qa8dloDk7V6YKW+JlCSlwWrVhgA63VyIMlTH1SErgA1YdqgPEgZlPipgJGOp3Fcv0coB3Big0BZbiQ42ZQD3unMA9e6ssA7zangdF0iqMuKAD37KkB/UxEoSgoCWcnRINDbDRivWwOWaWoyrFm5HIQF7AK1edHgWF0GONpQAMpSOaAm1Q8cq4gGjUk7wb7E7WB/xm5QluoBago4YG9OIGgpCgGH9yaAcRxX7EMjOl4GFyeHe8PFUX4ucHFcsCvRMTtoXs8yXOwRyoGLObFBcHFZbiRcfLIpBy5+pzMPLr7WlQUXv9OcChefrkuEi+uyIuDinn0VcHF/UxFcXJQUBBdnJUfDxYHebnCx8bo1RMdjK1aJjomOx1bEjlpriY7LUjlIjWtS/ZAaH6uIRmrcmLQTqfG+xO1Ijfdn7EZqXJbqgdS4poCD1HhvTiBS45aiEKTGh/eSseMRC3uMVNy4/i5GKg72nsZIRWPnCYxUtB9+CyMVXb19GKmISkjCSIW1rQtGKrIycjBSUVaYhZGKlD1+GKnwsLfASIXpSqLjETvT46tiomOi45GO6FHIji+cPgSOnzgOWrsOg47uo+BATy/ILSoF1vY7QWh4IoiIigdpqSkgNzkGGOlrgLgQb+C93RrkJUeC3q4mBk5ICNhoshEkhLqDtChPkBwXAuyszYCGmhLQ1FAHqmqawN7eEYQ7GID6kLWgNXwl2BegCar91EGRlwoY6Xgax/VbhHLAjphAUFoYB3rr0sDZ5jTwdlMiOFMfC07XxYOq1FDQVlkEzraUgPbSePDWwXrQWV8Kwvw8gcWGdQwcTxdwtK0UXOqrB6c7KkBfWxWoy4sFDTmhoDOPA/bGOIPiMDtQGOUIcmKdQEGKByjP8AMN+RzQXhYDxnFcsQ+N6FgDLo4L8YaLvbdbw8V5yZFEx+ygeT3LcLFFKAcu3hETCBeXFsbBxb11gy4+25wGF7/dlAgXn6mPhYtP18XDxVWpoXBxW2URXHy2pQQubi+Nh4vfOlgPF3fWl8LFYX6eRMdjK1aJjomOx1bEjlpriY7r8mKRGjfkhCI17szjIDXeG+OM1Lg4zA6pcWGUI1LjnFgnpMYFKR5Ijcsz/JAaN+RzkBq3l8WM2ll/uTsmOiY6frkRN2b3RnRMdDzSwTsKOt5fmQ/OvHUcdB/sBAfa28Dhw4dAaVUN2OnuBxJS8kFr51Hg7ukHHO1tgIXpRuBobw0iQjjgYHs7ONVzgKG4sBC4uu4CdmargY2pITBYrgtUNLWBjIoGEF0oD1R01wGD9ZbA29UE5EZvGSRyU+4T9vgsB7EB60CYpyEY6Xgax/Urrl0JNm+3AWlJoaC9PB4cr48Dp+uiQH9tDDhZkwQK9gSB6pwU0N9aCU42FID3TrSDIy3VICnCH/hst2EoSgoBvQ254OqJ/eBMdy040lIJyjIiQEN+BOipiAFNabtBbpANSAu2BykRDiApZhvISfQAFRneoDyTA8ZxXLEPjeh4I1zsaG8NF0eEcODig+3tRMfsoHk9y3Cx4tqVcPHm7TZwcVpSKFzcXh4PFx+vj4OLT9dFwcX9tTFw8cmaJLi4YE8QXFydkwIX97dWwsUnGwrg4vdOtMPFR1qq4eKkCH+i47EVq0THRMdjK2JHrbVEx2UZg6lxQ34EUuOeihikxk1pu5Ea5wbZIDVOC7ZHapwS4YDUOClmG1LjnEQPpMYVGd5IjcszOaN21l/ujomOiY5fbsSN2b0RHRMdj3TwjoKOg8OiwJmLF8GBg13gYHMTONzdDdJzC4CljQMoLtsLfv39Afj0i69AUmYuSM4qAEWV+0BXz2lw8uxV0H/6HENT22EQnZQDfH18wPIVK8AiNT0grb0WqBnZAL3NbmC5lS/Q2+oH1u2MABt2hQIzjzCwzsUf6G/zB8vsg8BIx9M4rl9SagFYtUoX+PruBFW5kaCzLBz0VoSBk9Ux4EBxHEgI9ADswYpTbbXg0qF94P3+btDVUAky40JBeqQPw/6iRNBbnwOu9taD/s5q0FlXBPKSgkFFehDoLIsE7YUcUBKzA6RwHEFimCOIi3QASTEug0Q7JT0hLNITjOO4Yh8a0XEBXFxUuQ8u7uo5DRefPHuV6JgdNK9nGS6WlFoAF69apQsX+/ruhIurciPh4s6ycLi4tyIMLj5ZHQMXHyiOg4sTAj2IjpOineDisEjP1yTkiI6Jjl+TUH/RwyQ6zksKRmpckR6E1LizLBKpcXshB6lxScwOpMYpnMHUODHMEalxXKTDYGoc44LUmOj4ReP1ObfHSEVwWBRGKs5cvIiRigMHuzBScbC5CSMVh7u7MVKRnluAkQpLGweMVBSX7cVIxa+/P8BIxadffIWRiqTMXIxUJGcRHT/neXvdVyM6Jjoe6f+BUciOzT2TQOe5D0DHkdOgq+0AOHCgB2TmFwMf/wBw/fo18Ojh7+Dho4fg6j++B1E5VSAwsQhEZdUBTlIliEgqZfCIKgRrHUMHsfFY+wSDLbuA5lY/oL7VF2hYBQEdx+hBnBJ0nqDhEA8UXVKAhkcW0PfOBku3JwLF7WlAwTkRjHQ8jeP6pRdJAe2VusDJzw1kpUeC+qwQ0JbDAR35oaAqJQjEBXqAfaU54GR7Lbh2vBW8e6IDNFTmgcz4UFBflMzQf6AWnO+qAtePN4D+rmpQU5gCMvcEgowoD1CfFwoaC4JBcZwrSA11BhGBDsDXfTPws1oFvD0sweYoHzCO44p9aETHVXBxYGIRXByVVQcXc5IqiY7ZQfN6luFi6UVScLH2Sl242MnPDS7OSo+Ei+uzQuDithwOXNyRHwoXV6UEwcVxgR5w8b7SHLj4ZHstXHzteCtc/O6JDri4oTIPLs6MDyU6HluxSnRMdDy2InbUWkt0nLknEKlxRpQHUuP6vFCkxo0FwUiNi+NckRqnhjojNY4IdEBq7Ou+Gamxn9UqpMbeHpZIjTdH+YzaWX+5OyY6Jjp+uRE3ZvdGdEx0PNLBOwo6lrdLAS5pTSC3qQ80dfSBgz2nwf6WjkEa9u1/wm+/3gaP/vgZ/PO7fwHf1DJgYOsHtCw8gdomz0FMvNSesHTDLgZl8yCgsDkMqGwOAApbOEDGOhqo2EcPYhej8gRFmz1AwS4RqDhmDOKUpvIEdZc0sMwlBWg5JQMN5wygbJ8ERjqexnH9cnIyYLmlGbCLiwB+cSEgNdYXFEV7grIEb5AZ5QkSQ71BfmosONa2F7zb2wROddaAvUUZoCw7ERxvr2a4cbYbXD/RAj7pbwcYOO7vqi5MjQLx4d4gyNMWpMd4gpKMQJAavQOEBTgAZw8bsMXDHphZrQeb3OyAUUYiGMdxxT40omM/uFjLguXiTZ5wsZqJF9ExO2hezzJcLCcnAxcvtzSDi+3iIuBiv7gQuDg11hcuLor2hIvLErzh4swoT7g4MdQbLs5PjYWLj7XthYvf7W2Ci0911sDFe4sy4OKy7ESi47EVq0THRMdjK2JHrbVEx/Hh3kiNgzxtkRqnx3giNS7JCERqnBq9A6lxWIADUmNnDxukxls87JEam1mtR2q8yc0OqbFRRuKonfWXu2OiY6LjlxtxY3ZvRMdExyMdvKOg4wUOWYPYxC94gr5bMkgo6wIN3adAYmoa6D9xGDx+cBf8/OuvIGtvJ1juFAvUt4awCFXf+n9oWIUDNcswoL6Vw6BqHQwUtgYD2S1BQNo8ACyyDAOy1tFAxioaKNjFA+VtyUDHPQ+scM8G+ruygY5bPlDfmQtUnDKBhnsRGOl4Gsf1L14sDZbZbAUWmSnAMiYYeAa7gUifbSCZsx2EeNqCUG8XkBgZAPo6a8GFQ/XgYF0BaK8vBScONoFLfR0MH547DD4+2wU+O9cJ3uqsAnEhnsBnlx2wNl8JdjgYg8jQnSAo0BG4eFiDjT47wKqUPcAwMx6syUgCa/PywDiOK/ahER2HwMX/Xzv39tNmfiZw/C+oVupu222zadpJJmGAcAiHYcmEcPRrGzuAwQaDDTgkBBIgAzkYhvM5HBJOxviEjYEAgTAQAsyQkElmNZlRR2pX3VG1q+3NXrQXnaverFa9qHYvWL72RXppHDs/6XNhJZH9vr/30VeP3oucKzLT4gRtCy2OL2wWOfYfmnfzMy0+deo9WvxhcREtzh8dpMWFHXdoce2dalrcWm+gxQO3TbT4bm0JLTbXVdLivtZGWry/4aXF32wv0OKt+SlavL5go8UvtlZEjkNrVkWORY5Da2KDdrUix/VX9azGurx0VuPLZUpW41ZzFavxrSYjq3FljY7VWFF/mdU4Y7CL1fjiaA+rcdZIP6tx9sRE0J760f6wyLHI8dFOXMj+msixyHGghzcIOY67OY+fl4/iPW0bFNfvocuy7HNvrOvQv//ut/jfv/4Fz7/+NTKNd5Fc1oVzJe1ILO18o5jCFpzV3DoQpWnEBwUf41R+I84U3kGErtVH3xtxKMowgJiKYZyvsyKtwYb0+imcr5tGcp0D52ptkLUuo3BoF4GepzD+/qz0DOjMZkgPRqB6MAi9uQHXKrUwV5dAr76IsgIZ7t6sxtbqLF5sevDZIye+3F3Dty+e4F+/2Djwuy+f4j/+ZQP/+dUG9pasaLhcCl2eDDlp8UhPjYa+WIbSKg1UNyqQ3deB8xYLJKsL8hkXPpwaRxjPlf+tiRy3v7HFiaWdtDimsEXk2H9o3s3PtDgrPYMW68xmWiw9GKHFqgeDtFhvbqDF1yq1tNhcXUKL9eqLtLisQEaL796spsVbq7O0+MWmhxZ/9shJi7/cXaPF3754InIcWrMqcixyHFoTG7SrFTnW5clYjXPS4lmN01OjWY31xTJW49IqDaux6kYFq3F2Xwer8XmLhdVYsvpWY/mMi9X4w6nxoD31o/1hkWOR46OduJD9NZFjkeNAD28QcpzY9BAnq6ZwQteDDwo/QWZFB7omFvFff/wef/7v/0HbmB2phibEF7eC/1M4pbw32dCNaI35jWILzQdiisyIKjT76FqjDkWXdPqU9kYfOmu6j+TrVqQ2OJBca0WM6T6iKkZxqmwYCXVuKHq2oB3ehar9EQI9T2H8/WPjNjQ7PFBaLMiYskDR3gpdlQGmUg3kaUlQydJgNOrgcI1jY8ONve1V7G8/wuu9Vfx6//GB3+5/in97tYbfvFrBWOct5Ek5KMpTQkpPQGpKJOSq87hUrUN2dxsyrNPIctggWW0+Mw7pULrFgjCeK/9bEzkWOfafB/H5b54ALR4bt9HiZoeHFistvhZnTFlosaK9lRbrqgy02FSqocXytCRarJKl0WKjUUeLHa5xWryx4abFe9urtHh/+xEtfr23KnL8Nx/nW/kXIscix2/lYL59FyVyXJSnZDWW0hNYjVNTIlmN5arzrMaXqnWsxtndbazGGdZpVuMsh99qbLWxGkszDlbjdIvl7RuHgFyRyLHIcUAGK/y+VORY5DjQUx2EHJ9rmMfJy9M4rh/GSV0/ogs7cOn6ML79/Z/w3R++h6ljFBk1HUgu70ZccRtSTf2IK25FRP5tnNWYD8QWfYK44g7E6nsQo+9DgmkUZwzDPsaRM4fiqi2IvToF/sEZ48g/afsRcdWOrO5dn47NrEMxlx8goXIEgZ6nMP7+NvcC9NN2KK0uyF1zyJ66D1lrA7KKlEhLTURGegqUBQqMTA5gdcODrc/WsbO7hi+ereGbV5/+vxdr3xx6vT+PV8/cuHFNh7iz76FYK4OhXAW5NhtShQaqliZIk5PItDugmHVA7nBAstuROWVBGM+V/62JHLfR4lRTPy2OK26lxRH5t0WO/Yfm3fxMi9vcC7RYP22nxUqrixbLXXO0OHvqPi2WtTbQ4qwiJS1OS02kxRnpKbRYWaCgxSOTA7R4dcNDi7c+W6fFO7u+Fn/xbE3kOLRmVeRY5Di0JjZoVytyXKyVsRobylWsxnJtNquxVKFhNVa1NLEaS5OTrMaZdt9qrJj1rcZyh4PVWLLbWY0zp8S744CNPW8qzjXM86bi5OVp3lQc1w/zpuKkrp83FdGFHbypuHR9mDcV3/7+T7yp+O4P3/OmwtQxypuKjJoO3lQkl3fzpiKuWOQ4YE86vL5Y5FjkONATHYztuM577tBJ0xR+YRjDL0vu44OSYcQUtaOm34PV198h/YoZyaYWJJZ3IamiBxeujSD1yiCSK3txtrD5QGTeXXyQ34yYkh7EGwYRY7iHyIoRRBiHccZwD++XDoJ/EGEcjq6ewcX2LcQ2LOJE6Sj+7qNrSDDeQ6DnKYy/X2t3QeWdR557GYWeJWQ7rMgc7UGSNg8xMdFISklEocmIccckVlY8eLqziWfPnuL1qx385vXnB371chNf7rjx+boFbeYayLI/RGWlGrWNFSi6boSmvQWXLNOQOWeRbptBlmUSOdNWSDY7sizTCOO58r81keMeWnzh2ggtTr0ySIuTK3tFjv2H5t38TIu1dhctVnnnaXGee5kWF3qWaHG2w0qLM0d7aHGSNo8Wx8RE0+KklERaXGgy0uJxxyQtXlnx0OKnO5u0+Nmzp7T49asdkePQmlWRY5Hj0JrYoF2tyHFlpZrVuLaxgtW46LqR1VjT3sJqfMkyzWosc86yGqfbZliNsyyTrMY501ZWY8lmZzXOskwH7akf7Q+LHIscH+3EheyviRyLHAd6eIOQ4+y2J4i8YsGJkiGcLpvE+8UjiNL3ITKvEdKNfsTrm3BCXYtjUi1Oa+4g3tiFlCuDSK0eQpKh64D/f3bxUdUQ/rlqBEmmYZyrGMLZ8ns4U9KLXxa2I7KsH2kfO5DX9xSK3h2k3F7BadMkfpBehwhtJwI9T2H8/QqbE7lzC1B7l6Gye5DrdEOamECs0YDjSQmIkkvQ93aizWPHpNeFrb1d7L98jq+/2sevvto78PL5Jp6uzGDNcx+DA22QadUoaTDB0FKPos4WaKctUHsXIJvz+Mw6ZYeUDgcUDieUThf8N+Uwniv/WxM5vkOL441dtDjlyiAtTq0eEjn2H5p38zMtVtictDh3boEWq73LtFhl99DiXKebFksTE7Q41migxceTEmhxlFyixfreTlrc5rHT4kmvixZv7e3S4v2Xz2nx11/tixyH1qyKHIsch9bEBu1qRY5LGkysxoaWelbjos4WVmPttIXVWO1d8K3Gcx5WY9msk9VY6XCwGiscTlZjpdMltuOjmHXeVGS3PeFNReQVC28qTpQM8abidNkkbyreLx7hTUWUvo83FZF5jbypkG7086YiXt/Em4oTat+bimNSLW8qTmtEjo/ioYfBb4gcixwHeoyDsB1fuL2C+GoLTmr7EFU2hjOlI4g0DCC6pB0RBR8jUnsLx+Q1+ElWNX6urMcx6TqOK+pwKv8WYnXNB1IqupB2dRCZ9ePINbuQ02hDfMUAoko63+ij2nFoe1ZR73oN48QX+OjWIn6m6cFxTQf+If0GAj1PYfz90pQV8gkrMm0OyNxuSE43ZBYbLvR2IaW5EWkD3cids6N8dR5NSx5Mba1j/sUull9u4+He4wPupyvwPJ6F97EL/S4L5C13oBkfgs42Bq3XhYKlRagWvZC8LuR6PVB75qB0zULt9rxRGM+V/62JHNfT4mPSdVp8XFFHi0/l3xI59h+ad/MzLZamfC2WT1hpcabNQYtlbl+LJaebFsssNlp8obeLFqc0N9LitIFuWpw7Z6fF5avztLhpyUOLp7bWafH8i11avPxyW+Q4tGZV5FjkOLQmNmhXK3KsGR9iNdbZxliNtV4Xq3HB0iKrsWrRy2oseV2sxrleD6ux2jPHaqx0zb5xNVa7PUF76kf7wyLHIsdHO3Eh+2sixyLHgR7eIOQ4+cYcUmqncVbfhyjdACL0Az6GvggUt0YcOl1wC6fymvCznFr8OPMq/F9K/DSnBv5//vcXL+OHqfoDv5BdQWzxXVyoGYLSbEPmzQkkVfYisaIHZ4tbkVU/AX3vMmond6Ef3EBc1QT+Ud2G94q68aOsBgR6nsL4+yW7EzkzDkgOFxSzc5C5PFB4F6H0epH/cBG6x2soWFtFycY6qp5s4ubmBpo+38ad5zu4u7d9wLy7jU92t9C8vY4baw9R8eghKjfXUf7kU5+d7fJDZdvbKFp/DPXSIi4tLSF3YRGS2wOlew4F3kWE8Vz535rIcR0t/mlOjcix/3CIz/4nQIslu5MW58w4aLHkcNFixewcLZa5PLRY4V2kxUqvlxbnP1ykxbrHa7S4YG2VFpdsrNPiqiebtPjm5gYtbvp8mxbfeb4jcuz/BN/+zyLHIsdv/5S+FVcocly5ue5bjZ98ympcvuNbjcu2t1mNi9YfsxqrlxZZjS8tLbEa5y4sshpLbg+rsdI9x2pc4F18KyYg8BchcixyHPgpC4tfEDkWOQ70IAchx4G+JfH94gTECYgTCMUTEDkOxacmrlmcgDiBMDwBkeMwfKjilsQJiBMIxRMQOQ7FpyauWZyAOIEwPAGR4zB8qOKWxAmIEwjFExA5DsWnJq5ZnIA4gTA8AZHjMHyo4pbECYgTCMUTEDkOxacmrlmcgDiBMDwBkeMwfKjilsQJiBMIxRMQOQ7FpyauWZyAOIEwPIH/A9xf0990GLmvAAAAAElFTkSuQmCC)"]},{"cell_type":"markdown","metadata":{"id":"y2HuDZktnPSv"},"source":["![image.png](data:image/png;base64,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)"]},{"cell_type":"markdown","metadata":{"id":"9qWKdhZcnvNe"},"source":["![image.png](data:image/png;base64,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)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lABOOwOQn_hZ"},"outputs":[],"source":["num_queries = 10  # Number of queries to classify and explain\n","classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]  # CIFAR-10 classes\n","stair = 0\n","# Iterate through the first `num_queries` test samples\n","for i in range(num_queries):\n","    query = X_test[i+stair].unsqueeze(0)  # Add batch dimension for the query\n","    true_label = y_test[i+stair].item()\n","    results = classify_and_explain(model, query, model.case_nets, classes)\n","\n","    print(f\"Query {i + stair+ 1}:\")\n","    print(f\"  True Class: {classes[true_label]}\")\n","    print(f\"  Predicted Class: {results['query_prediction']}\")\n","    print(f\"  Most Activated Case Label: {results['most_activated_case_label']}\")\n","    print(f\"  Most Activated Activation: {results['most_activated_activation']:.4f}\")\n","    print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"smPhW0ItrEfe"},"outputs":[],"source":["num_queries = 10  # Number of queries to classify and explain\n","classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]  # CIFAR-10 classes\n","stair = 10\n","# Iterate through the first `num_queries` test samples\n","for i in range(num_queries):\n","    query = X_test[i+stair].unsqueeze(0)  # Add batch dimension for the query\n","    true_label = y_test[i+stair].item()\n","    results = classify_and_explain(model, query, model.case_nets, classes)\n","\n","    print(f\"Query {i + stair+ 1}:\")\n","    print(f\"  True Class: {classes[true_label]}\")\n","    print(f\"  Predicted Class: {results['query_prediction']}\")\n","    print(f\"  Most Activated Case Label: {results['most_activated_case_label']}\")\n","    print(f\"  Most Activated Activation: {results['most_activated_activation']:.4f}\")\n","    print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qPfgnGlqt1Kh"},"outputs":[],"source":["num_queries = 10  # Number of queries to classify and explain\n","classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]  # CIFAR-10 classes\n","stair = 10\n","# Iterate through the first `num_queries` test samples\n","for i in range(num_queries):\n","    query = X_test[i+stair].unsqueeze(0)  # Add batch dimension for the query\n","    true_label = y_test[i+stair].item()\n","    results = classify_and_explain(model, query, model.case_nets, classes)\n","\n","    print(f\"Query {i + stair+ 1}:\")\n","    print(f\"  True Class: {classes[true_label]}\")\n","    print(f\"  Predicted Class: {results['query_prediction']}\")\n","    print(f\"  Most Activated Case Label: {results['most_activated_case_label']}\")\n","    print(f\"  Most Activated Activation: {results['most_activated_activation']:.4f}\")\n","    print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ZxaAtyBuqRk"},"outputs":[],"source":["num_queries = 10  # Number of queries to classify and explain\n","classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]  # CIFAR-10 classes\n","stair = 8000\n","# Iterate through the first `num_queries` test samples\n","for i in range(num_queries):\n","    query = X_test[i+stair].unsqueeze(0)  # Add batch dimension for the query\n","    true_label = y_test[i+stair].item()\n","    results = classify_and_explain(model, query, model.case_nets, classes)\n","\n","    print(f\"Query {i + stair+ 1}:\")\n","    print(f\"  True Class: {classes[true_label]}\")\n","    print(f\"  Predicted Class: {results['query_prediction']}\")\n","    print(f\"  Most Activated Case Label: {results['most_activated_case_label']}\")\n","    print(f\"  Most Activated Activation: {results['most_activated_activation']:.4f}\")\n","    print()"]}],"metadata":{"colab":{"collapsed_sections":["vHknYLrK33ES","2MNAEUwC30I0","r3LIZuDx1nTb"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}