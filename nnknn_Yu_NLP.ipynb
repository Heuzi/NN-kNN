{"cells":[{"cell_type":"markdown","metadata":{"id":"6MEBduUKpGrg"},"source":["Introduction for Psychologists:\n","\n","Hello. This is a demo of our model on predicting depression risk and explaining with features and cases. It is trained on a data set of cases.\n","\n","**Case**: a survey participant who answered 102 questions of depression screening survey (self-reporting). Each participant has a depression risk score 0,1,2 (judged by a psychologist, based on number of depression-related physical symptoms)\n","\n","**Feature**: Answers to survey questions (yes/no)\n","\n","**Query**: the new client who we are making a prediction on.\n","\n","**How does it work:**\n"," Our model learns about important features and cases during training. Given a new query (a new client), our model makes a prediction by retrieving the most relevant cases. It can explain in two main ways: highlighting (non-)important features, or highlighting (non-)important cases.\n","\n","**Goal**: The Goal of this demo is not to show you how good or how bad our model performs but more to open up a discussion about what you feel about using such models (part 2 of the interview). Please ignore the non-existing User-experience (UI) and the software code aspects because it is just a prototype. I will do my best to show you only the relevant parts."]},{"cell_type":"markdown","metadata":{"id":"rxoHWNZEmG4g"},"source":["# 1 Setup"]},{"cell_type":"markdown","metadata":{"id":"CsfLxAVaPOTf"},"source":["On google colab, you have to restart runtime after running the following line"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T3Y5CLhymG4l"},"outputs":[],"source":["# !pip install omegaconf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sz8oJcRAdwzs"},"outputs":[],"source":["folder_name = './'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q-0ffsjpbDLE"},"outputs":[],"source":["##This is added because my Rdata uses Cdata for the covid data set.\n","##Rdata use Cdata function to load the data set, then convert it to regression problem\n","import os\n","import sys\n","sys.path.append(folder_name + 'dataset')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":32026,"status":"ok","timestamp":1736957669384,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":300},"id":"oDGrACwVmG4o","outputId":"20656a0b-8d53-4fe8-cf83-41b3a4b7d347"},"outputs":[{"name":"stderr","output_type":"stream","text":["/nfs/nfs8/home/research/ml/ego4d.NOBACKUP/wang/dlenv/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n","  from pandas.core import (\n","/nfs/nfs8/home/research/ml/ego4d.NOBACKUP/wang/dlenv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n","  warn(f\"Failed to load image Python extension: {e}\")\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import accuracy_score\n","from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n","from sklearn.metrics import mean_squared_error\n","from tqdm import tqdm\n","from omegaconf import DictConfig, OmegaConf\n","\n","from dataset import cls_small_data as Cdata\n","from dataset import cls_medium_data\n","\n","from dataset import reg_data as Rdata"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bzTxZZJnmG4p"},"outputs":[],"source":["conf_file = OmegaConf.load(os.path.join(folder_name, 'config.yaml'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yT3W4iqSmG4p"},"outputs":[],"source":["device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1736957670350,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":300},"id":"KcsdY45IjhSV","outputId":"808f7838-dea6-46e3-fed8-87ed83b60fd4"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.is_available()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"54RUct06Mugc"},"outputs":[],"source":["random_seed = 43"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dp9ZZ76YJfzy"},"outputs":[],"source":["debug_print = False\n","def dprint(*args):\n","  global debug_print\n","  if debug_print:\n","    print(*args)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_5Q64-F1dwzv"},"outputs":[],"source":["import importlib\n","# importlib.reload(Rdata)\n","# importlib.reload(Cdata)\n","importlib.reload(cls_medium_data)"]},{"cell_type":"markdown","metadata":{"id":"46TjfSz-mG4q"},"source":["# 2 Data Sets"]},{"cell_type":"markdown","metadata":{"id":"NK9RJK0lKZw9"},"source":["## SST"]},{"cell_type":"markdown","metadata":{"id":"Txi1fC-8dwzw"},"source":["### Deprecated"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s6RWhzxrdwzw"},"outputs":[],"source":["dataset_name = \"sst1\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hJdwfNg-dwzw"},"outputs":[],"source":["num_classes = 5 if dataset_name == \"sst1\" else 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F32KEe75dwzw","outputId":"ba54ea23-7256-4305-c65e-0f7f11430b69"},"outputs":[{"data":{"text/plain":["5"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["num_classes"]},{"cell_type":"markdown","metadata":{"id":"vNitbaEcS6et"},"source":["Version 1, 5 labels\n","\n","Version 2, 2 labels, take out neutral"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KvGUKOHkdwzw"},"outputs":[],"source":["train_data, val_data, test_data = cls_medium_data.Cls_medium_data(dataset_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F7bwjbrUdwzw","outputId":"ed31354a-df19-4850-da77-3a02a0686515"},"outputs":[{"data":{"text/plain":["((8544, 4), (1101, 4), (2210, 4))"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["train_data.shape, val_data.shape, test_data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K-jaWFtCdwzx","outputId":"8a1db9e7-27c2-4464-89bc-5ef76d019f0a"},"outputs":[{"data":{"text/plain":["{'sentence': [\"The Rock is destined to be the 21st Century 's new `` Conan '' and that he 's going to make a splash even greater than Arnold Schwarzenegger , Jean-Claud Van Damme or Steven Segal .\",\n","  \"The Rock is destined to be the 21st Century 's new `` Conan '' and that he 's going to make a splash even greater than Arnold Schwarzenegger , Jean-Claud Van Damme or Steven Segal .\"],\n"," 'label': [3.0, 3.0],\n"," 'tokens': [\"The|Rock|is|destined|to|be|the|21st|Century|'s|new|``|Conan|''|and|that|he|'s|going|to|make|a|splash|even|greater|than|Arnold|Schwarzenegger|,|Jean-Claud|Van|Damme|or|Steven|Segal|.\",\n","  \"The|Rock|is|destined|to|be|the|21st|Century|'s|new|``|Conan|''|and|that|he|'s|going|to|make|a|splash|even|greater|than|Arnold|Schwarzenegger|,|Jean-Claud|Van|Damme|or|Steven|Segal|.\"],\n"," 'tree': ['70|70|68|67|63|62|61|60|58|58|57|56|56|64|65|55|54|53|52|51|49|47|47|46|46|45|40|40|41|39|38|38|43|37|37|69|44|39|42|41|42|43|44|45|50|48|48|49|50|51|52|53|54|55|66|57|59|59|60|61|62|63|64|65|66|67|68|69|71|71|0',\n","  '70|70|68|67|63|62|61|60|58|58|57|56|56|64|65|55|54|53|52|51|49|47|47|46|46|45|40|40|41|39|38|38|43|37|37|69|44|39|42|41|42|43|44|45|50|48|48|49|50|51|52|53|54|55|66|57|59|59|60|61|62|63|64|65|66|67|68|69|71|71|0']}"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["train_data[0, 0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KeXSJr6ddwzx"},"outputs":[],"source":["import nltk\n","# nltk.download('punkt_tab')\n","from nltk.tokenize import word_tokenize"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"weZC7WJodwzx","outputId":"254670ff-3442-4f18-fad0-8d163bc8f3f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Vocab size: 8740\n"]}],"source":["from collections import Counter\n","\n","def build_vocab(dataset, min_freq=1):\n","    \"\"\"\n","    Build a vocabulary from the 'sentence' field of the dataset.\n","    Returns:\n","      word2idx: dict mapping token -> integer index\n","      idx2word: list or dict mapping integer index -> token (optional)\n","    \"\"\"\n","    special_tokens = [\"<pad>\", \"<unk>\"]\n","    counter = Counter()\n","\n","    for i in range(len(dataset)):\n","        text = dataset[i]['sentence']\n","        tokens = word_tokenize(text)\n","        counter.update(tokens)\n","\n","    # Keep tokens with frequency >= min_freq\n","    vocab = [word for word, freq in counter.items() if freq >= min_freq]\n","    vocab = sorted(vocab)\n","\n","    # Build mapping\n","    word2idx = {}\n","    for i, sp_tok in enumerate(special_tokens):\n","        word2idx[sp_tok] = i\n","\n","    for i, word in enumerate(vocab, start=len(special_tokens)):\n","        word2idx[word] = i\n","\n","    return word2idx\n","\n","word2idx = build_vocab(train_data, min_freq=2)  # e.g., min_freq=2 might remove rarer words\n","idx2word = {v:k for k,v in word2idx.items()}\n","\n","PAD_IDX = word2idx[\"<pad>\"]\n","UNK_IDX = word2idx[\"<unk>\"]\n","vocab_size = len(word2idx)\n","print(f\"Vocab size: {vocab_size}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-hu2FYmNdwzx"},"outputs":[],"source":["# import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","# from sklearn.model_selection import train_test_split\n","from torch.nn.utils.rnn import pad_sequence\n","\n","# Let's assume you already have:\n","# train_data, val_data, test_data (dicts with 'sentence' and 'label')\n","# vocab (a dict {token: index, ..., \"<pad>\": some_int})\n","# tokenizer (a function that tokenizes string -> list of tokens)\n","\n","def prepare_dataset(data, vocab, tokenizer):\n","    texts = data[\"sentence\"]\n","    labels = data[\"label\"]\n","    # Convert each text to a list of token indices\n","    tokenized_texts = [\n","        torch.tensor([vocab.get(token, vocab[\"<unk>\"])  # default to <unk> if missing\n","                      for token in tokenizer(text)], dtype=torch.long)\n","        for text in texts\n","    ]\n","    # Pad to the max length in this batch\n","    padded_texts = pad_sequence(tokenized_texts, batch_first=True, padding_value=vocab[\"<pad>\"])\n","\n","    labels = torch.tensor(labels, dtype=torch.long)\n","    return padded_texts, labels\n","\n","# Example usage:\n","X_train, y_train = prepare_dataset(train_data, word2idx, word_tokenize)\n","X_val,   y_val   = prepare_dataset(val_data,   word2idx, word_tokenize)\n","X_test,  y_test  = prepare_dataset(test_data,  word2idx, word_tokenize)\n","\n","train_dataset = TensorDataset(X_train, y_train)\n","val_dataset   = TensorDataset(X_val,   y_val)\n","test_dataset  = TensorDataset(X_test,  y_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JVGRPiZudwzx"},"outputs":[],"source":["# from torch.utils.data import Dataset, DataLoader\n","\n","# class SST2DocDataset(Dataset):\n","#     def __init__(self, hf_dataset, word2idx, offset_doc_id=0):\n","#         self.hf_dataset = hf_dataset\n","#         self.word2idx = word2idx\n","#         self.offset_doc_id = offset_doc_id  # so we can keep doc IDs globally unique across train/val/test\n","\n","#     def __len__(self):\n","#         return len(self.hf_dataset)\n","\n","#     def __getitem__(self, idx):\n","#         item = self.hf_dataset[idx]\n","#         text = item['sentence']\n","#         label = item['label']  # 0 or 1\n","\n","#         # doc_id is index in dataset + some offset\n","#         doc_id = idx + self.offset_doc_id\n","\n","#         tokens = word_tokenize(text)\n","#         token_ids = [self.word2idx.get(t, self.word2idx[\"<UNK>\"]) for t in tokens]\n","\n","#         return {\n","#             'doc_id': doc_id,\n","#             'token_ids': token_ids,\n","#             'label': label\n","#         }\n","\n","# def collate_fn(batch):\n","#     \"\"\"\n","#     batch: list of dicts with keys ['doc_id', 'token_ids', 'label'].\n","#     We'll pad token_ids to the max length in the batch.\n","#     Returns:\n","#       doc_id_tensor (batch_size,)\n","#       padded_tokens (batch_size, max_len)\n","#       seq_lengths   (batch_size,) - actual lengths before padding\n","#       labels        (batch_size,)\n","#     \"\"\"\n","#     doc_ids = [x['doc_id'] for x in batch]\n","#     labels  = [x['label'] for x in batch]\n","\n","#     # Pad token sequences\n","#     token_lists = [x['token_ids'] for x in batch]\n","#     seq_lengths = [len(t) for t in token_lists]\n","#     max_len = max(seq_lengths) if seq_lengths else 1  # handle empty edge case\n","\n","#     padded_tokens = []\n","#     for t in token_lists:\n","#         padding_needed = max_len - len(t)\n","#         padded = t + [PAD_IDX]*padding_needed\n","#         padded_tokens.append(padded)\n","\n","#     # Convert to tensors\n","#     doc_id_tensor   = torch.tensor(doc_ids, dtype=torch.long)\n","#     padded_tokens_t = torch.tensor(padded_tokens, dtype=torch.long)\n","#     seq_len_tensor  = torch.tensor(seq_lengths, dtype=torch.long)\n","#     label_tensor    = torch.tensor(labels, dtype=torch.long)\n","\n","#     return doc_id_tensor, padded_tokens_t, seq_len_tensor, label_tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W-xqXQfFdwzx"},"outputs":[],"source":["# class Doc2VecModel(nn.Module):\n","#     def __init__(self, vocab_size, doc_count, embed_dim, num_classes=2):\n","#         \"\"\"\n","#         vocab_size: total number of tokens in vocabulary\n","#         doc_count:  total number of documents (train + val + test)\n","#         embed_dim:  dimension of embeddings\n","#         num_classes: e.g. 2 for binary classification\n","#         \"\"\"\n","#         super().__init__()\n","#         self.word_embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_dim)\n","\n","#         # One embedding vector per document ID\n","#         self.doc_embeddings = nn.Embedding(num_embeddings=doc_count, embedding_dim=embed_dim)\n","\n","#         # Classifier\n","#         self.fc = nn.Linear(embed_dim, num_classes)\n","\n","#     def forward(self, doc_ids, token_ids):\n","#         \"\"\"\n","#         doc_ids:   (batch_size,)\n","#         token_ids: (batch_size, seq_len)\n","#         \"\"\"\n","#         # Embed the documents -> shape: (batch_size, embed_dim)\n","#         d_emb = self.doc_embeddings(doc_ids)\n","\n","#         # Embed each token -> shape: (batch_size, seq_len, embed_dim)\n","#         w_emb = self.word_embeddings(token_ids)\n","\n","#         # Average across the sequence dimension to get a single vector per document\n","#         # Alternatively, you could do sum or an RNN, etc.\n","#         w_emb_mean = w_emb.mean(dim=1)  # shape: (batch_size, embed_dim)\n","\n","#         # Combine doc embedding + word embedding\n","#         doc_vector = d_emb + w_emb_mean  # shape: (batch_size, embed_dim)\n","\n","#         # Classify\n","#         logits = self.fc(doc_vector)  # shape: (batch_size, num_classes)\n","#         return logits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IkANDbfJdwzx"},"outputs":[],"source":["train_len = len(train_data)\n","val_len   = len(val_data)\n","test_len  = len(test_data)\n","\n","# train_dataset = SST2DocDataset(train_data, word2idx, offset_doc_id=0)\n","# val_dataset   = SST2DocDataset(val_data,   word2idx, offset_doc_id=train_len)\n","# test_dataset  = SST2DocDataset(test_data,  word2idx, offset_doc_id=(train_len + val_len))\n","doc_count = train_len + val_len + test_len"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AU4xQ6uAdwzy"},"outputs":[],"source":["# # import torch.optim as optim\n","# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n","# val_loader   = DataLoader(val_dataset,   batch_size=32, shuffle=False, collate_fn=collate_fn)\n","# test_loader  = DataLoader(test_dataset,  batch_size=32, shuffle=False, collate_fn=collate_fn)\n","\n","# doc_count = len(train_dataset) + len(val_dataset) + len(test_dataset)\n","# model = Doc2VecModel(\n","#     vocab_size=vocab_size,\n","#     doc_count=doc_count,\n","#     embed_dim=64,   # hyperparameter\n","#     num_classes=2\n","# )\n","\n","# criterion = nn.CrossEntropyLoss()\n","# optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","\n","# # Example: single epoch training loop\n","# for epoch in range(100):\n","#     model.train()\n","#     for doc_ids, token_ids, labels in train_loader:\n","#         # Forward pass\n","#         logits = model(doc_ids, token_ids)\n","#         loss = criterion(logits, labels)\n","\n","#         # Backprop + update\n","#         optimizer.zero_grad()\n","#         loss.backward()\n","#         optimizer.step()\n","\n","#     # Evaluate on validation set\n","#     model.eval()\n","#     correct, total = 0, 0\n","#     with torch.no_grad():\n","#         for doc_ids, token_ids, labels in val_loader:\n","#             logits = model(doc_ids, token_ids)\n","#             preds = logits.argmax(dim=1)\n","#             correct += (preds == labels).sum().item()\n","#             total   += labels.size(0)\n","#     val_acc = correct / total\n","#     print(f\"Epoch {epoch+1}, Val Accuracy = {val_acc:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cy-a7k0mdwzy"},"outputs":[],"source":["# import torch\n","# import torch.nn as nn\n","\n","# class BiLSTMClassifier(nn.Module):\n","#     def __init__(self, vocab_size, embed_dim=128, hidden_dim=128, num_classes=2):\n","#         \"\"\"\n","#         A purely Bi-LSTM-based classifier:\n","#           - Embeds tokens\n","#           - Encodes with a bidirectional LSTM\n","#           - Classifies based on the final hidden states\n","\n","#         Args:\n","#           vocab_size: size of vocabulary for nn.Embedding\n","#           embed_dim: dimension of each token embedding\n","#           hidden_dim: hidden size in the LSTM (per direction)\n","#           num_classes: number of output classes\n","#         \"\"\"\n","#         super().__init__()\n","#         # If you have a PAD_IDX, you can pass `padding_idx=PAD_IDX` to ignore\n","#         # the padded positions in the embedding. Otherwise, remove it.\n","#         self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n","\n","#         # Bi-LSTM means num_directions=2 for a single layer\n","#         self.lstm = nn.LSTM(\n","#             input_size=embed_dim,\n","#             hidden_size=hidden_dim,\n","#             batch_first=True,\n","#             bidirectional=True\n","#         )\n","\n","#         # Dropout to help reduce overfitting\n","#         # self.dropout = nn.Dropout(0.5)\n","\n","#         # Because bidirectional => final hidden state has dimensionality 2 * hidden_dim\n","#         self.fc = nn.Sequential(\n","#             nn.Linear(hidden_dim * 2, 128),\n","#             nn.ReLU(),\n","#             # nn.Dropout(0.2),\n","#             nn.Linear(128, num_classes)\n","#         )\n","\n","#     def forward(self, tokens, seq_lengths):\n","#         \"\"\"\n","#         We keep the same input signature for convenience, but `doc_ids` is unused.\n","\n","#         Args:\n","#           doc_ids:   (batch_size,) doc IDs [ignored in this model]\n","#           tokens:    (batch_size, max_len) long tensor of token IDs\n","#           seq_lengths: (batch_size,) lengths for each sequence (before padding)\n","\n","#         Returns:\n","#           logits of shape (batch_size, num_classes).\n","#         \"\"\"\n","\n","#         # [1] Embed the tokens\n","#         w_emb = self.embedding(tokens)  # (batch_size, max_len, embed_dim)\n","\n","#         # [2] Pack to ignore padded steps in the LSTM\n","#         packed_input = nn.utils.rnn.pack_padded_sequence(\n","#             w_emb,\n","#             lengths=seq_lengths.cpu(),  # lengths must be on CPU\n","#             batch_first=True,\n","#             enforce_sorted=False\n","#         )\n","\n","#         # [3] LSTM forward\n","#         #    h_n has shape (num_layers * num_directions, batch_size, hidden_dim).\n","#         #    For a single-layer Bi-LSTM => shape is (2, B, hidden_dim).\n","#         packed_output, (h_n, c_n) = self.lstm(packed_input)\n","\n","#         # [4] Concatenate the final forward and backward hidden states\n","#         #    h_n is [2, B, hidden_dim]. Let's reshape to [B, 2*hidden_dim].\n","#         h_n = h_n.transpose(0, 1).contiguous()  # [B, 2, hidden_dim]\n","#         h_n = h_n.view(h_n.size(0), -1)         # [B, 2*hidden_dim]\n","\n","#         # [5] Optional dropout before classification\n","#         # h_n = self.dropout(h_n)\n","\n","#         # [6] Classification head\n","#         logits = self.fc(h_n)  # (batch_size, num_classes)\n","\n","#         return logits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b9VyPWeqdwzy"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class BiLSTMClassifier(nn.Module):\n","    def __init__(self, vocab_size, embed_dim=128, hidden_dim=128, num_classes=2, pad_idx=0):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n","\n","        # bidirectional => output hidden_dim * 2\n","        self.lstm = nn.LSTM(\n","            input_size=embed_dim,\n","            hidden_size=hidden_dim,\n","            batch_first=True,\n","            bidirectional=True\n","        )\n","\n","        self.dropout = nn.Dropout(0.5)\n","        # final linear: 2*hidden_dim -> some intermediate -> ...\n","        self.fc = nn.Sequential(\n","            nn.Linear(hidden_dim * 2, 64),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(64, num_classes)\n","        )\n","\n","    def forward(self, tokens):\n","        # 'doc_ids' is ignored in this version\n","        embedded = self.embedding(tokens)\n","\n","        # pack so LSTM can skip the padded positions\n","        # packed = nn.utils.rnn.pack_padded_sequence(\n","        #     embedded,\n","        #     seq_lengths.cpu(),\n","        #     batch_first=True,\n","        #     enforce_sorted=False\n","        # )\n","\n","        _, (h_n, _) = self.lstm(embedded)  # h_n shape: (2, B, hidden_dim) for BiLSTM (1 layer)\n","\n","        # rearrange to shape (B, 2*hidden_dim)\n","        h_n = h_n.transpose(0, 1).contiguous().view(tokens.size(0), -1)\n","\n","        h_n = self.dropout(h_n)\n","        logits = self.fc(h_n)  # (B, num_classes)\n","        return logits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"41MdzoLgdwzy"},"outputs":[],"source":["train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader   = DataLoader(val_dataset,   batch_size=32, shuffle=False)\n","test_loader  = DataLoader(test_dataset,  batch_size=32, shuffle=False)\n","\n","PAD_IDX = word2idx[\"<pad>\"]  # the integer used for padding\n","model = BiLSTMClassifier(\n","    vocab_size=len(word2idx),\n","    embed_dim=128,\n","    hidden_dim=128,\n","    num_classes=num_classes,\n","    pad_idx=PAD_IDX\n",")\n","model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","\n","for epoch in range(100):\n","    model.train()\n","    total_loss = 0\n","    for X_batch, y_batch in train_loader:\n","        X_batch = X_batch.to(device)\n","        y_batch = y_batch.to(device)\n","\n","        # 1) compute seq_lengths by counting non-pad tokens\n","        seq_lengths = (X_batch != PAD_IDX).sum(dim=1)\n","\n","        # 2) forward pass: pass doc_ids=None, tokens=X_batch, seq_lengths=seq_lengths\n","        logits = model(X_batch)\n","\n","        loss = criterion(logits, y_batch)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    # Evaluate on val set\n","    model.eval()\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","        for X_batch, y_batch in val_loader:\n","            X_batch = X_batch.to(device)\n","            y_batch = y_batch.to(device)\n","\n","            logits = model(X_batch)\n","            preds = logits.argmax(dim=1)\n","            correct += (preds == y_batch).sum().item()\n","            total += y_batch.size(0)\n","    val_acc = correct / total\n","    print(f\"Epoch {epoch+1} - Train Loss: {total_loss:.4f} Val Acc: {val_acc:.4f}\")\n","\n","model.eval()\n","correct, total = 0, 0\n","with torch.no_grad():\n","    for X_batch, y_batch in test_loader:\n","        X_batch = X_batch.to(device)\n","        y_batch = y_batch.to(device)\n","\n","        logits = model(X_batch)\n","        preds = logits.argmax(dim=1)\n","        correct += (preds == y_batch).sum().item()\n","        total += y_batch.size(0)\n","test_acc = correct / total\n","print(f\"Epoch {epoch+1} - Test Acc: {test_acc:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"nxSpBPTBsRfR"},"source":["# GO"]},{"cell_type":"markdown","metadata":{"id":"Q9Z9vzQI8bdu"},"source":["## Feature Extractor"]},{"cell_type":"markdown","metadata":{"id":"-9vjp7Bidqnw"},"source":["### For Cifar10"]},{"cell_type":"markdown","metadata":{"id":"nP3nK-hABUb_"},"source":["https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/"]},{"cell_type":"markdown","metadata":{"id":"NfrMkpGvl_dG"},"source":["### Set up Feature Extractor"]},{"cell_type":"markdown","metadata":{"id":"dK0TeR-_mS3Y"},"source":["If you don't want feature extractor\n"]},{"cell_type":"markdown","metadata":{"id":"L_RvkFavIgmc"},"source":["# Text Classification Task"]},{"cell_type":"markdown","metadata":{"id":"zet7XwfjlcH0"},"source":["https://arxiv.org/pdf/1408.5882"]},{"cell_type":"markdown","metadata":{"id":"v7bVs5TdlcgJ"},"source":["https://github.com/Impavidity/kim_cnn"]},{"cell_type":"markdown","metadata":{"id":"2brzhaOcN1cl"},"source":["Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bg22h24xODjs"},"outputs":[],"source":["class BiLSTMFeatureExtractor(nn.Module):\n","    def __init__(self, lstm_classifier=None):\n","        \"\"\"\n","        lstm_classifier: a trained BiLSTMClassifier instance\n","                         whose submodules we'll reuse\n","        \"\"\"\n","        super().__init__()\n","        # Copy submodules from the trained classifier\n","        # We won't use fc (the classification head).\n","\n","        if lstm_classifier is None:\n","            lstm_classifier = BiLSTMClassifier(\n","                                vocab_size=len(word2idx),\n","                                embed_dim=128,\n","                                hidden_dim=128,\n","                                num_classes=2,\n","                                pad_idx=PAD_IDX)\n","\n","        self.embedding = lstm_classifier.embedding\n","        self.lstm = lstm_classifier.lstm\n","        self.feature_dim = None\n","\n","    def forward(self, tokens):\n","        \"\"\"\n","        Return a fixed-length feature (batch_size, 2*hidden_dim)\n","        from the final hidden states of the BiLSTM.\n","        \"\"\"\n","        # doc_ids is ignored\n","        w_emb = self.embedding(tokens)\n","\n","        packed_output, (h_n, c_n) = self.lstm(w_emb)\n","\n","        # h_n shape: (num_layers*num_directions, batch_size, hidden_dim)\n","        # For a single-layer BiLSTM => (2, B, hidden_dim)\n","        h_n = h_n.transpose(0, 1).contiguous()  # => (B, 2, hidden_dim)\n","        h_n = h_n.view(h_n.size(0), -1)         # => (B, 2*hidden_dim)\n","\n","        return h_n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"24PpLGZndwz3"},"outputs":[],"source":["feature_extractor = BiLSTMFeatureExtractor(None)\n","# feature_extractor.eval()  # so we don't train it further"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D5lVH_kWdwz3"},"outputs":[],"source":["for param in feature_extractor.parameters():\n","  param.requires_grad = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qXGookhLdwz3"},"outputs":[],"source":["from types import SimpleNamespace\n","cfg = SimpleNamespace(**{\"batch\": 100})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ekTJDOyudwz3"},"outputs":[],"source":["cfg.PATH = os.path.join(folder_name, f'checkpoints/classifier_{dataset_name}.h5')\n","cfg.patience = 7\n","cfg.training_epochs = 100"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y2MLlAJGdwz3"},"outputs":[],"source":["# for param in feature_extractor.parameters():\n","#     print(param.requires_grad)"]},{"cell_type":"markdown","metadata":{"id":"vxFFP2wGd_Cj"},"source":["# Sanity Check\n","Sanity check with a standard NN classifier using the feature extractor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tGBqnMoSdwz3","outputId":"35c7c86d-5233-423f-b97d-3e4fa83ca986"},"outputs":[{"data":{"text/plain":["(torch.Size([8544, 53]), torch.Size([2210, 56]))"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["X_train.shape, X_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aQPpN2NYLJv8"},"outputs":[],"source":["# import torch.optim as optim\n","# from torch.utils.data import DataLoader, TensorDataset\n","\n","# model.to(device)\n","\n","# # Define hyperparameters\n","# learning_rate = 0.0001\n","# num_epochs = 100  # Extend epochs since early stopping will halt earlier if needed\n","# patience = 100\n","# best_loss = float('inf')\n","# patience_counter = 0\n","# batch_size = 32  # Mini-batch size\n","\n","# # Define optimizer\n","# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# # Prepare the DataLoader for batching (Training Data)\n","# train_dataset = TensorDataset(X_train, y_train)\n","# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","# # Prepare the DataLoader for validation/testing (Validation Data)\n","# val_dataset = TensorDataset(X_test, y_test)\n","# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","# # Training loop\n","# for epoch in range(num_epochs):\n","#     # Train the model for one epoch\n","#     model.train()\n","#     for images, labels in train_loader:\n","#         optimizer.zero_grad()  # Zero the gradients\n","#         # Move images and labels to the same device as the model\n","#         images = images.to(device)\n","#         labels = labels.to(device)\n","#         # if(dataset_name == 'mnist'):\n","#         #   # Reshape images to add channel dimension (for CNN models on MNIST)\n","#         #   images = images.unsqueeze(1)  # Adds channel dimension (B, 1, H, W)\n","\n","#         # Forward pass\n","#         outputs = model(images)\n","#         loss = criterion(outputs, labels)\n","\n","#         # Backward pass and optimization\n","#         loss.backward()\n","#         optimizer.step()\n","\n","#     # Calculate average loss on validation set after each epoch\n","#     model.eval()\n","#     val_loss = 0.0\n","#     with torch.no_grad():\n","#         for images, labels in val_loader:\n","#             # if(dataset_name == 'mnist'):\n","#             #   images = images.unsqueeze(1)\n","#             images = images.to(device)\n","#             labels = labels.to(device)\n","#             outputs = model(images)\n","#             loss = criterion(outputs, labels)\n","#             val_loss += loss.item()\n","\n","#     avg_epoch_loss = val_loss / len(val_loader)  # Average loss over the validation set\n","#     print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {avg_epoch_loss:.4f}\")\n","\n","#     # Early stopping based on validation loss\n","#     if val_loss < best_loss:\n","#         best_loss = val_loss\n","#         patience_counter = 0\n","#         torch.save(model.state_dict(), 'best_model.pth')  # Save the best model\n","#     else:\n","#         patience_counter += 1\n","\n","#     if patience_counter >= patience:\n","#         print(f\"Early stopping triggered after {epoch+1} epochs.\")\n","#         model.load_state_dict(torch.load('best_model.pth'))  # Restore best model\n","#         break\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ln9HpOuYnld-"},"outputs":[],"source":["# import torch\n","# from torch.utils.data import DataLoader, TensorDataset\n","\n","# # Define batch size for testing\n","# test_batch_size = 128  # Adjust based on memory capacity\n","\n","# # Prepare the DataLoader for batching the test set\n","# test_dataset = TensorDataset(X_test, y_test)\n","# test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n","\n","# correct = 0\n","# total = 0\n","\n","# # Evaluation loop using DataLoader\n","# with torch.no_grad():\n","#     for images, labels in test_loader:\n","#         # Reshape for CNNs (e.g., MNIST)\n","#         # if dataset_name == 'mnist':\n","#         #     images = images.unsqueeze(1)  # Add channel dimension (B, 1, H, W)\n","#         images = images.to(device)\n","#         labels = labels.to(device)\n","#         # Forward pass over the mini-batch\n","#         outputs = model(images)\n","#         _, predicted = torch.max(outputs, 1)  # Get predicted class (max along dim=1)\n","\n","#         # Accumulate correct predictions\n","#         correct += (predicted == labels).sum().item()\n","#         total += labels.size(0)\n","\n","# # Calculate and print accuracy\n","# accuracy = 100 * correct / total\n","# print(f\"Accuracy of the model on the test images: {accuracy:.2f}%\")\n"]},{"cell_type":"markdown","metadata":{"id":"s5_q_St3dwz4"},"source":["## Pretrained Feature for KNN (Pretrained Conv + KNN)"]},{"cell_type":"markdown","metadata":{"id":"VmIRcBiHjnFj"},"source":["Run the following if you want to transform the features for vanilla knn"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1567,"status":"ok","timestamp":1736545681816,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":300},"id":"yaby7Ru7qUN6","outputId":"d3f7d0b0-329d-411e-974d-94d7929281e0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Transformed X_train shape: torch.Size([8544, 256])\n","Transformed X_test shape: torch.Size([2210, 256])\n"]}],"source":["# Step 1: Freeze the feature extractor's weights\n","for param in feature_extractor.parameters():\n","    param.requires_grad = False\n","\n","# Step 2: Convert X_train and X_test\n","def transform_dataset(X, feature_extractor, batch_size=128, device='cuda'):\n","    \"\"\"\n","    Transform a dataset using the feature extractor.\n","\n","    Args:\n","        X (torch.Tensor): Input dataset of shape (num_samples, channels, height, width).\n","        feature_extractor (nn.Module): Feature extractor model.\n","        batch_size (int): Batch size for processing.\n","        device (str): Device to perform computations ('cuda' or 'cpu').\n","\n","    Returns:\n","        torch.Tensor: Transformed dataset of shape (num_samples, feature_dim).\n","    \"\"\"\n","    feature_extractor.eval()  # Ensure the feature extractor is in evaluation mode\n","    X = X.to(device)\n","    transformed_features = []\n","\n","    with torch.no_grad():  # Disable gradient computation for efficiency\n","        for i in range(0, X.size(0), batch_size):\n","            batch = X[i:i + batch_size]\n","            features = feature_extractor(batch)  # Extract features\n","            transformed_features.append(features)\n","\n","    return torch.cat(transformed_features, dim=0)\n","\n","# Transform the datasets\n","X_train_transformed = transform_dataset(X_train, feature_extractor, batch_size=128, device=device)\n","X_test_transformed = transform_dataset(X_test, feature_extractor, batch_size=128, device=device)\n","\n","# Print shapes to verify\n","print(f\"Transformed X_train shape: {X_train_transformed.shape}\")\n","print(f\"Transformed X_test shape: {X_test_transformed.shape}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"12E0MLs4dwz4"},"outputs":[],"source":["feature_extractor = None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ycSFx7yGqXTn"},"outputs":[],"source":["X_train = X_train_transformed\n","X_test = X_test_transformed"]},{"cell_type":"markdown","metadata":{"id":"aIH5bd_O3eg3"},"source":["Sanity check using a vanilla knn"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":908,"status":"ok","timestamp":1736545686346,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":300},"id":"DD4hFap-tQ1Y","outputId":"42e6b4b6-48a2-4345-895f-2235046a5b87"},"outputs":[{"name":"stdout","output_type":"stream","text":["k-NN Accuracy: 0.35158371040723985\n"]}],"source":["# prompt: knn on the train and test data set\n","\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","# Assuming X_train, y_train, X_test, and y_test are defined from the previous code\n","# and contain the training and testing data.\n","\n","# Initialize the k-NN classifier\n","knn = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors\n","\n","# Reshape X_train and X_test to 2D arrays before fitting the k-NN model\n","X_train_reshaped = X_train.reshape(X_train.shape[0], -1)  # Reshape to (num_samples, height * width)\n","X_test_reshaped = X_test.reshape(X_test.shape[0], -1)    # Reshape to (num_samples, height * width)\n","\n","# Train the classifier on the reshaped training data\n","knn.fit(X_train_reshaped.cpu(), y_train)\n","\n","# Make predictions on the reshaped test data\n","y_pred = knn.predict(X_test_reshaped.cpu())\n","\n","# Evaluate the model (example: accuracy)\n","accuracy = accuracy_score(y_test.cpu().numpy(), y_pred)\n","print(f\"k-NN Accuracy: {accuracy}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8LytomXVdwz5"},"outputs":[],"source":["# del X_train_transformed, X_test_transformed"]},{"cell_type":"markdown","metadata":{"id":"xZUXibQNLGTj"},"source":["# Param Setup\n"]},{"cell_type":"markdown","metadata":{"id":"yLr1V5cGBSVb"},"source":["### Shared Param Setup"]},{"cell_type":"markdown","metadata":{"id":"sbhsX-I8dwz5"},"source":["Must run!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_3YnWoOwLHs6"},"outputs":[],"source":["def get_feature_dim(case, feature_extractor):\n","        if feature_extractor is None:\n","            return torch.prod(torch.tensor(case.shape)).item()\n","        else:\n","            return feature_extractor.feature_dim"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YZHloHXQLMBK"},"outputs":[],"source":["#if Xs is not defined, use X_train\n","if 'Xs' not in locals():\n","    Xs = X_train\n","    ys = y_train\n","\n","# feature_dim = get_feature_dim(Xs[0], feature_extractor)# Xs.shape[1]\n","# glocal_fw_set_num = 4;\n","\n","# sampling_cases_flag = False\n","# use_sampling_cases_divisor = False\n","# sampling_cases_divisor = 100\n","\n","# #DESIGN DECISION\n","# case_activation_by_top_k_average = True\n","# top_k_for_case_activation = 5\n","# num_samples=5000\n","\n","# #if case_activation_by_top_k_average = False, following will be used\n","# case_activation_default_percentage = 0.1  #this might require enabling top k\n","# top_case_enabled = False\n","\n","# bias_manual_set = False\n","# bias_manual_value = 6.0\n","\n","# model_path = 'best_model.pth'\n","# feature_weightor_path = 'best_fw.pth'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OFc7sVBKdwz5"},"outputs":[],"source":["case_activation_by_top_k_average = True\n","bias_manual_set = False\n","bias_manual_value = 6.0"]},{"cell_type":"markdown","metadata":{"id":"TmTmWAaqBWjz"},"source":["### Non-shared setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gbVb-x-dZnp_"},"outputs":[],"source":["#For MNIST\n","glocal_fw_set_num = 1\n","sampling_cases_flag = True\n","top_k_for_case_activation = 20\n","num_samples=500"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dxpbi5ISiyI7"},"outputs":[],"source":["#For Cifar 10\n","\n","glocal_fw_set_num = 1\n","sampling_cases_flag = True\n","top_k_for_case_activation = 20\n","num_samples=500"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gfpUrktGdwz6"},"outputs":[],"source":["#For SVHN\n","\n","glocal_fw_set_num = 4\n","sampling_cases_flag = True\n","top_k_for_case_activation = 20\n","num_samples=500"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QS33BQbPiSYH"},"outputs":[],"source":["#For SST\n","\n","glocal_fw_set_num = 4\n","sampling_cases_flag = True\n","top_k_for_case_activation = 5\n","num_samples=500"]},{"cell_type":"markdown","metadata":{"id":"HwswC5Cbdwz6"},"source":["# MUST RUN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Xz2ya_sdwz6"},"outputs":[],"source":["feature_extractor = BiLSTMFeatureExtractor().to(device)"]},{"cell_type":"markdown","metadata":{"id":"vHknYLrK33ES"},"source":["## Glocal Feature Weight"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lOL2WF2x4Ug3"},"outputs":[],"source":["class GlocalFeatureWeight(nn.Module):\n","    def __init__(self, feature_dim, set_num):\n","        \"\"\"\n","        Glocal feature weighting module for batched operations.\n","\n","        Args:\n","            feature_dim: Dimensionality of the features.\n","            set_num: Number of glocal weight sets.\n","        \"\"\"\n","        super(GlocalFeatureWeight, self).__init__()\n","        self.feature_dim = feature_dim\n","\n","        # Initialize feature weights\n","        self.feature_weights = nn.Parameter(torch.rand((set_num, feature_dim)), requires_grad=True)\n","        if glocal_fw_set_num == 1:\n","            self.feature_weights = nn.Parameter(torch.ones((set_num, feature_dim)), requires_grad=True)  # Shape: (set_num, feature_dim)\n","\n","    def forward(self, case_distance, glocal_weights):\n","        \"\"\"\n","        Apply feature weighting to the case distance in a batched manner.\n","\n","        Args:\n","            case_distance: Tensor of shape (batch_size, sample_num, feature_dim).\n","            glocal_weights: Tensor of shape (sample_num, set_num).\n","\n","        Returns:\n","            weighted_distance: Weighted case distance, shape (batch_size, sample_num, feature_dim).\n","        \"\"\"\n","        global debug_print\n","        debug_print = False\n","\n","        # Ensure positive feature weights using LeakyReLU\n","        pos_feature_weights = F.leaky_relu(self.feature_weights, negative_slope=0.001)  # Shape: (set_num, feature_dim)\n","        glocal_weights = F.leaky_relu(glocal_weights, negative_slope=0.001)  # Shape: (sample_num, set_num)\n","\n","        # Compute weight factors for all cases\n","        # Resulting shape: (sample_num, feature_dim)\n","        weight_factors = torch.matmul(glocal_weights, pos_feature_weights)  # Shape: (sample_num, feature_dim)\n","\n","        # Expand weight_factors to match batch size and elementwise multiply\n","        weighted_distance = case_distance * weight_factors.unsqueeze(0)  # Shape: (batch_size, sample_num, feature_dim)\n","\n","        if debug_print:\n","            print(\"case_distance:\", case_distance)\n","            print(\"glocal_weights:\", glocal_weights)\n","            print(\"feature_weights:\", self.feature_weights)\n","            print(\"weighted_distance:\", weighted_distance)\n","\n","        return weighted_distance\n"]},{"cell_type":"markdown","metadata":{"id":"vr-zruqOgsQJ"},"source":["## Case Bias Setup and others"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qBMS10DHoWVW"},"outputs":[],"source":["# prompt: a class recording a case's How often it is activated, how often it is sampled, how often it correctly classifies a query.\n","\n","class CaseRecord:\n","    def __init__(self, case_id = None):\n","        self.case_id = case_id\n","        self.activation_count = 0\n","        self.sample_count = 0\n","        self.correct_classification_count = 0\n","\n","    def activate(self):\n","        self.activation_count += 1\n","\n","    def sample(self):\n","        self.sample_count += 1\n","\n","    def correct_classification(self):\n","        self.correct_classification_count += 1\n","\n","    def get_activation_rate(self):\n","        return self.activation_count / (self.sample_count + 1e-10) # avoid division by zero\n","\n","    def get_sampling_rate(self):\n","      return self.sample_count\n","\n","    def get_accuracy(self):\n","        return self.correct_classification_count / (self.sample_count + 1e-10) # avoid division by zero"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Ge7LLx-f0mm"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","\n","def find_default_bias(X, feature_extractor = None,num_samples=500, case_activation_default_percentage=0.1):\n","    \"\"\"\n","    Estimates the default bias for CaseNets by randomly comparing pairwise distances.\n","    Handles both image (e.g., MNIST) and tabular data.\n","\n","    Args:\n","        X: The feature tensor. Shape can be (num_cases, feature_dim) or (num_cases, 1, H, W).\n","        num_samples: The number of random case pairs to compare.\n","        case_activation_default_percentage: Percentage of sorted distances to select.\n","\n","    Returns:\n","        The estimated default bias.\n","    \"\"\"\n","    num_cases = X.shape[0]\n","    distances = []\n","\n","    # Flatten if data is image-like (e.g., (num_cases, 1, 28, 28))\n","    if len(X.shape) > 2:\n","        X_flat = X.view(num_cases, -1)  # Flatten to (num_cases, feature_dim)\n","    else:\n","        X_flat = X  # Already in tabular form\n","    if feature_extractor is not None:\n","        # Extract features using the feature extractor\n","        with torch.no_grad():  # Disable gradient computation for efficiency\n","            X_flat = feature_extractor(X).view(X.shape[0], -1)  # Flatten to (num_cases, feature_dim)\n","\n","    # Compute random pairwise distances\n","    for _ in range(num_samples):\n","        idx1, idx2 = torch.randint(0, num_cases, (2,))\n","\n","        # Calculate the pairwise distance\n","        distance = F.pairwise_distance(X_flat[idx1].unsqueeze(0), X_flat[idx2].unsqueeze(0))\n","        distances.append(distance.item())\n","\n","    # Sort distances and select top 10% based on case_activation_default_percentage\n","    distances.sort()\n","    percentile_index = int(len(distances) * case_activation_default_percentage)\n","    default_bias = distances[percentile_index]\n","\n","    return default_bias\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fv3FXZfghhf3"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","\n","def find_default_bias_knn(X, feature_extractor=None, k=5, num_samples=500, batch_size=64):\n","    \"\"\"\n","    Efficiently estimates the default bias for CaseNets by computing the average distance\n","    to the k-th nearest neighbor for each case, using a randomly sampled subset of cases.\n","\n","    Args:\n","        X: The feature tensor, shape (num_cases, channels, height, width) for MNIST or CIFAR-10.\n","        feature_extractor: Optional feature extractor to transform the input tensor.\n","        k: The number of nearest neighbors to consider.\n","        num_samples: Number of random cases to compare against.\n","        batch_size: Batch size for processing cases.\n","\n","    Returns:\n","        The estimated default bias (average distance to the k-th nearest neighbor).\n","    \"\"\"\n","    num_cases = X.shape[0]\n","    all_kth_distances = []\n","\n","    # Extract features using the feature extractor, if provided\n","    if feature_extractor is not None:\n","        feature_list = []\n","        with torch.no_grad():\n","            for i in range(0, num_cases, batch_size):\n","                batch = X[i:i + batch_size]  # Shape: (batch_size, channels, height, width)\n","                batch_features = feature_extractor(batch)  # Shape: (batch_size, feature_dim)\n","                feature_list.append(batch_features)\n","        X = torch.cat(feature_list, dim=0)  # Concatenate all batches\n","\n","    # Flatten the features for distance computation\n","    X_flat = X.view(X.shape[0], -1)  # Shape: (num_cases, feature_dim)\n","\n","    # Randomly sample `num_samples` cases to form the comparison set\n","    sampled_indices = torch.randperm(num_cases)[:num_samples]\n","    sampled_cases = X_flat[sampled_indices]  # Shape: (num_samples, feature_dim)\n","\n","    # Process cases in batches to reduce memory usage\n","    for i in range(0, num_cases, batch_size):\n","        # Get the batch of cases\n","        batch = X_flat[i:i + batch_size]  # Shape: (batch_size, feature_dim)\n","\n","        # Compute pairwise distances with the sampled cases\n","        distances = torch.cdist(batch, sampled_cases)  # Shape: (batch_size, num_samples)\n","\n","        # Set self-distances to infinity for sampled cases\n","        batch_indices = torch.arange(i, min(i + batch_size, num_cases))\n","        mask = (batch_indices.unsqueeze(1) == sampled_indices.unsqueeze(0))  # Match indices in the batch\n","        distances[mask] = float('inf')\n","\n","        # Get the k-th smallest distance for each case in the batch\n","        k_actual = min(k, num_samples)  # Ensure k does not exceed the number of samples\n","        kth_distances = torch.topk(distances, k=k_actual, largest=False).values[:, -1]\n","        all_kth_distances.extend(kth_distances.tolist())\n","\n","    # Return the average k-th neighbor distance as the default bias\n","    return sum(all_kth_distances) / len(all_kth_distances)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U79sZXV9gNLp"},"outputs":[],"source":["# feature_extractor = feature_extractor.to(device)\n","\n","case_default_bias = 0\n","if bias_manual_set:\n","  case_default_bias = bias_manual_value\n","elif case_activation_by_top_k_average:\n","  case_default_bias = find_default_bias_knn(Xs.to(device), feature_extractor, top_k_for_case_activation, num_samples)\n","else:\n","  case_default_bias = find_default_bias(Xs)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1736959412654,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":300},"id":"njMPzLMbhQKj","outputId":"87f6a734-4dc6-4c95-d7f1-f7bfafccc986"},"outputs":[{"data":{"text/plain":["1.305230148628438"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["case_default_bias"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q6VKiDPGwQT3"},"outputs":[],"source":["# Initialize case_default_bias as a GLOBAL trainable parameter\n","# case_default_bias = nn.Parameter(torch.tensor(find_default_bias(Xs), dtype=torch.float32, device=device), requires_grad=True)\n"]},{"cell_type":"markdown","metadata":{"id":"2MNAEUwC30I0"},"source":["## Case Network"]},{"cell_type":"markdown","metadata":{"id":"DC6Xhx6t19y1"},"source":["### Custom Case Activation Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"74B8d3Xtz1vt"},"outputs":[],"source":["import torch\n","from functools import partial\n","\n","def scaled_sigmoid(x):\n","    \"\"\"\n","    Scaled and shifted sigmoid as a PyTorch operation.\n","\n","    Args:\n","        x: The input tensor.\n","        A: The value at which the output should be close to 1.\n","\n","    Returns:\n","        The scaled and shifted sigmoid output tensor.\n","    \"\"\"\n","    A = case_default_bias\n","    s = 8 / A  # Scaling factor\n","    b = 0 - 4      # Shift value\n","    return torch.sigmoid(s * x + b)\n","\n","\n","# Now you can use sigmoid_with_preset_A with variable x\n","x = torch.randn(10)*5  # Example input tensor\n","output = scaled_sigmoid(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7CVkE7Kmczzj"},"outputs":[],"source":["def mirrored_leaky_relu(x, negative_slope= 0.01, threshold = case_default_bias):\n","    \"\"\"\n","    Custom Leaky ReLU with mirrored behavior above a threshold.\n","\n","    Args:\n","        x: Input tensor.\n","        negative_slope: Slope for x < 0.\n","        threshold: Upper bound where the mirroring begins.\n","\n","    Returns:\n","        Transformed tensor.\n","    \"\"\"\n","    # Leaky ReLU for x < 0\n","    leaky_part = torch.where(x < 0, negative_slope * x, x)\n","\n","    # Mirroring effect for x > threshold\n","    mirror_part = torch.where(x > threshold,\n","                              threshold + negative_slope * (x - threshold),\n","                              leaky_part)\n","\n","    return mirror_part\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HehXwqisdwz8","outputId":"1e98c50f-c909-4ea9-d76b-14d6a2b8afb6"},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_247083/2926130680.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  ys = torch.tensor(ys) # Assuming ys is a NumPy array or a list\n"]}],"source":["# prompt: one hot encode ys\n","\n","import torch\n","ys = torch.tensor(ys) # Assuming ys is a NumPy array or a list\n","num_classes = len(torch.unique(ys))\n","ys_onehot = torch.nn.functional.one_hot(ys, num_classes=num_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5C-bqR4bdwz8"},"outputs":[],"source":["Xs = Xs.to(device)\n","ys_onehot = ys_onehot.to(device)\n","ys = ys.to(device)"]},{"cell_type":"markdown","metadata":{"id":"je4SsvHEbB7Z"},"source":["### Real Case Network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a6iCoXsbdwz8"},"outputs":[],"source":["cfg.batch_size = 100"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sVTM16Y4gwww"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class CaseNetsClassifier(nn.Module):\n","    def __init__(self, cases, labels, feature_extractor=None, glocal_weightor=None, sampling_cases=sampling_cases_flag, top_k=4):\n","        \"\"\"\n","        A combined class that replaces both `CaseNet` and `CaseNetsClassifier`.\n","\n","        Args:\n","            cases (torch.Tensor): Tensor containing all cases (e.g., images or sequences).\n","            labels (torch.Tensor): Tensor of one-hot encoded labels for each case.\n","            feature_extractor (nn.Module): Feature extractor (e.g., CNN for images or embedding for text).\n","            glocal_weightor (nn.Module): Global-local weightor for feature weighting.\n","            sampling_cases (bool): Whether to use sampling for case selection.\n","            top_k (int): Number of top cases to retrieve for explanation.\n","        \"\"\"\n","        super(CaseNetsClassifier, self).__init__()\n","        self.cases = cases  # Shape: [num_cases, *case_shape]\n","        self.labels = labels  # Shape: [num_cases, num_classes]\n","        self.feature_extractor = feature_extractor\n","        self.glocal_weightor = glocal_weightor\n","\n","        # Group cases by class\n","        self.class_to_cases = {}\n","        for i, label in enumerate(self.labels):\n","            class_label = torch.argmax(label).item()  # Extract class label\n","            if class_label not in self.class_to_cases:\n","                self.class_to_cases[class_label] = []\n","            self.class_to_cases[class_label].append(i)\n","\n","        self.sampling_cases = sampling_cases\n","        self.sample_num = num_samples\n","        self.top_k = top_k\n","\n","        # Parameters specific to each case\n","        self.biases = nn.Parameter(torch.full((len(cases),), case_default_bias))  # Shape: [num_cases]\n","        self.weights = nn.Parameter(torch.ones(len(cases)))  # Shape: [num_cases]\n","        self.glocal_weights = nn.Parameter(\n","            torch.softmax(torch.ones(len(cases), glocal_fw_set_num), dim=-1)\n","        )  # Shape: [num_cases, set_dim]\n","\n","        # Precompute feature dimensions if feature extractor exists\n","        self.feature_dim = None\n","        if feature_extractor is not None:\n","            with torch.no_grad():\n","                dummy_input = cases[0].unsqueeze(0).to(device)\n","                self.feature_dim = feature_extractor(dummy_input).shape[-1]\n","        else:\n","            self.feature_dim = cases.shape[-1]\n","        self.cached_features = None  # To cache features during evaluation mode\n","\n","        self.explanation_mode = False\n","    def _extract_features(self, case_indices):\n","        \"\"\"\n","        Extract features for selected cases using the feature extractor.\n","\n","        Args:\n","            case_indices (torch.Tensor): Indices of cases to process.\n","\n","        Returns:\n","            extracted_features (torch.Tensor): Features for the selected cases.\n","        \"\"\"\n","        selected_cases = self.cases[case_indices]  # Shape: [num_selected_cases, *case_shape]\n","\n","        if self.feature_extractor is not None:\n","            if self.training:\n","                # Always compute features during training\n","                extracted_features = self.feature_extractor(selected_cases)  # Shape: [num_selected_cases, feature_dim]\n","                #wipe cache because feature extractor will be updated\n","                self.cached_features = None\n","            else:\n","                # During evaluation, update cache only for processed indices\n","                if self.cached_features is None:\n","                    # Initialize cache on the first evaluation pass\n","                    self.cached_features = torch.zeros(\n","                        (len(self.cases), self.feature_dim), dtype=torch.float32, device=selected_cases.device\n","                    )\n","\n","                # Check which indices need to be computed\n","                uncached_indices = [idx.item() for idx in case_indices if self.cached_features[idx].sum() == 0]\n","                if uncached_indices:\n","                    uncached_cases = self.cases[uncached_indices]\n","                    uncached_features = self.feature_extractor(uncached_cases)  # Extract features for uncached cases\n","                    self.cached_features[uncached_indices] = uncached_features\n","\n","                # Retrieve features from the cache\n","                extracted_features = self.cached_features[case_indices]\n","        else:\n","            # No feature extraction; use raw cases as features\n","            extracted_features = selected_cases\n","\n","        return extracted_features\n","\n","\n","    def forward(self, query):\n","        \"\"\"\n","        Perform forward pass and optionally provide explanations.\n","\n","        Args:\n","            query (torch.Tensor): Query tensor of shape [batch_size, *query_shape].\n","            explanation_mode (bool): Whether to provide explanations (top-k cases).\n","\n","        Returns:\n","            final_predictions (torch.Tensor): Predicted probabilities/logits for each class.\n","            predicted_class (torch.Tensor): Predicted class indices.\n","            most_activated_cases (list, optional): List of top-k most activated cases (if explanation_mode=True).\n","            most_activated_activations (torch.Tensor, optional): Activations of the top-k most activated cases.\n","        \"\"\"\n","        batch_size = query.size(0)\n","        num_cases = len(self.cases)\n","        case_indices = torch.arange(num_cases).to(query.device)  # Default: use all case_nets\n","        # Sampling cases (optional)\n","        if self.sampling_cases:\n","          sampled_indices = []\n","          each_class_sample_num = max(1, self.sample_num // len(self.class_to_cases))\n","\n","          for class_label, case_indices in self.class_to_cases.items():\n","              if len(case_indices) >= each_class_sample_num:\n","                  # Sample directly from global indices\n","                  sampled_indices.extend(torch.tensor(case_indices)[torch.randperm(len(case_indices))[:each_class_sample_num]].tolist())\n","              else:\n","                  # If fewer cases, sample with replacement\n","                  sampled_indices.extend(\n","                      torch.tensor(case_indices)[torch.randint(0, len(case_indices), (each_class_sample_num,))].tolist()\n","                  )\n","          case_indices = torch.tensor(sampled_indices).to(query.device)\n","\n","        # Extract features\n","        query_features = self.feature_extractor(query) if self.feature_extractor is not None else query\n","        case_features = self._extract_features(case_indices)\n","\n","        # Compute distances\n","        query_expanded = query_features.unsqueeze(1).expand(-1, len(case_indices), -1)  # [batch_size, num_selected_cases, feature_dim]\n","        case_expanded = case_features.unsqueeze(0).expand(batch_size, -1, -1)  # [batch_size, num_selected_cases, feature_dim]\n","        elementwise_distance = (query_expanded - case_expanded) ** 2  # Shape: [batch_size, num_selected_cases, feature_dim]\n","\n","        # Apply global-local weighting if applicable\n","        if self.glocal_weightor is not None:\n","            glocal_weights = self.glocal_weights[case_indices]  # [num_selected_cases, set_dim]\n","            elementwise_distance = self.glocal_weightor(elementwise_distance, glocal_weights)  # Weighted distances\n","\n","        distances = torch.sqrt(torch.relu(torch.sum(elementwise_distance, dim=-1)))  # [batch_size, num_selected_cases]\n","        # Convert distances to activations\n","        activations = self.biases[case_indices] - torch.sqrt(distances)  # [batch_size, num_selected_cases]\n","        activations = scaled_sigmoid(activations) * self.weights[case_indices]  # Scale by case-specific weights\n","\n","        # Multiply activations by labels\n","        selected_labels = self.labels[case_indices]  # [num_selected_cases, num_classes]\n","        weighted_activations = activations.unsqueeze(2) * selected_labels.unsqueeze(0)  # [batch_size, num_selected_cases, num_classes]\n","\n","        # Sum over cases to produce predictions\n","        final_predictions = weighted_activations.sum(dim=1)  # [batch_size, num_classes]\n","        predicted_class = final_predictions.argmax(dim=1)  # [batch_size]\n","\n","        # Explanation (Top-k cases)\n","        most_activated_cases, most_activated_case_labels, most_activated_activations = None, None, None\n","        if self.explanation_mode:\n","            top_k_activations, top_k_indices = torch.topk(activations, self.top_k, dim=1)  # [batch_size, top_k]\n","            most_activated_cases = [self.cases[case_indices[idx]] for idx in top_k_indices]\n","            most_activated_case_labels = [self.labels[case_indices[idx]] for idx in top_k_indices]\n","            most_activated_activations = top_k_activations\n","\n","        return final_predictions, predicted_class, most_activated_cases, most_activated_case_labels, most_activated_activations\n"]},{"cell_type":"markdown","metadata":{"id":"LpR7hv0_HIsD"},"source":["Debugging code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Z16yaz5hVfG"},"outputs":[],"source":["# CNs = CaseNetsClassifier([exampleCN0])\n","# CNs = CaseNetsClassifier([exampleCN0, exampleCN1])\n","# CNs = CaseNetsClassifier([exampleCN0, exampleCN1], top_case_enabled=True)\n","# CNs.eval()\n","# example_queries = Xs[0:2]\n","# final_predictions, predicted_class = CNs(example_queries)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S_hxHspW_nF3"},"outputs":[],"source":["# final_predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f3GEIoYi_pHn"},"outputs":[],"source":["# predicted_class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HBBhj1VvDDlo"},"outputs":[],"source":["# for name, param in CNs.named_parameters():\n","#     print(f\"Parameter name: {name}\")\n","#     print(f\"Parameter data: {param.data}\")\n","#     print(f\"Requires gradient: {param.requires_grad}\")\n","#     print(\"------\")\n"]},{"cell_type":"markdown","metadata":{"id":"mrqj1y0Wdwz9"},"source":["# MANUAL RUN"]},{"cell_type":"markdown","metadata":{"id":"jmbLMmPmvupr"},"source":["## Training Case Network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d2xbWXYfdwz9"},"outputs":[],"source":["# feature_extractor = iniitialize_feature_extractor()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VcnaYPMtdwz9","outputId":"03d2dc98-7774-498c-b635-7f7f0b208947"},"outputs":[{"data":{"text/plain":["namespace(batch=100,\n","          PATH='./checkpoints/classifier_sst1.h5',\n","          patience=7,\n","          training_epochs=100,\n","          batch_size=100)"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["cfg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2f6g3G5Rdwz9"},"outputs":[],"source":["cfg.batch_size = 100"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dVc9RV0Pdwz-","outputId":"a353544b-0e01-4c13-aa9a-25a364aeddfb"},"outputs":[{"data":{"text/plain":["namespace(batch=100,\n","          PATH='./checkpoints/classifier_sst1.h5',\n","          patience=7,\n","          training_epochs=100,\n","          batch_size=100)"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["cfg.PATH = os.path.join(folder_name, f'checkpoints/classifier_{dataset_name}.h5')\n","cfg.patience = 7\n","cfg"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1736959413019,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":300},"id":"GS1vkeXb-W49","outputId":"e3bd747e-c64f-4183-a35c-471a454363a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n"]}],"source":["for param in feature_extractor.parameters():\n","    print(param.requires_grad)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ELS7DMrCCvVK"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from sklearn.model_selection import KFold, train_test_split\n","from sklearn.metrics import accuracy_score\n","import os\n","import numpy as np\n","\n","def train_model(X_train, y_train, X_val, y_val, cfg, glocal_fw_set_num=glocal_fw_set_num):\n","    global debug_print\n","    \"\"\"\n","    Train the NN-kNN model using the provided train/validation split.\n","\n","    Args:\n","        X_train: Training feature tensor.\n","        y_train: Training labels.\n","        X_val: Validation feature tensor.\n","        y_val: Validation labels.\n","        cfg: Configuration object with training hyperparameters.\n","        glocal_fw_set_num: Number of sets for the global feature weightor.\n","\n","    Returns:\n","        best_accuracy: The best accuracy achieved during training.\n","        glocal_weightor: The trained global feature weightor.\n","    \"\"\"\n","    # Move data to the appropriate device\n","    X_train = X_train.to(device)\n","    y_train = y_train.to(device)\n","\n","    # DataLoader for batching\n","    train_loader = torch.utils.data.DataLoader(\n","        torch.utils.data.TensorDataset(X_train, y_train),\n","        batch_size=cfg.batch_size,\n","        shuffle=True\n","    )\n","    val_loader = torch.utils.data.DataLoader(\n","        torch.utils.data.TensorDataset(X_val, y_val),\n","        batch_size=cfg.batch_size,\n","        shuffle=False\n","    )\n","\n","    # Initialize the global feature weightor\n","    glocal_weightor = GlocalFeatureWeight(feature_dim, glocal_fw_set_num)\n","    glocal_weightor.to(device)\n","\n","    print(glocal_weightor.state_dict())\n","    # Initialize CaseNet instances for the training set\n","    # case_nets = [CaseNet(X_train[i], ys_onehot[i], feature_weightor=glocal_weightor) for i in range(len(X_train))]\n","    # model = CaseNetsClassifier(case_nets, glocal_weightor, feature_extractor)\n","\n","    model = CaseNetsClassifier(X_train, ys_onehot, feature_extractor, glocal_weightor)\n","    model.to(device)\n","    # Separate parameters for different learning rates\n","    feature_extractor_params = list()\n","    if(feature_extractor is not None):\n","        feature_extractor_params = list(feature_extractor.parameters())\n","    glocal_weightor_params = list(model.glocal_weightor.parameters())\n","    #print out number of parameters here\n","\n","    shared_params_ids = {id(param) for param in feature_extractor_params + glocal_weightor_params}\n","    # case_net_params = [param for case_net in model.case_nets for param in case_net.parameters() if id(param) not in shared_params_ids]\n","    case_net_params = [param for param in model.parameters() if id(param) not in shared_params_ids]\n","    print(\"Number of feature extractor parameters:\", len(feature_extractor_params))\n","    for param in feature_extractor_params:\n","        print(param.shape)\n","    print(\"Number of glocal weightor parameters:\", len(glocal_weightor_params))\n","    for param in glocal_weightor_params:\n","        print(param.shape)\n","    print(\"Number of case_net_params:\", len(case_net_params))\n","    for param in case_net_params:\n","        print(param.shape)\n","    print(\"*****************\")\n","    # print(model.state_dict())\n","\n","\n","    optimizer = torch.optim.Adam([\n","        {'params': feature_extractor_params, 'lr': 1e-4},\n","        {'params': glocal_weightor_params, 'lr': 1e-3}, #I tried 1e-3 here, this is better.\n","        {'params': case_net_params, 'lr': 1e-4}\n","    ], weight_decay=1e-5)\n","\n","    patience_counter = 0\n","    best_accuracy = 0\n","    best_val_loss = float('inf')\n","    best_found = False\n","    best_epoch = 0\n","    print(f\"Training started for {cfg.training_epochs} epochs with batch size {cfg.batch_size}\")\n","\n","    # for epoch in range(cfg.training_epochs):\n","    for epoch in range(100):\n","        if best_found:\n","            break\n","        running_loss = 0.0\n","        total_batches = len(train_loader)\n","\n","        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n","            model.train()\n","            # break\n","            optimizer.zero_grad()\n","            # print(X_batch.shape)\n","            final_predictions, _, _, _,_= model(X_batch)\n","            # print(\"Checking final pred\")\n","            # print(final_predictions)\n","            # print(\"Checking y_batch\")\n","            # print(y_batch)\n","            loss = criterion(final_predictions, y_batch)\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","            # if batch_idx % 10 == 0 or batch_idx == total_batches - 1:\n","            #     # avg_loss = running_loss / (batch_idx + 1)\n","            #     # print(f\"[Epoch {epoch+1}/{cfg.training_epochs}] Batch {batch_idx+1}/{total_batches} - Loss: {avg_loss:.4f}\")\n","            #     print(f\"[Epoch {epoch+1}/{cfg.training_epochs}] Batch {batch_idx+1}/{total_batches} - Loss: {loss.item():.4f}\")\n","            #     # Evaluate on the validation set\n","        print(f\"[Epoch {epoch+1}/{cfg.training_epochs}] - Loss: {loss.item():.4f}\")\n","\n","        model.eval()\n","        with torch.no_grad():\n","            final_predictions = torch.empty((0, num_classes))\n","            predicted_classes = torch.empty((0,))\n","            for batch_idx, (X_batch, _) in enumerate(val_loader):\n","                X_batch = X_batch.to(device)\n","\n","                final_prediction, predicted_class,_,_, _ = model(X_batch)\n","\n","                final_predictions = torch.cat((final_predictions, final_prediction.cpu()), dim=0)\n","                predicted_classes = torch.cat((predicted_classes, predicted_class.cpu()), dim=0)\n","\n","            # print(final_predictions.shape, y_val.shape)\n","            accuracy = accuracy_score(y_val, predicted_classes.cpu().numpy())\n","            val_loss = criterion(final_predictions, y_val).item()\n","\n","        print(f\"Epoch {epoch+1} - Validation Accuracy: {accuracy:.4f}\")\n","        print(f\"Epoch {epoch+1} - Validation Loss: {val_loss:.4f}\")\n","\n","        # if best_accuracy < accuracy:\n","        #     best_accuracy = accuracy\n","\n","        # Early stopping and model saving\n","\n","        if epoch == 0 or best_accuracy < accuracy:\n","            #Note: shouldn't use val_loss here because it's the validation set. we are training on training loss, not validation loss.\n","            #  or (val_loss < best_val_loss and  best_accuracy == accuracy) : #or val_loss < best_val_loss or best_accuracy < accuracy:\n","            best_val_loss = val_loss\n","            best_accuracy = accuracy_score(y_val, predicted_classes.cpu().numpy())\n","            torch.save(model.state_dict(), cfg.PATH)\n","            print(f\"New best loss {val_loss:.4f} - Model saved.\")\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","            print(f\"so far, best loss: {best_val_loss:.4f}\")\n","            print(f\"so far, best acc: {best_accuracy:.4f}\")\n","        if patience_counter > cfg.patience:\n","            print(\"Patience exceeded. Loading best model.\")\n","            model.load_state_dict(torch.load(cfg.PATH))\n","            best_found = True\n","            break\n","\n","    print(\"Training completed. Best Acc: \", best_accuracy)\n","    # print(\"Final global feature weights:\", glocal_weightor.feature_weights)\n","    return best_accuracy, glocal_weightor, model\n","\n","\n","def cross_validate(Xs, ys, cfg, k_folds=10):\n","    \"\"\"\n","    Perform k-fold cross-validation using the train_model function.\n","\n","    Args:\n","        Xs: Feature tensor.\n","        ys: Labels.\n","        cfg: Configuration object.\n","        k_folds: Number of cross-validation folds.\n","\n","    Returns:\n","        best_accuracies: List of best accuracies for each fold.\n","    \"\"\"\n","    k_fold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n","    best_accuracies = []\n","    last_model = None\n","    for train_index, test_index in k_fold.split(Xs):\n","        X_train, X_test = Xs[train_index], Xs[test_index]\n","        y_train, y_test = ys[train_index], ys[test_index]\n","\n","        best_accuracy, _, last_model = train_model(X_train, y_train, X_test, y_test, cfg)\n","        best_accuracies.append(best_accuracy)\n","        # break\n","\n","    print(\"Cross-validation results:\", best_accuracies)\n","    print(f\"Average accuracy: {np.mean(best_accuracies):.3f}\")\n","    print(f\"Standard deviation: {np.std(best_accuracies):.3f}\")\n","    print(f\"{np.mean(best_accuracies):.3f} ({np.std(best_accuracies):.3f})\")\n","    return best_accuracies, last_model\n","\n","\n","def train_with_given_split(X_train, y_train, X_test, y_test, cfg):\n","    \"\"\"\n","    Train NN-kNN directly with a provided train/test split.\n","\n","    Args:\n","        X_train: Training feature tensor.\n","        y_train: Training labels.\n","        X_test: Test feature tensor.\n","        y_test: Test labels.\n","        cfg: Configuration object.\n","    \"\"\"\n","    best_accuracy, glocal_weightor, model = train_model(X_train, y_train, X_test, y_test, cfg)\n","    print(f\"Accuracy on provided split: {best_accuracy:.3f}\")\n","    #print(\"Final global feature weights:\", glocal_weightor.feature_weights)\n","    return best_accuracy, glocal_weightor, model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fFUYUU6NJos7"},"outputs":[],"source":["\n","# # Option 1: Cross-validation\n","# feature_extractor = iniitialize_feature_extractor()\n","# best_accuracies, last_model = cross_validate(Xs, ys, cfg)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_yfb-Au6dwz-"},"outputs":[],"source":["import gc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mMD0Aqpydwz-","outputId":"ed363b67-7c37-4754-bea1-ca073be8a213"},"outputs":[{"name":"stdout","output_type":"stream","text":["OrderedDict([('feature_weights', tensor([[0.2676, 0.0056, 0.8214,  ..., 0.3745, 0.0702, 0.0893],\n","        [0.0098, 0.5012, 0.5941,  ..., 0.4263, 0.6173, 0.6845],\n","        [0.4249, 0.6357, 0.7227,  ..., 0.7871, 0.7515, 0.6103],\n","        [0.8360, 0.3996, 0.3982,  ..., 0.7629, 0.5364, 0.9472]],\n","       device='cuda:1'))])\n","Number of feature extractor parameters: 9\n","torch.Size([8740, 128])\n","torch.Size([512, 128])\n","torch.Size([512, 128])\n","torch.Size([512])\n","torch.Size([512])\n","torch.Size([512, 128])\n","torch.Size([512, 128])\n","torch.Size([512])\n","torch.Size([512])\n","Number of glocal weightor parameters: 1\n","torch.Size([4, 256])\n","Number of case_net_params: 3\n","torch.Size([8544])\n","torch.Size([8544])\n","torch.Size([8544, 4])\n","*****************\n","Training started for 100 epochs with batch size 100\n","[Epoch 1/100] - Loss: 1.5358\n","Epoch 1 - Validation Accuracy: 0.2579\n","Epoch 1 - Validation Loss: 1.6008\n","New best loss 1.6008 - Model saved.\n","[Epoch 2/100] - Loss: 1.5479\n","Epoch 2 - Validation Accuracy: 0.2873\n","Epoch 2 - Validation Loss: 1.5808\n","New best loss 1.5808 - Model saved.\n","[Epoch 3/100] - Loss: 1.5045\n","Epoch 3 - Validation Accuracy: 0.2778\n","Epoch 3 - Validation Loss: 1.5702\n","so far, best loss: 1.5808\n","so far, best acc: 0.2873\n","[Epoch 4/100] - Loss: 1.4999\n","Epoch 4 - Validation Accuracy: 0.2692\n","Epoch 4 - Validation Loss: 1.5721\n","so far, best loss: 1.5808\n","so far, best acc: 0.2873\n","[Epoch 5/100] - Loss: 1.5031\n","Epoch 5 - Validation Accuracy: 0.2819\n","Epoch 5 - Validation Loss: 1.5725\n","so far, best loss: 1.5808\n","so far, best acc: 0.2873\n","[Epoch 6/100] - Loss: 1.5824\n","Epoch 6 - Validation Accuracy: 0.2891\n","Epoch 6 - Validation Loss: 1.5669\n","New best loss 1.5669 - Model saved.\n","[Epoch 7/100] - Loss: 1.5038\n","Epoch 7 - Validation Accuracy: 0.2706\n","Epoch 7 - Validation Loss: 1.5700\n","so far, best loss: 1.5669\n","so far, best acc: 0.2891\n","[Epoch 8/100] - Loss: 1.5807\n","Epoch 8 - Validation Accuracy: 0.2760\n","Epoch 8 - Validation Loss: 1.5692\n","so far, best loss: 1.5669\n","so far, best acc: 0.2891\n","[Epoch 9/100] - Loss: 1.3705\n","Epoch 9 - Validation Accuracy: 0.3077\n","Epoch 9 - Validation Loss: 1.5563\n","New best loss 1.5563 - Model saved.\n","[Epoch 10/100] - Loss: 1.5242\n","Epoch 10 - Validation Accuracy: 0.3063\n","Epoch 10 - Validation Loss: 1.5566\n","so far, best loss: 1.5563\n","so far, best acc: 0.3077\n","[Epoch 11/100] - Loss: 1.4763\n","Epoch 11 - Validation Accuracy: 0.2873\n","Epoch 11 - Validation Loss: 1.5560\n","so far, best loss: 1.5563\n","so far, best acc: 0.3077\n","[Epoch 12/100] - Loss: 1.4391\n","Epoch 12 - Validation Accuracy: 0.3176\n","Epoch 12 - Validation Loss: 1.5345\n","New best loss 1.5345 - Model saved.\n","[Epoch 13/100] - Loss: 1.3736\n","Epoch 13 - Validation Accuracy: 0.3154\n","Epoch 13 - Validation Loss: 1.5419\n","so far, best loss: 1.5345\n","so far, best acc: 0.3176\n","[Epoch 14/100] - Loss: 1.4723\n","Epoch 14 - Validation Accuracy: 0.3321\n","Epoch 14 - Validation Loss: 1.5347\n","New best loss 1.5347 - Model saved.\n","[Epoch 15/100] - Loss: 1.4445\n","Epoch 15 - Validation Accuracy: 0.3376\n","Epoch 15 - Validation Loss: 1.5324\n","New best loss 1.5324 - Model saved.\n","[Epoch 16/100] - Loss: 1.3593\n","Epoch 16 - Validation Accuracy: 0.3407\n","Epoch 16 - Validation Loss: 1.5234\n","New best loss 1.5234 - Model saved.\n","[Epoch 17/100] - Loss: 1.3126\n","Epoch 17 - Validation Accuracy: 0.3403\n","Epoch 17 - Validation Loss: 1.5272\n","so far, best loss: 1.5234\n","so far, best acc: 0.3407\n","[Epoch 18/100] - Loss: 1.3386\n","Epoch 18 - Validation Accuracy: 0.3448\n","Epoch 18 - Validation Loss: 1.5181\n","New best loss 1.5181 - Model saved.\n","[Epoch 19/100] - Loss: 1.4386\n","Epoch 19 - Validation Accuracy: 0.3412\n","Epoch 19 - Validation Loss: 1.5340\n","so far, best loss: 1.5181\n","so far, best acc: 0.3448\n","[Epoch 20/100] - Loss: 1.4088\n","Epoch 20 - Validation Accuracy: 0.3398\n","Epoch 20 - Validation Loss: 1.5265\n","so far, best loss: 1.5181\n","so far, best acc: 0.3448\n","[Epoch 21/100] - Loss: 1.3620\n","Epoch 21 - Validation Accuracy: 0.3489\n","Epoch 21 - Validation Loss: 1.5216\n","New best loss 1.5216 - Model saved.\n","[Epoch 22/100] - Loss: 1.2830\n","Epoch 22 - Validation Accuracy: 0.3321\n","Epoch 22 - Validation Loss: 1.5331\n","so far, best loss: 1.5216\n","so far, best acc: 0.3489\n","[Epoch 23/100] - Loss: 1.1889\n","Epoch 23 - Validation Accuracy: 0.3425\n","Epoch 23 - Validation Loss: 1.5530\n","so far, best loss: 1.5216\n","so far, best acc: 0.3489\n","[Epoch 24/100] - Loss: 1.3534\n","Epoch 24 - Validation Accuracy: 0.3353\n","Epoch 24 - Validation Loss: 1.5287\n","so far, best loss: 1.5216\n","so far, best acc: 0.3489\n","[Epoch 25/100] - Loss: 1.2064\n","Epoch 25 - Validation Accuracy: 0.3502\n","Epoch 25 - Validation Loss: 1.5354\n","New best loss 1.5354 - Model saved.\n","[Epoch 26/100] - Loss: 1.1763\n","Epoch 26 - Validation Accuracy: 0.3534\n","Epoch 26 - Validation Loss: 1.5386\n","New best loss 1.5386 - Model saved.\n","[Epoch 27/100] - Loss: 1.3005\n","Epoch 27 - Validation Accuracy: 0.3480\n","Epoch 27 - Validation Loss: 1.5315\n","so far, best loss: 1.5386\n","so far, best acc: 0.3534\n","[Epoch 28/100] - Loss: 1.4266\n","Epoch 28 - Validation Accuracy: 0.3606\n","Epoch 28 - Validation Loss: 1.5741\n","New best loss 1.5741 - Model saved.\n","[Epoch 29/100] - Loss: 1.1837\n","Epoch 29 - Validation Accuracy: 0.3475\n","Epoch 29 - Validation Loss: 1.5638\n","so far, best loss: 1.5741\n","so far, best acc: 0.3606\n","[Epoch 30/100] - Loss: 1.0833\n","Epoch 30 - Validation Accuracy: 0.3480\n","Epoch 30 - Validation Loss: 1.5710\n","so far, best loss: 1.5741\n","so far, best acc: 0.3606\n","[Epoch 31/100] - Loss: 1.1649\n","Epoch 31 - Validation Accuracy: 0.3606\n","Epoch 31 - Validation Loss: 1.5640\n","so far, best loss: 1.5741\n","so far, best acc: 0.3606\n","[Epoch 32/100] - Loss: 1.2603\n","Epoch 32 - Validation Accuracy: 0.3652\n","Epoch 32 - Validation Loss: 1.5777\n","New best loss 1.5777 - Model saved.\n","[Epoch 33/100] - Loss: 1.2452\n","Epoch 33 - Validation Accuracy: 0.3421\n","Epoch 33 - Validation Loss: 1.5860\n","so far, best loss: 1.5777\n","so far, best acc: 0.3652\n","[Epoch 34/100] - Loss: 1.1136\n","Epoch 34 - Validation Accuracy: 0.3647\n","Epoch 34 - Validation Loss: 1.5755\n","so far, best loss: 1.5777\n","so far, best acc: 0.3652\n","[Epoch 35/100] - Loss: 1.1338\n","Epoch 35 - Validation Accuracy: 0.3412\n","Epoch 35 - Validation Loss: 1.6756\n","so far, best loss: 1.5777\n","so far, best acc: 0.3652\n","[Epoch 36/100] - Loss: 0.8167\n","Epoch 36 - Validation Accuracy: 0.3561\n","Epoch 36 - Validation Loss: 1.6200\n","so far, best loss: 1.5777\n","so far, best acc: 0.3652\n","[Epoch 37/100] - Loss: 1.2926\n","Epoch 37 - Validation Accuracy: 0.3484\n","Epoch 37 - Validation Loss: 1.6884\n","so far, best loss: 1.5777\n","so far, best acc: 0.3652\n","[Epoch 38/100] - Loss: 1.2105\n","Epoch 38 - Validation Accuracy: 0.3425\n","Epoch 38 - Validation Loss: 1.6546\n","so far, best loss: 1.5777\n","so far, best acc: 0.3652\n","[Epoch 39/100] - Loss: 0.8725\n","Epoch 39 - Validation Accuracy: 0.3661\n","Epoch 39 - Validation Loss: 1.6768\n","New best loss 1.6768 - Model saved.\n","[Epoch 40/100] - Loss: 1.0581\n","Epoch 40 - Validation Accuracy: 0.3588\n","Epoch 40 - Validation Loss: 1.6812\n","so far, best loss: 1.6768\n","so far, best acc: 0.3661\n","[Epoch 41/100] - Loss: 1.0483\n","Epoch 41 - Validation Accuracy: 0.3471\n","Epoch 41 - Validation Loss: 1.7141\n","so far, best loss: 1.6768\n","so far, best acc: 0.3661\n","[Epoch 42/100] - Loss: 1.0282\n","Epoch 42 - Validation Accuracy: 0.3629\n","Epoch 42 - Validation Loss: 1.7215\n","so far, best loss: 1.6768\n","so far, best acc: 0.3661\n","[Epoch 43/100] - Loss: 0.9823\n","Epoch 43 - Validation Accuracy: 0.3543\n","Epoch 43 - Validation Loss: 1.7595\n","so far, best loss: 1.6768\n","so far, best acc: 0.3661\n","[Epoch 44/100] - Loss: 0.9693\n","Epoch 44 - Validation Accuracy: 0.3552\n","Epoch 44 - Validation Loss: 1.7825\n","so far, best loss: 1.6768\n","so far, best acc: 0.3661\n","[Epoch 45/100] - Loss: 0.7692\n","Epoch 45 - Validation Accuracy: 0.3407\n","Epoch 45 - Validation Loss: 1.8284\n","so far, best loss: 1.6768\n","so far, best acc: 0.3661\n","[Epoch 46/100] - Loss: 1.2919\n","Epoch 46 - Validation Accuracy: 0.3529\n","Epoch 46 - Validation Loss: 1.7906\n","so far, best loss: 1.6768\n","so far, best acc: 0.3661\n","[Epoch 47/100] - Loss: 0.8209\n","Epoch 47 - Validation Accuracy: 0.3548\n","Epoch 47 - Validation Loss: 1.8470\n","so far, best loss: 1.6768\n","so far, best acc: 0.3661\n","Patience exceeded. Loading best model.\n","Training completed. Best Acc:  0.36606334841628957\n","Accuracy on provided split: 0.366\n","OrderedDict([('feature_weights', tensor([[0.3136, 0.6186, 0.1072,  ..., 0.3040, 0.8060, 0.8609],\n","        [0.4072, 0.8868, 0.7122,  ..., 0.8610, 0.3112, 0.3710],\n","        [0.6534, 0.5678, 0.7101,  ..., 0.3037, 0.0913, 0.2844],\n","        [0.0124, 0.4311, 0.4557,  ..., 0.7146, 0.7711, 0.0686]],\n","       device='cuda:1'))])\n","Number of feature extractor parameters: 9\n","torch.Size([8740, 128])\n","torch.Size([512, 128])\n","torch.Size([512, 128])\n","torch.Size([512])\n","torch.Size([512])\n","torch.Size([512, 128])\n","torch.Size([512, 128])\n","torch.Size([512])\n","torch.Size([512])\n","Number of glocal weightor parameters: 1\n","torch.Size([4, 256])\n","Number of case_net_params: 3\n","torch.Size([8544])\n","torch.Size([8544])\n","torch.Size([8544, 4])\n","*****************\n","Training started for 100 epochs with batch size 100\n","[Epoch 1/100] - Loss: 1.6099\n","Epoch 1 - Validation Accuracy: 0.2335\n","Epoch 1 - Validation Loss: 1.6144\n","New best loss 1.6144 - Model saved.\n","[Epoch 2/100] - Loss: 1.4747\n","Epoch 2 - Validation Accuracy: 0.2570\n","Epoch 2 - Validation Loss: 1.5933\n","New best loss 1.5933 - Model saved.\n","[Epoch 3/100] - Loss: 1.5160\n","Epoch 3 - Validation Accuracy: 0.2814\n","Epoch 3 - Validation Loss: 1.5768\n","New best loss 1.5768 - Model saved.\n","[Epoch 4/100] - Loss: 1.5022\n","Epoch 4 - Validation Accuracy: 0.3005\n","Epoch 4 - Validation Loss: 1.5618\n","New best loss 1.5618 - Model saved.\n","[Epoch 5/100] - Loss: 1.4130\n","Epoch 5 - Validation Accuracy: 0.2787\n","Epoch 5 - Validation Loss: 1.5717\n","so far, best loss: 1.5618\n","so far, best acc: 0.3005\n","[Epoch 6/100] - Loss: 1.5207\n","Epoch 6 - Validation Accuracy: 0.2683\n","Epoch 6 - Validation Loss: 1.5812\n","so far, best loss: 1.5618\n","so far, best acc: 0.3005\n","[Epoch 7/100] - Loss: 1.4590\n","Epoch 7 - Validation Accuracy: 0.2986\n","Epoch 7 - Validation Loss: 1.5534\n","so far, best loss: 1.5618\n","so far, best acc: 0.3005\n","[Epoch 8/100] - Loss: 1.4372\n","Epoch 8 - Validation Accuracy: 0.3045\n","Epoch 8 - Validation Loss: 1.5525\n","New best loss 1.5525 - Model saved.\n","[Epoch 9/100] - Loss: 1.5398\n","Epoch 9 - Validation Accuracy: 0.2923\n","Epoch 9 - Validation Loss: 1.5574\n","so far, best loss: 1.5525\n","so far, best acc: 0.3045\n","[Epoch 10/100] - Loss: 1.3262\n","Epoch 10 - Validation Accuracy: 0.3167\n","Epoch 10 - Validation Loss: 1.5369\n","New best loss 1.5369 - Model saved.\n","[Epoch 11/100] - Loss: 1.4658\n","Epoch 11 - Validation Accuracy: 0.3353\n","Epoch 11 - Validation Loss: 1.5321\n","New best loss 1.5321 - Model saved.\n","[Epoch 12/100] - Loss: 1.5997\n","Epoch 12 - Validation Accuracy: 0.3326\n","Epoch 12 - Validation Loss: 1.5216\n","so far, best loss: 1.5321\n","so far, best acc: 0.3353\n","[Epoch 13/100] - Loss: 1.3930\n","Epoch 13 - Validation Accuracy: 0.3362\n","Epoch 13 - Validation Loss: 1.5243\n","New best loss 1.5243 - Model saved.\n","[Epoch 14/100] - Loss: 1.3903\n","Epoch 14 - Validation Accuracy: 0.3389\n","Epoch 14 - Validation Loss: 1.5263\n","New best loss 1.5263 - Model saved.\n","[Epoch 15/100] - Loss: 1.2693\n","Epoch 15 - Validation Accuracy: 0.3439\n","Epoch 15 - Validation Loss: 1.5202\n","New best loss 1.5202 - Model saved.\n","[Epoch 16/100] - Loss: 1.2853\n","Epoch 16 - Validation Accuracy: 0.3348\n","Epoch 16 - Validation Loss: 1.5223\n","so far, best loss: 1.5202\n","so far, best acc: 0.3439\n","[Epoch 17/100] - Loss: 1.2434\n","Epoch 17 - Validation Accuracy: 0.3538\n","Epoch 17 - Validation Loss: 1.5034\n","New best loss 1.5034 - Model saved.\n","[Epoch 18/100] - Loss: 1.3405\n","Epoch 18 - Validation Accuracy: 0.3489\n","Epoch 18 - Validation Loss: 1.5104\n","so far, best loss: 1.5034\n","so far, best acc: 0.3538\n","[Epoch 19/100] - Loss: 1.4229\n","Epoch 19 - Validation Accuracy: 0.3502\n","Epoch 19 - Validation Loss: 1.5046\n","so far, best loss: 1.5034\n","so far, best acc: 0.3538\n","[Epoch 20/100] - Loss: 1.4224\n","Epoch 20 - Validation Accuracy: 0.3489\n","Epoch 20 - Validation Loss: 1.5253\n","so far, best loss: 1.5034\n","so far, best acc: 0.3538\n","[Epoch 21/100] - Loss: 1.2045\n","Epoch 21 - Validation Accuracy: 0.3403\n","Epoch 21 - Validation Loss: 1.5227\n","so far, best loss: 1.5034\n","so far, best acc: 0.3538\n","[Epoch 22/100] - Loss: 1.3151\n","Epoch 22 - Validation Accuracy: 0.3570\n","Epoch 22 - Validation Loss: 1.5165\n","New best loss 1.5165 - Model saved.\n","[Epoch 23/100] - Loss: 1.2557\n","Epoch 23 - Validation Accuracy: 0.3502\n","Epoch 23 - Validation Loss: 1.5232\n","so far, best loss: 1.5165\n","so far, best acc: 0.3570\n","[Epoch 24/100] - Loss: 1.1864\n","Epoch 24 - Validation Accuracy: 0.3624\n","Epoch 24 - Validation Loss: 1.5156\n","New best loss 1.5156 - Model saved.\n","[Epoch 25/100] - Loss: 1.4124\n","Epoch 25 - Validation Accuracy: 0.3674\n","Epoch 25 - Validation Loss: 1.4969\n","New best loss 1.4969 - Model saved.\n","[Epoch 26/100] - Loss: 1.3273\n","Epoch 26 - Validation Accuracy: 0.3597\n","Epoch 26 - Validation Loss: 1.5146\n","so far, best loss: 1.4969\n","so far, best acc: 0.3674\n","[Epoch 27/100] - Loss: 1.2135\n","Epoch 27 - Validation Accuracy: 0.3615\n","Epoch 27 - Validation Loss: 1.5260\n","so far, best loss: 1.4969\n","so far, best acc: 0.3674\n","[Epoch 28/100] - Loss: 1.1024\n","Epoch 28 - Validation Accuracy: 0.3602\n","Epoch 28 - Validation Loss: 1.5221\n","so far, best loss: 1.4969\n","so far, best acc: 0.3674\n","[Epoch 29/100] - Loss: 1.2098\n","Epoch 29 - Validation Accuracy: 0.3611\n","Epoch 29 - Validation Loss: 1.5405\n","so far, best loss: 1.4969\n","so far, best acc: 0.3674\n","[Epoch 30/100] - Loss: 1.0305\n","Epoch 30 - Validation Accuracy: 0.3543\n","Epoch 30 - Validation Loss: 1.5310\n","so far, best loss: 1.4969\n","so far, best acc: 0.3674\n","[Epoch 31/100] - Loss: 1.1480\n","Epoch 31 - Validation Accuracy: 0.3561\n","Epoch 31 - Validation Loss: 1.5808\n","so far, best loss: 1.4969\n","so far, best acc: 0.3674\n","[Epoch 32/100] - Loss: 1.2736\n","Epoch 32 - Validation Accuracy: 0.3575\n","Epoch 32 - Validation Loss: 1.5579\n","so far, best loss: 1.4969\n","so far, best acc: 0.3674\n","[Epoch 33/100] - Loss: 1.1433\n","Epoch 33 - Validation Accuracy: 0.3584\n","Epoch 33 - Validation Loss: 1.5503\n","so far, best loss: 1.4969\n","so far, best acc: 0.3674\n","Patience exceeded. Loading best model.\n","Training completed. Best Acc:  0.36742081447963804\n","Accuracy on provided split: 0.367\n","OrderedDict([('feature_weights', tensor([[0.7308, 0.0281, 0.3894,  ..., 0.4469, 0.9073, 0.0340],\n","        [0.5566, 0.4251, 0.1018,  ..., 0.6537, 0.9787, 0.4937],\n","        [0.7464, 0.5383, 0.7622,  ..., 0.4446, 0.9510, 0.9898],\n","        [0.6361, 0.4240, 0.3425,  ..., 0.0618, 0.5779, 0.2920]],\n","       device='cuda:1'))])\n","Number of feature extractor parameters: 9\n","torch.Size([8740, 128])\n","torch.Size([512, 128])\n","torch.Size([512, 128])\n","torch.Size([512])\n","torch.Size([512])\n","torch.Size([512, 128])\n","torch.Size([512, 128])\n","torch.Size([512])\n","torch.Size([512])\n","Number of glocal weightor parameters: 1\n","torch.Size([4, 256])\n","Number of case_net_params: 3\n","torch.Size([8544])\n","torch.Size([8544])\n","torch.Size([8544, 4])\n","*****************\n","Training started for 100 epochs with batch size 100\n","[Epoch 1/100] - Loss: 1.6289\n","Epoch 1 - Validation Accuracy: 0.2570\n","Epoch 1 - Validation Loss: 1.5974\n","New best loss 1.5974 - Model saved.\n","[Epoch 2/100] - Loss: 1.5309\n","Epoch 2 - Validation Accuracy: 0.2665\n","Epoch 2 - Validation Loss: 1.5851\n","New best loss 1.5851 - Model saved.\n","[Epoch 3/100] - Loss: 1.5616\n","Epoch 3 - Validation Accuracy: 0.2665\n","Epoch 3 - Validation Loss: 1.5816\n","so far, best loss: 1.5851\n","so far, best acc: 0.2665\n","[Epoch 4/100] - Loss: 1.4853\n","Epoch 4 - Validation Accuracy: 0.2864\n","Epoch 4 - Validation Loss: 1.5698\n","New best loss 1.5698 - Model saved.\n","[Epoch 5/100] - Loss: 1.4515\n","Epoch 5 - Validation Accuracy: 0.2964\n","Epoch 5 - Validation Loss: 1.5707\n","New best loss 1.5707 - Model saved.\n","[Epoch 6/100] - Loss: 1.5264\n","Epoch 6 - Validation Accuracy: 0.2896\n","Epoch 6 - Validation Loss: 1.5688\n","so far, best loss: 1.5707\n","so far, best acc: 0.2964\n","[Epoch 7/100] - Loss: 1.4243\n","Epoch 7 - Validation Accuracy: 0.3027\n","Epoch 7 - Validation Loss: 1.5568\n","New best loss 1.5568 - Model saved.\n","[Epoch 8/100] - Loss: 1.4252\n","Epoch 8 - Validation Accuracy: 0.2864\n","Epoch 8 - Validation Loss: 1.5544\n","so far, best loss: 1.5568\n","so far, best acc: 0.3027\n","[Epoch 9/100] - Loss: 1.6335\n","Epoch 9 - Validation Accuracy: 0.2982\n","Epoch 9 - Validation Loss: 1.5528\n","so far, best loss: 1.5568\n","so far, best acc: 0.3027\n","[Epoch 10/100] - Loss: 1.4519\n","Epoch 10 - Validation Accuracy: 0.3023\n","Epoch 10 - Validation Loss: 1.5337\n","so far, best loss: 1.5568\n","so far, best acc: 0.3027\n","[Epoch 11/100] - Loss: 1.5279\n","Epoch 11 - Validation Accuracy: 0.3072\n","Epoch 11 - Validation Loss: 1.5311\n","New best loss 1.5311 - Model saved.\n","[Epoch 12/100] - Loss: 1.5014\n","Epoch 12 - Validation Accuracy: 0.3285\n","Epoch 12 - Validation Loss: 1.5244\n","New best loss 1.5244 - Model saved.\n","[Epoch 13/100] - Loss: 1.4039\n","Epoch 13 - Validation Accuracy: 0.3285\n","Epoch 13 - Validation Loss: 1.5272\n","so far, best loss: 1.5244\n","so far, best acc: 0.3285\n","[Epoch 14/100] - Loss: 1.3052\n","Epoch 14 - Validation Accuracy: 0.3290\n","Epoch 14 - Validation Loss: 1.5256\n","New best loss 1.5256 - Model saved.\n","[Epoch 15/100] - Loss: 1.4230\n","Epoch 15 - Validation Accuracy: 0.3376\n","Epoch 15 - Validation Loss: 1.5156\n","New best loss 1.5156 - Model saved.\n","[Epoch 16/100] - Loss: 1.4974\n","Epoch 16 - Validation Accuracy: 0.3348\n","Epoch 16 - Validation Loss: 1.5184\n","so far, best loss: 1.5156\n","so far, best acc: 0.3376\n","[Epoch 17/100] - Loss: 1.4448\n","Epoch 17 - Validation Accuracy: 0.3434\n","Epoch 17 - Validation Loss: 1.5188\n","New best loss 1.5188 - Model saved.\n","[Epoch 18/100] - Loss: 1.2725\n","Epoch 18 - Validation Accuracy: 0.3348\n","Epoch 18 - Validation Loss: 1.5156\n","so far, best loss: 1.5188\n","so far, best acc: 0.3434\n","[Epoch 19/100] - Loss: 1.3503\n","Epoch 19 - Validation Accuracy: 0.3534\n","Epoch 19 - Validation Loss: 1.5022\n","New best loss 1.5022 - Model saved.\n","[Epoch 20/100] - Loss: 1.2486\n","Epoch 20 - Validation Accuracy: 0.3498\n","Epoch 20 - Validation Loss: 1.5116\n","so far, best loss: 1.5022\n","so far, best acc: 0.3534\n","[Epoch 21/100] - Loss: 1.1432\n","Epoch 21 - Validation Accuracy: 0.3584\n","Epoch 21 - Validation Loss: 1.5116\n","New best loss 1.5116 - Model saved.\n","[Epoch 22/100] - Loss: 1.1749\n","Epoch 22 - Validation Accuracy: 0.3606\n","Epoch 22 - Validation Loss: 1.5020\n","New best loss 1.5020 - Model saved.\n","[Epoch 23/100] - Loss: 1.2090\n","Epoch 23 - Validation Accuracy: 0.3462\n","Epoch 23 - Validation Loss: 1.5097\n","so far, best loss: 1.5020\n","so far, best acc: 0.3606\n","[Epoch 24/100] - Loss: 1.2068\n","Epoch 24 - Validation Accuracy: 0.3566\n","Epoch 24 - Validation Loss: 1.5150\n","so far, best loss: 1.5020\n","so far, best acc: 0.3606\n","[Epoch 25/100] - Loss: 1.2770\n","Epoch 25 - Validation Accuracy: 0.3561\n","Epoch 25 - Validation Loss: 1.5147\n","so far, best loss: 1.5020\n","so far, best acc: 0.3606\n","[Epoch 26/100] - Loss: 1.1245\n","Epoch 26 - Validation Accuracy: 0.3633\n","Epoch 26 - Validation Loss: 1.5320\n","New best loss 1.5320 - Model saved.\n","[Epoch 27/100] - Loss: 1.1083\n","Epoch 27 - Validation Accuracy: 0.3615\n","Epoch 27 - Validation Loss: 1.5263\n","so far, best loss: 1.5320\n","so far, best acc: 0.3633\n","[Epoch 28/100] - Loss: 1.2049\n","Epoch 28 - Validation Accuracy: 0.3561\n","Epoch 28 - Validation Loss: 1.5232\n","so far, best loss: 1.5320\n","so far, best acc: 0.3633\n","[Epoch 29/100] - Loss: 1.2681\n","Epoch 29 - Validation Accuracy: 0.3602\n","Epoch 29 - Validation Loss: 1.5387\n","so far, best loss: 1.5320\n","so far, best acc: 0.3633\n","[Epoch 30/100] - Loss: 1.1131\n","Epoch 30 - Validation Accuracy: 0.3652\n","Epoch 30 - Validation Loss: 1.5354\n","New best loss 1.5354 - Model saved.\n","[Epoch 31/100] - Loss: 1.2526\n","Epoch 31 - Validation Accuracy: 0.3529\n","Epoch 31 - Validation Loss: 1.5594\n","so far, best loss: 1.5354\n","so far, best acc: 0.3652\n","[Epoch 32/100] - Loss: 1.0177\n","Epoch 32 - Validation Accuracy: 0.3606\n","Epoch 32 - Validation Loss: 1.5642\n","so far, best loss: 1.5354\n","so far, best acc: 0.3652\n","[Epoch 33/100] - Loss: 0.9646\n","Epoch 33 - Validation Accuracy: 0.3670\n","Epoch 33 - Validation Loss: 1.5756\n","New best loss 1.5756 - Model saved.\n","[Epoch 34/100] - Loss: 1.1765\n","Epoch 34 - Validation Accuracy: 0.3615\n","Epoch 34 - Validation Loss: 1.5892\n","so far, best loss: 1.5756\n","so far, best acc: 0.3670\n","[Epoch 35/100] - Loss: 1.1113\n","Epoch 35 - Validation Accuracy: 0.3629\n","Epoch 35 - Validation Loss: 1.6099\n","so far, best loss: 1.5756\n","so far, best acc: 0.3670\n","[Epoch 36/100] - Loss: 1.1333\n","Epoch 36 - Validation Accuracy: 0.3543\n","Epoch 36 - Validation Loss: 1.5998\n","so far, best loss: 1.5756\n","so far, best acc: 0.3670\n","[Epoch 37/100] - Loss: 1.1652\n","Epoch 37 - Validation Accuracy: 0.3611\n","Epoch 37 - Validation Loss: 1.5943\n","so far, best loss: 1.5756\n","so far, best acc: 0.3670\n","[Epoch 38/100] - Loss: 1.1182\n","Epoch 38 - Validation Accuracy: 0.3566\n","Epoch 38 - Validation Loss: 1.6381\n","so far, best loss: 1.5756\n","so far, best acc: 0.3670\n","[Epoch 39/100] - Loss: 1.2695\n","Epoch 39 - Validation Accuracy: 0.3529\n","Epoch 39 - Validation Loss: 1.6545\n","so far, best loss: 1.5756\n","so far, best acc: 0.3670\n","[Epoch 40/100] - Loss: 0.9098\n","Epoch 40 - Validation Accuracy: 0.3597\n","Epoch 40 - Validation Loss: 1.6421\n","so far, best loss: 1.5756\n","so far, best acc: 0.3670\n","[Epoch 41/100] - Loss: 0.9670\n","Epoch 41 - Validation Accuracy: 0.3534\n","Epoch 41 - Validation Loss: 1.6633\n","so far, best loss: 1.5756\n","so far, best acc: 0.3670\n","Patience exceeded. Loading best model.\n","Training completed. Best Acc:  0.3669683257918552\n","Accuracy on provided split: 0.367\n","OrderedDict([('feature_weights', tensor([[0.5047, 0.6510, 0.7801,  ..., 0.5057, 0.3008, 0.3928],\n","        [0.6766, 0.0188, 0.0081,  ..., 0.7965, 0.7457, 0.9558],\n","        [0.3132, 0.5356, 0.0751,  ..., 0.5797, 0.0949, 0.3497],\n","        [0.1957, 0.9482, 0.3107,  ..., 0.5513, 0.8132, 0.2563]],\n","       device='cuda:1'))])\n","Number of feature extractor parameters: 9\n","torch.Size([8740, 128])\n","torch.Size([512, 128])\n","torch.Size([512, 128])\n","torch.Size([512])\n","torch.Size([512])\n","torch.Size([512, 128])\n","torch.Size([512, 128])\n","torch.Size([512])\n","torch.Size([512])\n","Number of glocal weightor parameters: 1\n","torch.Size([4, 256])\n","Number of case_net_params: 3\n","torch.Size([8544])\n","torch.Size([8544])\n","torch.Size([8544, 4])\n","*****************\n","Training started for 100 epochs with batch size 100\n","[Epoch 1/100] - Loss: 1.5854\n","Epoch 1 - Validation Accuracy: 0.2344\n","Epoch 1 - Validation Loss: 1.6160\n","New best loss 1.6160 - Model saved.\n","[Epoch 2/100] - Loss: 1.4714\n","Epoch 2 - Validation Accuracy: 0.2710\n","Epoch 2 - Validation Loss: 1.5826\n","New best loss 1.5826 - Model saved.\n","[Epoch 3/100] - Loss: 1.5021\n","Epoch 3 - Validation Accuracy: 0.2765\n","Epoch 3 - Validation Loss: 1.5760\n","New best loss 1.5760 - Model saved.\n","[Epoch 4/100] - Loss: 1.5527\n","Epoch 4 - Validation Accuracy: 0.2774\n","Epoch 4 - Validation Loss: 1.5679\n","New best loss 1.5679 - Model saved.\n","[Epoch 5/100] - Loss: 1.5031\n","Epoch 5 - Validation Accuracy: 0.2751\n","Epoch 5 - Validation Loss: 1.5707\n","so far, best loss: 1.5679\n","so far, best acc: 0.2774\n","[Epoch 6/100] - Loss: 1.4444\n","Epoch 6 - Validation Accuracy: 0.2647\n","Epoch 6 - Validation Loss: 1.5744\n","so far, best loss: 1.5679\n","so far, best acc: 0.2774\n","[Epoch 7/100] - Loss: 1.4786\n","Epoch 7 - Validation Accuracy: 0.2991\n","Epoch 7 - Validation Loss: 1.5686\n","New best loss 1.5686 - Model saved.\n","[Epoch 8/100] - Loss: 1.5476\n","Epoch 8 - Validation Accuracy: 0.2873\n","Epoch 8 - Validation Loss: 1.5690\n","so far, best loss: 1.5686\n","so far, best acc: 0.2991\n","[Epoch 9/100] - Loss: 1.4928\n","Epoch 9 - Validation Accuracy: 0.2873\n","Epoch 9 - Validation Loss: 1.5751\n","so far, best loss: 1.5686\n","so far, best acc: 0.2991\n","[Epoch 10/100] - Loss: 1.4804\n","Epoch 10 - Validation Accuracy: 0.2937\n","Epoch 10 - Validation Loss: 1.5668\n","so far, best loss: 1.5686\n","so far, best acc: 0.2991\n","[Epoch 11/100] - Loss: 1.4460\n","Epoch 11 - Validation Accuracy: 0.3090\n","Epoch 11 - Validation Loss: 1.5477\n","New best loss 1.5477 - Model saved.\n","[Epoch 12/100] - Loss: 1.4716\n","Epoch 12 - Validation Accuracy: 0.3294\n","Epoch 12 - Validation Loss: 1.5413\n","New best loss 1.5413 - Model saved.\n","[Epoch 13/100] - Loss: 1.4861\n","Epoch 13 - Validation Accuracy: 0.3163\n","Epoch 13 - Validation Loss: 1.5494\n","so far, best loss: 1.5413\n","so far, best acc: 0.3294\n","[Epoch 14/100] - Loss: 1.4235\n","Epoch 14 - Validation Accuracy: 0.3208\n","Epoch 14 - Validation Loss: 1.5383\n","so far, best loss: 1.5413\n","so far, best acc: 0.3294\n","[Epoch 15/100] - Loss: 1.3161\n","Epoch 15 - Validation Accuracy: 0.3367\n","Epoch 15 - Validation Loss: 1.5329\n","New best loss 1.5329 - Model saved.\n","[Epoch 16/100] - Loss: 1.4619\n","Epoch 16 - Validation Accuracy: 0.3235\n","Epoch 16 - Validation Loss: 1.5404\n","so far, best loss: 1.5329\n","so far, best acc: 0.3367\n","[Epoch 17/100] - Loss: 1.3413\n","Epoch 17 - Validation Accuracy: 0.3385\n","Epoch 17 - Validation Loss: 1.5313\n","New best loss 1.5313 - Model saved.\n","[Epoch 18/100] - Loss: 1.4579\n","Epoch 18 - Validation Accuracy: 0.3439\n","Epoch 18 - Validation Loss: 1.5338\n","New best loss 1.5338 - Model saved.\n","[Epoch 19/100] - Loss: 1.1340\n","Epoch 19 - Validation Accuracy: 0.3362\n","Epoch 19 - Validation Loss: 1.5375\n","so far, best loss: 1.5338\n","so far, best acc: 0.3439\n","[Epoch 20/100] - Loss: 1.3500\n","Epoch 20 - Validation Accuracy: 0.3434\n","Epoch 20 - Validation Loss: 1.5245\n","so far, best loss: 1.5338\n","so far, best acc: 0.3439\n","[Epoch 21/100] - Loss: 1.2794\n","Epoch 21 - Validation Accuracy: 0.3502\n","Epoch 21 - Validation Loss: 1.5306\n","New best loss 1.5306 - Model saved.\n","[Epoch 22/100] - Loss: 1.3586\n","Epoch 22 - Validation Accuracy: 0.3611\n","Epoch 22 - Validation Loss: 1.5186\n","New best loss 1.5186 - Model saved.\n","[Epoch 23/100] - Loss: 1.5496\n","Epoch 23 - Validation Accuracy: 0.3588\n","Epoch 23 - Validation Loss: 1.5141\n","so far, best loss: 1.5186\n","so far, best acc: 0.3611\n","[Epoch 24/100] - Loss: 1.3131\n","Epoch 24 - Validation Accuracy: 0.3511\n","Epoch 24 - Validation Loss: 1.5207\n","so far, best loss: 1.5186\n","so far, best acc: 0.3611\n","[Epoch 25/100] - Loss: 1.3945\n","Epoch 25 - Validation Accuracy: 0.3629\n","Epoch 25 - Validation Loss: 1.5355\n","New best loss 1.5355 - Model saved.\n","[Epoch 26/100] - Loss: 1.2950\n","Epoch 26 - Validation Accuracy: 0.3624\n","Epoch 26 - Validation Loss: 1.5407\n","so far, best loss: 1.5355\n","so far, best acc: 0.3629\n","[Epoch 27/100] - Loss: 1.3748\n","Epoch 27 - Validation Accuracy: 0.3588\n","Epoch 27 - Validation Loss: 1.5252\n","so far, best loss: 1.5355\n","so far, best acc: 0.3629\n","[Epoch 28/100] - Loss: 1.2578\n","Epoch 28 - Validation Accuracy: 0.3525\n","Epoch 28 - Validation Loss: 1.5430\n","so far, best loss: 1.5355\n","so far, best acc: 0.3629\n","[Epoch 29/100] - Loss: 1.0771\n","Epoch 29 - Validation Accuracy: 0.3652\n","Epoch 29 - Validation Loss: 1.5317\n","New best loss 1.5317 - Model saved.\n","[Epoch 30/100] - Loss: 0.9270\n","Epoch 30 - Validation Accuracy: 0.3584\n","Epoch 30 - Validation Loss: 1.5508\n","so far, best loss: 1.5317\n","so far, best acc: 0.3652\n","[Epoch 31/100] - Loss: 1.0614\n","Epoch 31 - Validation Accuracy: 0.3665\n","Epoch 31 - Validation Loss: 1.5441\n","New best loss 1.5441 - Model saved.\n","[Epoch 32/100] - Loss: 1.0695\n","Epoch 32 - Validation Accuracy: 0.3670\n","Epoch 32 - Validation Loss: 1.5581\n","New best loss 1.5581 - Model saved.\n","[Epoch 33/100] - Loss: 1.0740\n","Epoch 33 - Validation Accuracy: 0.3638\n","Epoch 33 - Validation Loss: 1.5605\n","so far, best loss: 1.5581\n","so far, best acc: 0.3670\n","[Epoch 34/100] - Loss: 1.3164\n","Epoch 34 - Validation Accuracy: 0.3529\n","Epoch 34 - Validation Loss: 1.6065\n","so far, best loss: 1.5581\n","so far, best acc: 0.3670\n","[Epoch 35/100] - Loss: 1.1396\n","Epoch 35 - Validation Accuracy: 0.3525\n","Epoch 35 - Validation Loss: 1.6528\n","so far, best loss: 1.5581\n","so far, best acc: 0.3670\n","[Epoch 36/100] - Loss: 1.2232\n","Epoch 36 - Validation Accuracy: 0.3561\n","Epoch 36 - Validation Loss: 1.6334\n","so far, best loss: 1.5581\n","so far, best acc: 0.3670\n","[Epoch 37/100] - Loss: 1.0616\n","Epoch 37 - Validation Accuracy: 0.3751\n","Epoch 37 - Validation Loss: 1.5904\n","New best loss 1.5904 - Model saved.\n","[Epoch 38/100] - Loss: 0.9810\n","Epoch 38 - Validation Accuracy: 0.3575\n","Epoch 38 - Validation Loss: 1.6529\n","so far, best loss: 1.5904\n","so far, best acc: 0.3751\n","[Epoch 39/100] - Loss: 0.9824\n","Epoch 39 - Validation Accuracy: 0.3552\n","Epoch 39 - Validation Loss: 1.6664\n","so far, best loss: 1.5904\n","so far, best acc: 0.3751\n","[Epoch 40/100] - Loss: 1.1894\n","Epoch 40 - Validation Accuracy: 0.3638\n","Epoch 40 - Validation Loss: 1.6299\n","so far, best loss: 1.5904\n","so far, best acc: 0.3751\n","[Epoch 41/100] - Loss: 1.0298\n","Epoch 41 - Validation Accuracy: 0.3756\n","Epoch 41 - Validation Loss: 1.6495\n","New best loss 1.6495 - Model saved.\n","[Epoch 42/100] - Loss: 1.0532\n","Epoch 42 - Validation Accuracy: 0.3552\n","Epoch 42 - Validation Loss: 1.7010\n","so far, best loss: 1.6495\n","so far, best acc: 0.3756\n","[Epoch 43/100] - Loss: 1.1339\n","Epoch 43 - Validation Accuracy: 0.3715\n","Epoch 43 - Validation Loss: 1.6938\n","so far, best loss: 1.6495\n","so far, best acc: 0.3756\n","[Epoch 44/100] - Loss: 1.0956\n","Epoch 44 - Validation Accuracy: 0.3738\n","Epoch 44 - Validation Loss: 1.6949\n","so far, best loss: 1.6495\n","so far, best acc: 0.3756\n","[Epoch 45/100] - Loss: 1.0138\n","Epoch 45 - Validation Accuracy: 0.3715\n","Epoch 45 - Validation Loss: 1.7468\n","so far, best loss: 1.6495\n","so far, best acc: 0.3756\n","[Epoch 46/100] - Loss: 1.2756\n","Epoch 46 - Validation Accuracy: 0.3643\n","Epoch 46 - Validation Loss: 1.7466\n","so far, best loss: 1.6495\n","so far, best acc: 0.3756\n","[Epoch 47/100] - Loss: 0.9830\n","Epoch 47 - Validation Accuracy: 0.3679\n","Epoch 47 - Validation Loss: 1.7324\n","so far, best loss: 1.6495\n","so far, best acc: 0.3756\n","[Epoch 48/100] - Loss: 0.7886\n","Epoch 48 - Validation Accuracy: 0.3471\n","Epoch 48 - Validation Loss: 1.8283\n","so far, best loss: 1.6495\n","so far, best acc: 0.3756\n","[Epoch 49/100] - Loss: 1.0003\n","Epoch 49 - Validation Accuracy: 0.3697\n","Epoch 49 - Validation Loss: 1.7790\n","so far, best loss: 1.6495\n","so far, best acc: 0.3756\n","Patience exceeded. Loading best model.\n","Training completed. Best Acc:  0.3755656108597285\n","Accuracy on provided split: 0.376\n","OrderedDict([('feature_weights', tensor([[0.1214, 0.8229, 0.4126,  ..., 0.8317, 0.8882, 0.5500],\n","        [0.9192, 0.6455, 0.3346,  ..., 0.5177, 0.7586, 0.4178],\n","        [0.9206, 0.4305, 0.3216,  ..., 0.5178, 0.2625, 0.5544],\n","        [0.6288, 0.7340, 0.4868,  ..., 0.7187, 0.6099, 0.7092]],\n","       device='cuda:1'))])\n","Number of feature extractor parameters: 9\n","torch.Size([8740, 128])\n","torch.Size([512, 128])\n","torch.Size([512, 128])\n","torch.Size([512])\n","torch.Size([512])\n","torch.Size([512, 128])\n","torch.Size([512, 128])\n","torch.Size([512])\n","torch.Size([512])\n","Number of glocal weightor parameters: 1\n","torch.Size([4, 256])\n","Number of case_net_params: 3\n","torch.Size([8544])\n","torch.Size([8544])\n","torch.Size([8544, 4])\n","*****************\n","Training started for 100 epochs with batch size 100\n","[Epoch 1/100] - Loss: 1.6225\n","Epoch 1 - Validation Accuracy: 0.2471\n","Epoch 1 - Validation Loss: 1.6125\n","New best loss 1.6125 - Model saved.\n","[Epoch 2/100] - Loss: 1.5851\n","Epoch 2 - Validation Accuracy: 0.2760\n","Epoch 2 - Validation Loss: 1.5765\n","New best loss 1.5765 - Model saved.\n","[Epoch 3/100] - Loss: 1.5316\n","Epoch 3 - Validation Accuracy: 0.2484\n","Epoch 3 - Validation Loss: 1.5852\n","so far, best loss: 1.5765\n","so far, best acc: 0.2760\n","[Epoch 4/100] - Loss: 1.4840\n","Epoch 4 - Validation Accuracy: 0.2842\n","Epoch 4 - Validation Loss: 1.5750\n","New best loss 1.5750 - Model saved.\n","[Epoch 5/100] - Loss: 1.5801\n","Epoch 5 - Validation Accuracy: 0.2543\n","Epoch 5 - Validation Loss: 1.5845\n","so far, best loss: 1.5750\n","so far, best acc: 0.2842\n","[Epoch 6/100] - Loss: 1.4769\n","Epoch 6 - Validation Accuracy: 0.2810\n","Epoch 6 - Validation Loss: 1.5655\n","so far, best loss: 1.5750\n","so far, best acc: 0.2842\n","[Epoch 7/100] - Loss: 1.4482\n","Epoch 7 - Validation Accuracy: 0.2801\n","Epoch 7 - Validation Loss: 1.5661\n","so far, best loss: 1.5750\n","so far, best acc: 0.2842\n","[Epoch 8/100] - Loss: 1.3963\n","Epoch 8 - Validation Accuracy: 0.2855\n","Epoch 8 - Validation Loss: 1.5672\n","New best loss 1.5672 - Model saved.\n","[Epoch 9/100] - Loss: 1.5113\n","Epoch 9 - Validation Accuracy: 0.3167\n","Epoch 9 - Validation Loss: 1.5412\n","New best loss 1.5412 - Model saved.\n","[Epoch 10/100] - Loss: 1.4567\n","Epoch 10 - Validation Accuracy: 0.3113\n","Epoch 10 - Validation Loss: 1.5404\n","so far, best loss: 1.5412\n","so far, best acc: 0.3167\n","[Epoch 11/100] - Loss: 1.2298\n","Epoch 11 - Validation Accuracy: 0.3199\n","Epoch 11 - Validation Loss: 1.5345\n","New best loss 1.5345 - Model saved.\n","[Epoch 12/100] - Loss: 1.4000\n","Epoch 12 - Validation Accuracy: 0.3326\n","Epoch 12 - Validation Loss: 1.5279\n","New best loss 1.5279 - Model saved.\n","[Epoch 13/100] - Loss: 1.3025\n","Epoch 13 - Validation Accuracy: 0.3357\n","Epoch 13 - Validation Loss: 1.5155\n","New best loss 1.5155 - Model saved.\n","[Epoch 14/100] - Loss: 1.3834\n","Epoch 14 - Validation Accuracy: 0.3376\n","Epoch 14 - Validation Loss: 1.5083\n","New best loss 1.5083 - Model saved.\n","[Epoch 15/100] - Loss: 1.4489\n","Epoch 15 - Validation Accuracy: 0.3362\n","Epoch 15 - Validation Loss: 1.5177\n","so far, best loss: 1.5083\n","so far, best acc: 0.3376\n","[Epoch 16/100] - Loss: 1.3141\n","Epoch 16 - Validation Accuracy: 0.3507\n","Epoch 16 - Validation Loss: 1.5097\n","New best loss 1.5097 - Model saved.\n","[Epoch 17/100] - Loss: 1.2459\n","Epoch 17 - Validation Accuracy: 0.3448\n","Epoch 17 - Validation Loss: 1.5240\n","so far, best loss: 1.5097\n","so far, best acc: 0.3507\n","[Epoch 18/100] - Loss: 1.3348\n","Epoch 18 - Validation Accuracy: 0.3557\n","Epoch 18 - Validation Loss: 1.5107\n","New best loss 1.5107 - Model saved.\n","[Epoch 19/100] - Loss: 1.1448\n","Epoch 19 - Validation Accuracy: 0.3480\n","Epoch 19 - Validation Loss: 1.5131\n","so far, best loss: 1.5107\n","so far, best acc: 0.3557\n","[Epoch 20/100] - Loss: 1.3570\n","Epoch 20 - Validation Accuracy: 0.3502\n","Epoch 20 - Validation Loss: 1.5123\n","so far, best loss: 1.5107\n","so far, best acc: 0.3557\n","[Epoch 21/100] - Loss: 1.2659\n","Epoch 21 - Validation Accuracy: 0.3552\n","Epoch 21 - Validation Loss: 1.5128\n","so far, best loss: 1.5107\n","so far, best acc: 0.3557\n","[Epoch 22/100] - Loss: 1.4046\n","Epoch 22 - Validation Accuracy: 0.3543\n","Epoch 22 - Validation Loss: 1.5180\n","so far, best loss: 1.5107\n","so far, best acc: 0.3557\n","[Epoch 23/100] - Loss: 1.2620\n","Epoch 23 - Validation Accuracy: 0.3480\n","Epoch 23 - Validation Loss: 1.5350\n","so far, best loss: 1.5107\n","so far, best acc: 0.3557\n","[Epoch 24/100] - Loss: 1.1725\n","Epoch 24 - Validation Accuracy: 0.3692\n","Epoch 24 - Validation Loss: 1.5117\n","New best loss 1.5117 - Model saved.\n","[Epoch 25/100] - Loss: 1.1134\n","Epoch 25 - Validation Accuracy: 0.3606\n","Epoch 25 - Validation Loss: 1.5239\n","so far, best loss: 1.5117\n","so far, best acc: 0.3692\n","[Epoch 26/100] - Loss: 1.1833\n","Epoch 26 - Validation Accuracy: 0.3511\n","Epoch 26 - Validation Loss: 1.5365\n","so far, best loss: 1.5117\n","so far, best acc: 0.3692\n","[Epoch 27/100] - Loss: 1.1537\n","Epoch 27 - Validation Accuracy: 0.3620\n","Epoch 27 - Validation Loss: 1.5390\n","so far, best loss: 1.5117\n","so far, best acc: 0.3692\n","[Epoch 28/100] - Loss: 1.1934\n","Epoch 28 - Validation Accuracy: 0.3579\n","Epoch 28 - Validation Loss: 1.5420\n","so far, best loss: 1.5117\n","so far, best acc: 0.3692\n","[Epoch 29/100] - Loss: 1.3280\n","Epoch 29 - Validation Accuracy: 0.3652\n","Epoch 29 - Validation Loss: 1.5448\n","so far, best loss: 1.5117\n","so far, best acc: 0.3692\n","[Epoch 30/100] - Loss: 1.0935\n","Epoch 30 - Validation Accuracy: 0.3557\n","Epoch 30 - Validation Loss: 1.5645\n","so far, best loss: 1.5117\n","so far, best acc: 0.3692\n","[Epoch 31/100] - Loss: 1.0366\n","Epoch 31 - Validation Accuracy: 0.3606\n","Epoch 31 - Validation Loss: 1.5799\n","so far, best loss: 1.5117\n","so far, best acc: 0.3692\n","[Epoch 32/100] - Loss: 1.1266\n","Epoch 32 - Validation Accuracy: 0.3602\n","Epoch 32 - Validation Loss: 1.6199\n","so far, best loss: 1.5117\n","so far, best acc: 0.3692\n","Patience exceeded. Loading best model.\n","Training completed. Best Acc:  0.36923076923076925\n","Accuracy on provided split: 0.369\n","OrderedDict([('feature_weights', tensor([[0.0833, 0.4470, 0.0721,  ..., 0.2497, 0.6653, 0.7681],\n","        [0.7586, 0.4418, 0.2962,  ..., 0.1912, 0.3089, 0.0067],\n","        [0.8903, 0.2653, 0.9423,  ..., 0.8316, 0.6286, 0.8604],\n","        [0.8761, 0.1923, 0.6832,  ..., 0.8441, 0.4484, 0.6720]],\n","       device='cuda:1'))])\n","Number of feature extractor parameters: 9\n","torch.Size([8740, 128])\n","torch.Size([512, 128])\n","torch.Size([512, 128])\n","torch.Size([512])\n","torch.Size([512])\n","torch.Size([512, 128])\n","torch.Size([512, 128])\n","torch.Size([512])\n","torch.Size([512])\n","Number of glocal weightor parameters: 1\n","torch.Size([4, 256])\n","Number of case_net_params: 3\n","torch.Size([8544])\n","torch.Size([8544])\n","torch.Size([8544, 4])\n","*****************\n","Training started for 100 epochs with batch size 100\n","[Epoch 1/100] - Loss: 1.6032\n","Epoch 1 - Validation Accuracy: 0.2471\n","Epoch 1 - Validation Loss: 1.6190\n","New best loss 1.6190 - Model saved.\n","[Epoch 2/100] - Loss: 1.6363\n","Epoch 2 - Validation Accuracy: 0.2674\n","Epoch 2 - Validation Loss: 1.5903\n","New best loss 1.5903 - Model saved.\n","[Epoch 3/100] - Loss: 1.6358\n","Epoch 3 - Validation Accuracy: 0.2941\n","Epoch 3 - Validation Loss: 1.5784\n","New best loss 1.5784 - Model saved.\n","[Epoch 4/100] - Loss: 1.5712\n","Epoch 4 - Validation Accuracy: 0.2941\n","Epoch 4 - Validation Loss: 1.5640\n","so far, best loss: 1.5784\n","so far, best acc: 0.2941\n","[Epoch 5/100] - Loss: 1.5519\n","Epoch 5 - Validation Accuracy: 0.3050\n","Epoch 5 - Validation Loss: 1.5700\n","New best loss 1.5700 - Model saved.\n","[Epoch 6/100] - Loss: 1.5964\n","Epoch 6 - Validation Accuracy: 0.2733\n","Epoch 6 - Validation Loss: 1.5789\n","so far, best loss: 1.5700\n","so far, best acc: 0.3050\n","[Epoch 7/100] - Loss: 1.5322\n","Epoch 7 - Validation Accuracy: 0.2814\n","Epoch 7 - Validation Loss: 1.5705\n","so far, best loss: 1.5700\n","so far, best acc: 0.3050\n","[Epoch 8/100] - Loss: 1.4413\n","Epoch 8 - Validation Accuracy: 0.2828\n","Epoch 8 - Validation Loss: 1.5668\n","so far, best loss: 1.5700\n","so far, best acc: 0.3050\n","[Epoch 9/100] - Loss: 1.4733\n","Epoch 9 - Validation Accuracy: 0.3149\n","Epoch 9 - Validation Loss: 1.5523\n","New best loss 1.5523 - Model saved.\n","[Epoch 10/100] - Loss: 1.5437\n","Epoch 10 - Validation Accuracy: 0.3081\n","Epoch 10 - Validation Loss: 1.5432\n","so far, best loss: 1.5523\n","so far, best acc: 0.3149\n","[Epoch 11/100] - Loss: 1.4553\n","Epoch 11 - Validation Accuracy: 0.3222\n","Epoch 11 - Validation Loss: 1.5454\n","New best loss 1.5454 - Model saved.\n","[Epoch 12/100] - Loss: 1.3860\n","Epoch 12 - Validation Accuracy: 0.3267\n","Epoch 12 - Validation Loss: 1.5349\n","New best loss 1.5349 - Model saved.\n","[Epoch 13/100] - Loss: 1.4748\n","Epoch 13 - Validation Accuracy: 0.3213\n","Epoch 13 - Validation Loss: 1.5389\n","so far, best loss: 1.5349\n","so far, best acc: 0.3267\n","[Epoch 14/100] - Loss: 1.4625\n","Epoch 14 - Validation Accuracy: 0.3357\n","Epoch 14 - Validation Loss: 1.5267\n","New best loss 1.5267 - Model saved.\n","[Epoch 15/100] - Loss: 1.3408\n","Epoch 15 - Validation Accuracy: 0.3466\n","Epoch 15 - Validation Loss: 1.5251\n","New best loss 1.5251 - Model saved.\n","[Epoch 16/100] - Loss: 1.2374\n","Epoch 16 - Validation Accuracy: 0.3425\n","Epoch 16 - Validation Loss: 1.5149\n","so far, best loss: 1.5251\n","so far, best acc: 0.3466\n","[Epoch 17/100] - Loss: 1.4153\n","Epoch 17 - Validation Accuracy: 0.3466\n","Epoch 17 - Validation Loss: 1.5158\n","so far, best loss: 1.5251\n","so far, best acc: 0.3466\n","[Epoch 18/100] - Loss: 1.3223\n","Epoch 18 - Validation Accuracy: 0.3475\n","Epoch 18 - Validation Loss: 1.5218\n","New best loss 1.5218 - Model saved.\n","[Epoch 19/100] - Loss: 1.4871\n","Epoch 19 - Validation Accuracy: 0.3493\n","Epoch 19 - Validation Loss: 1.5208\n","New best loss 1.5208 - Model saved.\n","[Epoch 20/100] - Loss: 1.2618\n","Epoch 20 - Validation Accuracy: 0.3561\n","Epoch 20 - Validation Loss: 1.5196\n","New best loss 1.5196 - Model saved.\n","[Epoch 21/100] - Loss: 1.3692\n","Epoch 21 - Validation Accuracy: 0.3615\n","Epoch 21 - Validation Loss: 1.5194\n","New best loss 1.5194 - Model saved.\n","[Epoch 22/100] - Loss: 1.2709\n","Epoch 22 - Validation Accuracy: 0.3661\n","Epoch 22 - Validation Loss: 1.5195\n","New best loss 1.5195 - Model saved.\n","[Epoch 23/100] - Loss: 1.1837\n","Epoch 23 - Validation Accuracy: 0.3724\n","Epoch 23 - Validation Loss: 1.5178\n","New best loss 1.5178 - Model saved.\n","[Epoch 24/100] - Loss: 1.1904\n","Epoch 24 - Validation Accuracy: 0.3697\n","Epoch 24 - Validation Loss: 1.5326\n","so far, best loss: 1.5178\n","so far, best acc: 0.3724\n","[Epoch 25/100] - Loss: 1.2236\n","Epoch 25 - Validation Accuracy: 0.3652\n","Epoch 25 - Validation Loss: 1.5248\n","so far, best loss: 1.5178\n","so far, best acc: 0.3724\n","[Epoch 26/100] - Loss: 1.1608\n","Epoch 26 - Validation Accuracy: 0.3570\n","Epoch 26 - Validation Loss: 1.5572\n","so far, best loss: 1.5178\n","so far, best acc: 0.3724\n","[Epoch 27/100] - Loss: 1.2085\n","Epoch 27 - Validation Accuracy: 0.3597\n","Epoch 27 - Validation Loss: 1.5307\n","so far, best loss: 1.5178\n","so far, best acc: 0.3724\n","[Epoch 28/100] - Loss: 1.1934\n","Epoch 28 - Validation Accuracy: 0.3584\n","Epoch 28 - Validation Loss: 1.5480\n","so far, best loss: 1.5178\n","so far, best acc: 0.3724\n","[Epoch 29/100] - Loss: 1.1017\n","Epoch 29 - Validation Accuracy: 0.3652\n","Epoch 29 - Validation Loss: 1.5495\n","so far, best loss: 1.5178\n","so far, best acc: 0.3724\n","[Epoch 30/100] - Loss: 1.1314\n","Epoch 30 - Validation Accuracy: 0.3434\n","Epoch 30 - Validation Loss: 1.5639\n","so far, best loss: 1.5178\n","so far, best acc: 0.3724\n","[Epoch 31/100] - Loss: 1.2115\n","Epoch 31 - Validation Accuracy: 0.3557\n","Epoch 31 - Validation Loss: 1.5791\n","so far, best loss: 1.5178\n","so far, best acc: 0.3724\n","Patience exceeded. Loading best model.\n","Training completed. Best Acc:  0.3723981900452489\n","Accuracy on provided split: 0.372\n","OrderedDict([('feature_weights', tensor([[0.5222, 0.0788, 0.1440,  ..., 0.0015, 0.5467, 0.5947],\n","        [0.4810, 0.6280, 0.5384,  ..., 0.1359, 0.0032, 0.2626],\n","        [0.8859, 0.9405, 0.6482,  ..., 0.6771, 0.5521, 0.9181],\n","        [0.2799, 0.5916, 0.7228,  ..., 0.7764, 0.4060, 0.7466]],\n","       device='cuda:1'))])\n","Number of feature extractor parameters: 9\n","torch.Size([8740, 128])\n","torch.Size([512, 128])\n","torch.Size([512, 128])\n","torch.Size([512])\n","torch.Size([512])\n","torch.Size([512, 128])\n","torch.Size([512, 128])\n","torch.Size([512])\n","torch.Size([512])\n","Number of glocal weightor parameters: 1\n","torch.Size([4, 256])\n","Number of case_net_params: 3\n","torch.Size([8544])\n","torch.Size([8544])\n","torch.Size([8544, 4])\n","*****************\n","Training started for 100 epochs with batch size 100\n","[Epoch 1/100] - Loss: 1.4816\n","Epoch 1 - Validation Accuracy: 0.2308\n","Epoch 1 - Validation Loss: 1.6082\n","New best loss 1.6082 - Model saved.\n","[Epoch 2/100] - Loss: 1.4910\n","Epoch 2 - Validation Accuracy: 0.2833\n","Epoch 2 - Validation Loss: 1.5831\n","New best loss 1.5831 - Model saved.\n","[Epoch 3/100] - Loss: 1.6263\n","Epoch 3 - Validation Accuracy: 0.2814\n","Epoch 3 - Validation Loss: 1.5695\n","so far, best loss: 1.5831\n","so far, best acc: 0.2833\n","[Epoch 4/100] - Loss: 1.5417\n","Epoch 4 - Validation Accuracy: 0.2896\n","Epoch 4 - Validation Loss: 1.5723\n","New best loss 1.5723 - Model saved.\n","[Epoch 5/100] - Loss: 1.5014\n","Epoch 5 - Validation Accuracy: 0.2602\n","Epoch 5 - Validation Loss: 1.5762\n","so far, best loss: 1.5723\n","so far, best acc: 0.2896\n","[Epoch 6/100] - Loss: 1.4035\n","Epoch 6 - Validation Accuracy: 0.3023\n","Epoch 6 - Validation Loss: 1.5598\n","New best loss 1.5598 - Model saved.\n","[Epoch 7/100] - Loss: 1.3548\n","Epoch 7 - Validation Accuracy: 0.2801\n","Epoch 7 - Validation Loss: 1.5688\n","so far, best loss: 1.5598\n","so far, best acc: 0.3023\n","[Epoch 8/100] - Loss: 1.4868\n","Epoch 8 - Validation Accuracy: 0.2955\n","Epoch 8 - Validation Loss: 1.5668\n","so far, best loss: 1.5598\n","so far, best acc: 0.3023\n","[Epoch 9/100] - Loss: 1.4887\n","Epoch 9 - Validation Accuracy: 0.3167\n","Epoch 9 - Validation Loss: 1.5470\n","New best loss 1.5470 - Model saved.\n","[Epoch 10/100] - Loss: 1.4360\n","Epoch 10 - Validation Accuracy: 0.3353\n","Epoch 10 - Validation Loss: 1.5344\n","New best loss 1.5344 - Model saved.\n","[Epoch 11/100] - Loss: 1.4702\n","Epoch 11 - Validation Accuracy: 0.3226\n","Epoch 11 - Validation Loss: 1.5321\n","so far, best loss: 1.5344\n","so far, best acc: 0.3353\n","[Epoch 12/100] - Loss: 1.3798\n","Epoch 12 - Validation Accuracy: 0.3326\n","Epoch 12 - Validation Loss: 1.5237\n","so far, best loss: 1.5344\n","so far, best acc: 0.3353\n","[Epoch 13/100] - Loss: 1.4081\n","Epoch 13 - Validation Accuracy: 0.3443\n","Epoch 13 - Validation Loss: 1.5158\n","New best loss 1.5158 - Model saved.\n","[Epoch 14/100] - Loss: 1.3397\n","Epoch 14 - Validation Accuracy: 0.3371\n","Epoch 14 - Validation Loss: 1.5180\n","so far, best loss: 1.5158\n","so far, best acc: 0.3443\n","[Epoch 15/100] - Loss: 1.4051\n","Epoch 15 - Validation Accuracy: 0.3339\n","Epoch 15 - Validation Loss: 1.5334\n","so far, best loss: 1.5158\n","so far, best acc: 0.3443\n","[Epoch 16/100] - Loss: 1.3206\n","Epoch 16 - Validation Accuracy: 0.3502\n","Epoch 16 - Validation Loss: 1.5151\n","New best loss 1.5151 - Model saved.\n","[Epoch 17/100] - Loss: 1.3408\n","Epoch 17 - Validation Accuracy: 0.3525\n","Epoch 17 - Validation Loss: 1.5185\n","New best loss 1.5185 - Model saved.\n","[Epoch 18/100] - Loss: 1.4193\n","Epoch 18 - Validation Accuracy: 0.3520\n","Epoch 18 - Validation Loss: 1.5230\n","so far, best loss: 1.5185\n","so far, best acc: 0.3525\n","[Epoch 19/100] - Loss: 1.3561\n","Epoch 19 - Validation Accuracy: 0.3303\n","Epoch 19 - Validation Loss: 1.5387\n","so far, best loss: 1.5185\n","so far, best acc: 0.3525\n","[Epoch 20/100] - Loss: 1.1191\n","Epoch 20 - Validation Accuracy: 0.3412\n","Epoch 20 - Validation Loss: 1.5330\n","so far, best loss: 1.5185\n","so far, best acc: 0.3525\n","[Epoch 21/100] - Loss: 1.2968\n","Epoch 21 - Validation Accuracy: 0.3398\n","Epoch 21 - Validation Loss: 1.5379\n","so far, best loss: 1.5185\n","so far, best acc: 0.3525\n","[Epoch 22/100] - Loss: 1.2183\n","Epoch 22 - Validation Accuracy: 0.3498\n","Epoch 22 - Validation Loss: 1.5281\n","so far, best loss: 1.5185\n","so far, best acc: 0.3525\n","[Epoch 23/100] - Loss: 1.4340\n","Epoch 23 - Validation Accuracy: 0.3398\n","Epoch 23 - Validation Loss: 1.5490\n","so far, best loss: 1.5185\n","so far, best acc: 0.3525\n","[Epoch 24/100] - Loss: 1.3671\n","Epoch 24 - Validation Accuracy: 0.3493\n","Epoch 24 - Validation Loss: 1.5493\n","so far, best loss: 1.5185\n","so far, best acc: 0.3525\n","[Epoch 25/100] - Loss: 1.2006\n","Epoch 25 - Validation Accuracy: 0.3434\n","Epoch 25 - Validation Loss: 1.5441\n","so far, best loss: 1.5185\n","so far, best acc: 0.3525\n","Patience exceeded. Loading best model.\n","Training completed. Best Acc:  0.35248868778280545\n","Accuracy on provided split: 0.352\n","OrderedDict([('feature_weights', tensor([[0.5142, 0.8287, 0.9361,  ..., 0.5490, 0.7088, 0.0722],\n","        [0.5067, 0.6445, 0.9014,  ..., 0.2716, 0.1183, 0.5097],\n","        [0.7432, 0.1696, 0.7084,  ..., 0.5534, 0.5726, 0.7347],\n","        [0.7587, 0.5145, 0.8381,  ..., 0.5100, 0.2103, 0.2564]],\n","       device='cuda:1'))])\n","Number of feature extractor parameters: 9\n","torch.Size([8740, 128])\n","torch.Size([512, 128])\n","torch.Size([512, 128])\n","torch.Size([512])\n","torch.Size([512])\n","torch.Size([512, 128])\n","torch.Size([512, 128])\n","torch.Size([512])\n","torch.Size([512])\n","Number of glocal weightor parameters: 1\n","torch.Size([4, 256])\n","Number of case_net_params: 3\n","torch.Size([8544])\n","torch.Size([8544])\n","torch.Size([8544, 4])\n","*****************\n","Training started for 100 epochs with batch size 100\n","[Epoch 1/100] - Loss: 1.5460\n","Epoch 1 - Validation Accuracy: 0.2529\n","Epoch 1 - Validation Loss: 1.6060\n","New best loss 1.6060 - Model saved.\n","[Epoch 2/100] - Loss: 1.5664\n","Epoch 2 - Validation Accuracy: 0.2561\n","Epoch 2 - Validation Loss: 1.5958\n","New best loss 1.5958 - Model saved.\n","[Epoch 3/100] - Loss: 1.4313\n","Epoch 3 - Validation Accuracy: 0.2710\n","Epoch 3 - Validation Loss: 1.5796\n","New best loss 1.5796 - Model saved.\n","[Epoch 4/100] - Loss: 1.6263\n","Epoch 4 - Validation Accuracy: 0.2647\n","Epoch 4 - Validation Loss: 1.5744\n","so far, best loss: 1.5796\n","so far, best acc: 0.2710\n","[Epoch 5/100] - Loss: 1.6044\n","Epoch 5 - Validation Accuracy: 0.2593\n","Epoch 5 - Validation Loss: 1.5806\n","so far, best loss: 1.5796\n","so far, best acc: 0.2710\n","[Epoch 6/100] - Loss: 1.5383\n","Epoch 6 - Validation Accuracy: 0.2688\n","Epoch 6 - Validation Loss: 1.5775\n","so far, best loss: 1.5796\n","so far, best acc: 0.2710\n","[Epoch 7/100] - Loss: 1.4735\n","Epoch 7 - Validation Accuracy: 0.2683\n","Epoch 7 - Validation Loss: 1.5775\n","so far, best loss: 1.5796\n","so far, best acc: 0.2710\n","[Epoch 8/100] - Loss: 1.5360\n","Epoch 8 - Validation Accuracy: 0.2923\n","Epoch 8 - Validation Loss: 1.5755\n","New best loss 1.5755 - Model saved.\n","[Epoch 9/100] - Loss: 1.3785\n","Epoch 9 - Validation Accuracy: 0.2774\n","Epoch 9 - Validation Loss: 1.5711\n","so far, best loss: 1.5755\n","so far, best acc: 0.2923\n","[Epoch 10/100] - Loss: 1.4925\n","Epoch 10 - Validation Accuracy: 0.2855\n","Epoch 10 - Validation Loss: 1.5751\n","so far, best loss: 1.5755\n","so far, best acc: 0.2923\n","[Epoch 11/100] - Loss: 1.4508\n","Epoch 11 - Validation Accuracy: 0.3136\n","Epoch 11 - Validation Loss: 1.5608\n","New best loss 1.5608 - Model saved.\n","[Epoch 12/100] - Loss: 1.4527\n","Epoch 12 - Validation Accuracy: 0.3303\n","Epoch 12 - Validation Loss: 1.5502\n","New best loss 1.5502 - Model saved.\n","[Epoch 13/100] - Loss: 1.3594\n","Epoch 13 - Validation Accuracy: 0.3213\n","Epoch 13 - Validation Loss: 1.5466\n","so far, best loss: 1.5502\n","so far, best acc: 0.3303\n","[Epoch 14/100] - Loss: 1.3883\n","Epoch 14 - Validation Accuracy: 0.3326\n","Epoch 14 - Validation Loss: 1.5387\n","New best loss 1.5387 - Model saved.\n","[Epoch 15/100] - Loss: 1.3963\n","Epoch 15 - Validation Accuracy: 0.3339\n","Epoch 15 - Validation Loss: 1.5361\n","New best loss 1.5361 - Model saved.\n","[Epoch 16/100] - Loss: 1.3678\n","Epoch 16 - Validation Accuracy: 0.3412\n","Epoch 16 - Validation Loss: 1.5208\n","New best loss 1.5208 - Model saved.\n","[Epoch 17/100] - Loss: 1.6236\n","Epoch 17 - Validation Accuracy: 0.3389\n","Epoch 17 - Validation Loss: 1.5191\n","so far, best loss: 1.5208\n","so far, best acc: 0.3412\n","[Epoch 18/100] - Loss: 1.2689\n","Epoch 18 - Validation Accuracy: 0.3326\n","Epoch 18 - Validation Loss: 1.5370\n","so far, best loss: 1.5208\n","so far, best acc: 0.3412\n","[Epoch 19/100] - Loss: 1.2689\n","Epoch 19 - Validation Accuracy: 0.3398\n","Epoch 19 - Validation Loss: 1.5333\n","so far, best loss: 1.5208\n","so far, best acc: 0.3412\n","[Epoch 20/100] - Loss: 1.3804\n","Epoch 20 - Validation Accuracy: 0.3543\n","Epoch 20 - Validation Loss: 1.5295\n","New best loss 1.5295 - Model saved.\n","[Epoch 21/100] - Loss: 1.5992\n","Epoch 21 - Validation Accuracy: 0.3692\n","Epoch 21 - Validation Loss: 1.5035\n","New best loss 1.5035 - Model saved.\n","[Epoch 22/100] - Loss: 1.2885\n","Epoch 22 - Validation Accuracy: 0.3448\n","Epoch 22 - Validation Loss: 1.5199\n","so far, best loss: 1.5035\n","so far, best acc: 0.3692\n","[Epoch 23/100] - Loss: 1.3470\n","Epoch 23 - Validation Accuracy: 0.3597\n","Epoch 23 - Validation Loss: 1.5223\n","so far, best loss: 1.5035\n","so far, best acc: 0.3692\n","[Epoch 24/100] - Loss: 1.2139\n","Epoch 24 - Validation Accuracy: 0.3525\n","Epoch 24 - Validation Loss: 1.5118\n","so far, best loss: 1.5035\n","so far, best acc: 0.3692\n","[Epoch 25/100] - Loss: 1.4200\n","Epoch 25 - Validation Accuracy: 0.3751\n","Epoch 25 - Validation Loss: 1.5116\n","New best loss 1.5116 - Model saved.\n","[Epoch 26/100] - Loss: 1.2280\n","Epoch 26 - Validation Accuracy: 0.3525\n","Epoch 26 - Validation Loss: 1.5314\n","so far, best loss: 1.5116\n","so far, best acc: 0.3751\n","[Epoch 27/100] - Loss: 1.3551\n","Epoch 27 - Validation Accuracy: 0.3462\n","Epoch 27 - Validation Loss: 1.5275\n","so far, best loss: 1.5116\n","so far, best acc: 0.3751\n","[Epoch 28/100] - Loss: 1.1046\n","Epoch 28 - Validation Accuracy: 0.3493\n","Epoch 28 - Validation Loss: 1.5420\n","so far, best loss: 1.5116\n","so far, best acc: 0.3751\n","[Epoch 29/100] - Loss: 1.1810\n","Epoch 29 - Validation Accuracy: 0.3683\n","Epoch 29 - Validation Loss: 1.5303\n","so far, best loss: 1.5116\n","so far, best acc: 0.3751\n","[Epoch 30/100] - Loss: 1.2058\n","Epoch 30 - Validation Accuracy: 0.3715\n","Epoch 30 - Validation Loss: 1.5324\n","so far, best loss: 1.5116\n","so far, best acc: 0.3751\n","[Epoch 31/100] - Loss: 1.2646\n","Epoch 31 - Validation Accuracy: 0.3579\n","Epoch 31 - Validation Loss: 1.5495\n","so far, best loss: 1.5116\n","so far, best acc: 0.3751\n","[Epoch 32/100] - Loss: 1.0083\n","Epoch 32 - Validation Accuracy: 0.3661\n","Epoch 32 - Validation Loss: 1.5478\n","so far, best loss: 1.5116\n","so far, best acc: 0.3751\n","[Epoch 33/100] - Loss: 1.0209\n","Epoch 33 - Validation Accuracy: 0.3629\n","Epoch 33 - Validation Loss: 1.5530\n","so far, best loss: 1.5116\n","so far, best acc: 0.3751\n","Patience exceeded. Loading best model.\n","Training completed. Best Acc:  0.3751131221719457\n","Accuracy on provided split: 0.375\n"]}],"source":["# feature_extractor.feature_dim = 128\n","feature_dim = 256\n","\n","# Option 2: Direct train-test split (when not using cross-validation)\n","best_accuracies = []\n","for i in range(8):\n","    feature_extractor = BiLSTMFeatureExtractor().to(device)\n","    # feature_extractor = iniitialize_feature_extractor()\n","    gc.collect()\n","    # For CUDA tensors\n","    if torch.cuda.is_available():\n","      torch.cuda.empty_cache()\n","    # X_train, X_test, y_train, y_test = train_test_split(Xs, ys, test_size=0.1, random_state=cfg.random_seed)\n","    best_accuracy, glocal_weightor, last_model = train_with_given_split(X_train, y_train, X_test, y_test, cfg)\n","    best_accuracies.append(best_accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DTnwMoo6dwz-","outputId":"e8b5c021-8bc6-4e8d-a964-977e59ae9478"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average accuracy across all folds: 0.3681561085972851\n","Standard deviation of accuracy: 0.006839683085941891\n"]}],"source":["# prompt: average of best_accuracies\n","\n","average_accuracy = np.mean(best_accuracies)\n","print(f\"Average accuracy across all folds: {average_accuracy}\")\n","print(f\"Standard deviation of accuracy: {np.std(best_accuracies)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rCT7UnB9dwz_","outputId":"74115323-a062-4125-fe84-8792d6cab660"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average accuracy:0.368\n"]}],"source":["print(f\"Average accuracy:{np.mean(best_accuracies):.3f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KX_W9XtFdwz_","outputId":"ccc83717-f088-42de-d010-52b7e4bcf3e2"},"outputs":[{"data":{"text/plain":["(0.3755656108597285, 0.35248868778280545)"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["max(best_accuracies), min(best_accuracies)"]},{"cell_type":"markdown","metadata":{"id":"j9Ueijo6OGP1"},"source":["## Load Model From Checkpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cUuWejcPPEsn"},"outputs":[],"source":["# Updated to reflect the removal of CaseNet\n","def load_model_cns(X_train, y_train, cfg):\n","    \"\"\"\n","    Load a CaseNetsClassifier model with the provided training data and configuration.\n","\n","    Args:\n","        X_train (torch.Tensor): Tensor of training cases (e.g., images or sequences).\n","        y_train (torch.Tensor): Tensor of one-hot encoded labels for each case.\n","        cfg: Configuration object containing model parameters.\n","\n","    Returns:\n","        CaseNetsClassifier: The loaded model.\n","    \"\"\"\n","    # Define the global-local weightor\n","    glocal_weightor = GlocalFeatureWeight(feature_dim=feature_dim, set_dim=glocal_fw_set_num)\n","    # glocal_weightor.load_state_dict(torch.load(feature_weightor_path))  # Optional: Load pre-trained weights\n","    glocal_weightor.to(device)\n","\n","    # Initialize the CaseNetsClassifier directly with cases and labels\n","    model = CaseNetsClassifier(\n","        cases=X_train,\n","        labels=y_train,\n","        feature_extractor=feature_extractor,  # Pass the feature extractor\n","        glocal_weightor=glocal_weightor  # Pass the global-local weightor\n","    )\n","\n","    # Load the model's weights\n","    model.load_state_dict(torch.load(cfg.PATH))\n","    model.to(device)\n","    model.eval()\n","\n","    return model\n"]},{"cell_type":"markdown","metadata":{"id":"o9TiTSXbnoyn"},"source":["note: loading the cifar10 model takes about 1 hour"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"knVNy1AXOFw9"},"outputs":[],"source":["cfg.PATH = os.path.join(folder_name, f'checkpoints/classifier_{dataset_name}.h5')\n","\n","model = load_model_cns(X_train,y_train,cfg)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"geCINROvItc1"},"outputs":[],"source":["model.sample_num"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qhVk1AJBT-h1"},"outputs":[],"source":["model.state_dict()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9j5C3HOCJ_6_"},"outputs":[],"source":["# prompt: garbage collection\n","\n","import gc\n","\n","# Force garbage collection\n","gc.collect()\n","\n","# For CUDA tensors\n","if torch.cuda.is_available():\n","  torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VhnUZwsWdw0A"},"outputs":[],"source":["next(model.parameters()).is_cuda"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"crtSSc0RUFGM"},"outputs":[],"source":["from torch.utils.data import DataLoader, TensorDataset # Import TensorDataset\n","\n","\n","X_val = X_test.to(device)\n","y_val = y_test.to(device)\n","batch_size = 128  # Or an even smaller size if needed\n","\n","# Create a DataLoader for your validation data\n","val_dataset = TensorDataset(X_val, y_val)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","final_predictions_list = []\n","predicted_class_list = []\n","\n","with torch.no_grad():\n","    for batch_X, batch_y in val_loader:\n","        batch_final_predictions, batch_predicted_class,_,_ = model(batch_X)\n","        final_predictions_list.append(batch_final_predictions)\n","        predicted_class_list.append(batch_predicted_class)\n","\n","# Concatenate predictions from all batches\n","final_predictions = torch.cat(final_predictions_list, dim=0)\n","predicted_class = torch.cat(predicted_class_list, dim=0)\n","# final_predictions, predicted_class = model(X_val)\n","val_loss = criterion(final_predictions, y_val).item()\n","print(f\"Validation Loss: {val_loss:.4f}\")\n","best_accuracy = accuracy_score(y_val.cpu().numpy(), predicted_class.cpu().numpy())\n","print(f\"Validation Accuracy: {best_accuracy:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qiV-z0hldw0B"},"outputs":[],"source":["from torch.utils.data import DataLoader, TensorDataset\n","import torch\n","from sklearn.metrics import accuracy_score\n","\n","# Move data to device\n","X_val = X_test.to(device)\n","y_val = y_test.to(device)\n","batch_size = 128  # Or an even smaller size if needed\n","\n","# Create a DataLoader for your validation data\n","val_dataset = TensorDataset(X_val, y_val)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","final_predictions_list = []\n","predicted_class_list = []\n","\n","with torch.no_grad():\n","    for batch_X, batch_y in val_loader:\n","        # Get predictions for the batch\n","        batch_final_predictions, batch_predicted_class, _, _, _ = model(batch_X)\n","        final_predictions_list.append(batch_final_predictions)\n","        predicted_class_list.append(batch_predicted_class)\n","\n","# Concatenate predictions from all batches\n","final_predictions = torch.cat(final_predictions_list, dim=0)\n","predicted_class = torch.cat(predicted_class_list, dim=0)\n","\n","# Compute validation loss\n","val_loss = criterion(final_predictions, y_val).item()\n","print(f\"Validation Loss: {val_loss:.4f}\")\n","\n","# Calculate accuracy for the top-1 predictions\n","best_accuracy = accuracy_score(y_val.cpu().numpy(), predicted_class.cpu().numpy())\n","print(f\"Validation Accuracy (Top-1): {best_accuracy:.4f}\")\n","\n","# Calculate Top-k Accuracies (Top-1, Top-2, Top-3)\n","top_k_values = [1, 2, 3]\n","top_k_correct_counts = {k: 0 for k in top_k_values}\n","\n","# Get top-k predictions for each sample\n","top_k_predictions = torch.topk(final_predictions, max(top_k_values), dim=1).indices  # Shape: [num_samples, max_k]\n","\n","for k in top_k_values:\n","    # Check if the correct class is within the top-k predictions\n","    correct_in_top_k = torch.any(top_k_predictions[:, :k] == y_val.unsqueeze(1), dim=1)\n","    top_k_correct_counts[k] = correct_in_top_k.sum().item()\n","\n","# Calculate percentages\n","num_samples = y_val.size(0)\n","for k in top_k_values:\n","    accuracy_k = top_k_correct_counts[k] / num_samples * 100\n","    print(f\"Top-{k} Accuracy: {accuracy_k:.2f}%\")\n"]},{"cell_type":"markdown","metadata":{"id":"aQMTPXLwaBVq"},"source":["# Results Interpretation"]},{"cell_type":"markdown","metadata":{"id":"FeyCa4Nitll8"},"source":["## Inspecting one case"]},{"cell_type":"markdown","metadata":{"id":"k3uBeaYMgI_G"},"source":["### Explanation for SST\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6euPutF8gNnR"},"outputs":[],"source":["query = X_test[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1736637507116,"user":{"displayName":"Xiaomeng Ye","userId":"13514710516313163849"},"user_tz":300},"id":"3HCLJLlXgOlM","outputId":"082878f5-e706-4d6a-fbdd-7f453955d5c6"},"outputs":[{"data":{"text/plain":["torch.Size([56])"]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["query.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T01GFgBcghJw"},"outputs":[],"source":["def classify_and_explain_sst(model, query, case_nets, vocab, classes, device='cuda'):\n","    \"\"\"\n","    Classify a query sentence and provide the most activated case as an explanation.\n","\n","    Args:\n","        model (CaseNetsClassifier): Trained model for classification.\n","        query (torch.Tensor): Query tensor of shape [seq_len].\n","        case_nets (list): List of CaseNet objects.\n","        vocab (torchtext.vocab.Vocab): Vocabulary used for numericalization.\n","        classes (list): List of class names for the dataset.\n","        device (str): Device to run the inference on ('cuda' or 'cpu').\n","\n","    Returns:\n","        dict: Results containing predictions and explanation.\n","    \"\"\"\n","    model = model.to(device)\n","    query = query.to(device)  # Add batch dimension [1, seq_len]\n","\n","    # Classify query and get explanation\n","    final_predictions, predicted_class, most_activated_cases, most_activated_activations = model(query)\n","\n","    # Get the most activated case and its label\n","    most_activated_case = most_activated_cases[0].case.cpu().squeeze()\n","    most_activated_label = torch.argmax(most_activated_cases[0].label).item()\n","    most_activated_activation = most_activated_activations[0].item()\n","\n","    # Decode query and most activated case from indices to tokens\n","    def decode(tokens, vocab):\n","        reverse_vocab = {idx: token for token, idx in vocab.items()}  # Create reverse mapping\n","        return \" \".join([reverse_vocab[token.item()] for token in tokens if token.item() != vocab[\"<pad>\"]])\n","\n","    query_text = decode(query.squeeze().cpu(), vocab)\n","    most_activated_case_text = decode(most_activated_case, vocab)\n","\n","    # Return detailed results\n","    return {\n","        \"query\": query_text,\n","        \"query_prediction\": classes[predicted_class.item()],\n","        \"most_activated_case\": most_activated_case_text,\n","        \"most_activated_case_label\": classes[most_activated_label],\n","        \"most_activated_activation\": most_activated_activation\n","    }\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"54dH0sPeg9-0"},"outputs":[],"source":["model = last_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q3DET2iBgqZL"},"outputs":[],"source":["# Example usage\n","# Assume you have a trained CaseNetsClassifier `model`, SST data, and case_nets\n","\n","# Select a query from the test dataset\n","query_idx = 3  # Example test query index\n","query = X_test[query_idx]  # No need to unsqueeze; function handles it\n","classes = [\"Negative\", \"Positive\"]  # SST binary classes\n","classes = [\"Negative\", \"Somewhat Negative\", \"Neutral\", \"Somewhat Positive\", \"Positive\"]\n","# Run the classify_and_explain_sst function\n","results = classify_and_explain_sst(model, query, model.case_nets, vocab, classes)\n","\n","# Print the classification results\n","print(\"Classification Results:\")\n","print(f\"Query Sentence: {results['query']}\")\n","print(f\"Predicted Class: {results['query_prediction']}\")\n","print(f\"Most Activated Case Sentence: {results['most_activated_case']}\")\n","print(f\"Most Activated Case Label: {results['most_activated_case_label']}\")\n","print(f\"Most Activated Activation: {results['most_activated_activation']:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r28NZrjYkszn"},"outputs":[],"source":["# model.sampling_cases = True\n","# model.sample_num = 500"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fY03_oK8Rrit"},"outputs":[],"source":["model.sampling_cases"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UC3GjdG8ssaC"},"outputs":[],"source":["model.sample_num"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3DLq8zuGjDJz"},"outputs":[],"source":["import random\n","random_indices = random.sample(range(len(X_test)), 20)\n","\n","# Loop through the randomly selected queries\n","for i, query_idx in enumerate(random_indices):  # Loop through the first 20 test queries\n","    query = X_test[query_idx]  # Get numericalized query tensor\n","    true_class = y_test[query_idx]  # Get true class label\n","    # Run the classify_and_explain_sst function\n","    results = classify_and_explain_sst(model, query, model.case_nets, vocab, classes)\n","\n","    # Print the classification results\n","    print(f\"--- Example {query_idx + 1} ---\")\n","    print(f\"Query Sentence: {results['query']}\")\n","    print(f\"True Class: {classes[true_class]}\")\n","    print(f\"Predicted Class: {results['query_prediction']}\")\n","    print(f\"Most Activated Case Sentence: {results['most_activated_case']}\")\n","    print(f\"Most Activated Case Label: {results['most_activated_case_label']}\")\n","    print(f\"Most Activated Activation: {results['most_activated_activation']:.4f}\")\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"zd23CxmQle91"},"source":["### 6.0 Explanation for CIFAR10"]},{"cell_type":"markdown","metadata":{"id":"XLS88En2lqdb"},"source":["For CIFAR10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dDKfKBiRlg2T"},"outputs":[],"source":["query = X_test[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1KhzwNellkK7"},"outputs":[],"source":["query.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_tykP0rplrlM"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import torchvision.transforms as transforms\n","\n","def classify_and_explain(model, query, case_nets, classes, device='cuda'):\n","    \"\"\"\n","    Classify a query and provide the most activated case as an explanation.\n","\n","    Args:\n","        model (CaseNetsClassifier): Trained model for classification.\n","        query (torch.Tensor): Query tensor of shape [1, channels, height, width].\n","        case_nets (list): List of CaseNet objects.\n","        classes (list): List of class names for the dataset.\n","        device (str): Device to run the inference on ('cuda' or 'cpu').\n","\n","    Returns:\n","        dict: Results containing predictions and explanation.\n","    \"\"\"\n","    model = model.to(device)\n","    query = query.to(device)\n","\n","    # Classify query and get explanation\n","    final_predictions, predicted_class, most_activated_cases, most_activated_activations = model(query)\n","\n","    # Get the most activated case and its label\n","    most_activated_case = most_activated_cases[0].case.cpu().squeeze()\n","    most_activated_label = torch.argmax(most_activated_cases[0].label).item()\n","    most_activated_activation = most_activated_activations[0].item()\n","\n","    # De-normalize the query and most activated case for visualization\n","    # Single mean and std for all channels\n","    mean, std = 0.4734, 0.2111  # Replace with your computed values\n","\n","    transform = transforms.Compose([\n","        transforms.Normalize(mean=[-mean / std], std=[1 / std]),  # Single value for all channels\n","        transforms.ToPILImage()\n","    ])\n","\n","    query_image = transform(query.cpu().squeeze())\n","    most_activated_image = transform(most_activated_case)\n","\n","    # Visualization\n","    plt.figure(figsize=(5, 2))\n","\n","    # Query Image\n","    plt.subplot(1, 2, 1)\n","    plt.imshow(query_image)\n","    plt.title(f\"Query (Predicted: {classes[predicted_class.item()]})\")\n","    plt.axis('off')\n","\n","    # Most Activated Case\n","    plt.subplot(1, 2, 2)\n","    plt.imshow(most_activated_image)\n","    plt.title(f\"Most Activated Case\\n(Label: {classes[most_activated_label]}, Activation: {most_activated_activation:.4f})\")\n","    plt.axis('off')\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","    # Return detailed results\n","    return {\n","        \"query_prediction\": classes[predicted_class.item()],\n","        \"most_activated_case_label\": classes[most_activated_label],\n","        \"most_activated_activation\": most_activated_activation\n","    }\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L6Z7vqIzlvek"},"outputs":[],"source":["# Example usage\n","# Assume you have a trained CaseNetsClassifier `model`, a CIFAR-10 query, and case_nets\n","\n","query_idx = 3  # Example test query index\n","query = X_test[query_idx].unsqueeze(0)  # Add batch dimension\n","classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]  # CIFAR-10 classes\n","\n","results = classify_and_explain(model, query, model.case_nets, classes)\n","\n","print(\"Classification Results:\")\n","print(f\"Predicted Class: {results['query_prediction']}\")\n","print(f\"Most Activated Case Label: {results['most_activated_case_label']}\")\n","print(f\"Most Activated Activation: {results['most_activated_activation']:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"dmY-zmsanS2G"},"source":["![image.png](data:image/png;base64,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)"]},{"cell_type":"markdown","metadata":{"id":"y2HuDZktnPSv"},"source":["![image.png](data:image/png;base64,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)"]},{"cell_type":"markdown","metadata":{"id":"9qWKdhZcnvNe"},"source":["![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAfAAAAC+CAIAAABF68oZAAAgAElEQVR4Aeydd1zUyPvHg6BgBztFQXpHmnQQK4IKdsACIqJSpCkWinRFEJDeLagoNuxdz3b2jnq2syuK9ezeaX548/VDfgsu6uGxB8Pr/UfIJpOZybPvfXaSzTAs/aM9QHuA9gDtgXrRA0y9aAVtBO0B2gO0B2gPsFToNAhoD9AeoD1QT3qACr2enEjaDNoDtAdoD1Ch0xigPUB7gPZAPekBKvR6ciJpM2gP0B6gPUCFTmOA9gDtAdoD9aQHqNDryYmkzaA9QHuA9gAVOo0B2gO0B2gP1JMeoEKvJyeSNoP2AO0B2gNU6DQGaA/Uqx5wcXGRlZUVkCYtXLiQYZgbN24ISH3qfTWo0Ov9KaYNrL4HiGsYhjlw4AB3i0+fPsnIyDAMY2dnx13/A8v37t2bPXv26dOnv2Xf9PR0hmG6d+/+LRuTbaotv7aE/vr169mzZ+/du/fb61N1y28R+unTp0eNGiUjI9OkSRMJCYlevXoVFBT89ddfVUuja2rsASr0GruIblA/e4C4RkxMbPLkydwW7t27l2EYUVHRfy7048ePMwyzcOFCbvlfWzY1NZWTk2MY5urVq1/bhmd9teV/+PDh3bt3PFv+wL/l5eUMw8yePfsH9sUuNQo9NzdXWFhYSkpq+vTpeXl5SUlJAwYMEBISiomJQSF04dt7gAr92/uKblmveoC4ZsiQIe3atfvzzz/RtgkTJujr68vKyv6bQv/9998Zhlm7dm379u3Dw8NRGf4L1Qqd/y7f/uq/IPTDhw8LCwubm5v/8ccf3IodP378Gz8FuXvRZZalz3KhUdBQe4AIfdWqVUJCQlu2bCHd8P79ewkJifnz5/MI/dWrVwEBAWRYQFlZOT4+/tOnT+i5HTt2mJmZtW7dunnz5srKyjNnzmRZlmT6DOePj6SioqIkJCTev38/efJkJSUllEwWnj175ufnJysr26RJE2lp6TFjxpSXl3+tfAy5fPjwQUJCwtXVlVvaixcvREVFAwMDWZZ9//59aGionp5eq1atmjVrZm5uvmfPHrLxjRs3OBX/vIhU/dKlS0OHDpWQkBAVFdXX11+/fj23/NLSUmtrazExMWlp6aioqPz8fD5j6DY2NiIiIrdu3eKWwLMcHx9vYmLSpk0bMTExPT29VatWcTeotufJBu/evQsLC1NQUGjSpImMjMy0adNq5YsL9+gCuEwzdAE8KbRK/0YPEKEfP37c1NR0zJgx5JAlJSWNGjW6d+8eV+ifPn3q2bOnkJCQu7t7WlrawIEDGYbx8/Mju5SWljZp0sTAwGDBggVZWVlTp061tLRkWbasrCwyMpJhGA8Pj8K//65fv/61hqmqqo4fP55l2f379zMMc+zYMWz58uVLTU1NYWHhCRMmZGZmRkVFGRoanj59+mvlQ+gsy7q5uYmLi79//x6lLV68uOLywPHjx1mWLS8vl5SUDAgIyMzMnDdvnoqKSuPGjcmI/6tXrzIzMxmGGTx4MKn82bNnWZYtLS1t3bq1urp6XFxcWlqapaWlkJDQ2rVrSfkPHjxo3769hIREeHh4fHy8kpKStrb214T++vXrxo0b9+zZE3WrdkFGRsbT0zMtLS0xMbF79+4Mw2zatIls+bWeZ1n248ePffv2bdasmZ+fX3Z2tre3t4iIiL29fbWHqE8rqdDr09mkbfmOHoDQ09LSWrZs+ebNG5Zlhw8fbm1tzbIsV+glJSUMw0RHR6P0YcOGCQkJXbt2jWXZpKQkhmHKy8vxKha+cUjkxIkTDMPs3LmTZVlySdbX1xeFhIWFkdEYrCGbsSxbbflcoW/fvp1hmI0bN2JfW1tbeXl58u9ff/3Fdf2zZ886duzo5uZGXq12yKVXr15aWlpIdT99+mRqaoqvFH5+fgzDHD16lJTw6NGj1q1bf03oZ8+eZRiG21JUkrtAzgtZ8+HDB01NTXwG8On5wsLCRo0acS93Z2VlMQxz6NAhbuH1b5kKvf6dU9qib+oBCP3Ro0ciIiLFxcV//PFH06ZNc3NzeYTu4eEhLCzMHec9fPgwwzCpqakVW5Jy8vLyPn78yHPgaoXLsw3Lsv7+/h07dsR9HYGBgdx/NTQ0dHR0qu71LUL/888/27VrN3r0aLL706dPGzduTEaEuAV+/PjxyZMn5eXldnZ23bp1Iy9VFfqTJ0+EhISioqLKOX8REREMw9y9e5dlWWVlZWNjY27Jnp6eXxP6gQMHGIYJCQnhbs9n+enTp+Xl5ZMnTxYXFyeb8en5QYMGaWhocKpZfuXKFZ5PZT7H+u++RIX+3z13tOb/qAcgdJZlbWxsHBwcFi1a1KRJk2fPnvEIvV+/fp07d+Ye7Pnz5wzDTJ06lWXZN2/emJmZMQzTrl27kSNHrly5Emb/FqH/9ddfkpKSjo6OV7/8FRcXMwyzfft2ckQxMbFRo0Zxj47lasvnZugsy06cOLFly5Ykp87Ly2MY5syZMyhh0aJFWlpajRs3xoh5165dyatVhX706FFsxrNw6tQplmVFRUUxeEUKWbBgwdeE/o0Z+saNG42MjERFRXFEISEhUjifnldTU8P23IUpU6ag7fVygQq9Xp5W2qiae4Ar9CVLloiKihobG2OYlTvkwl/oZMR2165d/v7+xCM9e/Yk6Xa1wuWp2Y4dO7jGwfLYsWPJlv9Q6OTa6bp161iW7du3r6qqKipQWFhY4XcHB4clS5Zs27Zt586dPXv2xI+SqgqdfC+ZOnXqzip/5OvLdwn99evXIiIiGD9BrbgL+/fvFxISsrKyys/P37Jly86dO52dnSuu0GKbjx8/VtvzKioqWlpaVaq587fffsO+9XKhsmvqZfNoo2gPfK0HuEJ/+fJl06ZNGYZZuXIl2Z4r9KpDLkeOHMGQC0/5MTExGBAng+N8bm5hWdbFxaVDhw6r/v+fk5MThvX5DLlUWz5Phv7x40fyDaC8vFxERAQ3q7Asa29vLy8vz71dx9TUFEJ//Pgx9+YWlmUfPnzIMEzVERv0wHcNuZAPGBERkdu3b6MEngVfX9+mTZtiyJ5lWR6hc7fn9rytra20tDS3adwt6/EyFXo9Prm0afx6gCt0lmUXLVoUHh6OS3BcoZOLorGxsShu5MiRuCj65MkTrGdZdvPmzbgT49KlSwzDJCUlcTfgLr9586Zly5a4DomXDh06xDDMihUrKq5/8rkoWm35PEJnWdbHx6d58+aJiYkMw1y8eBFHGTJkiLy8PAaIjhw5IiQkBKG/efOm6kXLHj16tGnT5v79+yiEZdlHjx6Rf7/roijLsocOHRIWFraysnr58iW3wBMnTixatIhl2YCAgGbNmlX8ZpW8euPGjWbNmiFD59PzFWeTYZjs7GxusW/evHn16hV3Tf1bpkKvf+eUtuibeoBH6Dz7cIX+8eNHa2trISEhDw+P9PR0e3t77m2Lvr6+urq6ISEhubm5MTEx0tLSMjIyz58/Z1n2w4cP4uLiKioqeXl5RUVFv//+O89RVqxYwTBMSUkJz/qPHz+2b99+4MCBLMu+fPlSXV2d3LaYlZUVGxtrbGxMxsGrLb+q0A8ePMgwTMuWLbW0tLgHKigoYBhm0KBB2dnZM2bMEBcX19DQgNBZllVXV+/UqVN6enpRUdH58+cr7gK6cOGChIRE27ZtZ8yYkZOTExUVZWtrq62tTYq9f/9+27Ztv/G2RbJLVlZWo0aNpKWlZ8yYkZ+fn5yc7ODg0KhRI/LxuXv3boZhLCwsMjMzIyIiOnToQO6DJPvy6fmPHz/a2toKCQk5OjqmpqYmJydPmjSpTZs25H5NbifUs2Uq9Hp2QmlzvrUHvl3oxKr+/v5SUlKNGzdWUlLi/rBo9+7d9vb2UlJSTZo0kZKScnJyunLlCiqxfv16dXV1ERGRap8BMHDgQDExMWSg2ItlWVdX18aNGz9+/LgixX7y5Im3t7e0tDT5jYyLiwtZz7Js1fKrCv3Tp0+dO3eueo/Hp0+fYmNjZWVlRUVFdXV1N23axLPvr7/+qq+v36RJE+7Yy/Xr18eOHdupU6fGjRtLS0sPGDBg9erVqPm5c+esrKy+8YdFZK+TJ086OzuTviXPclm8eDG+N+Tn5yspKYmKiqqqqlYMXs2ePRsZOv+e//DhQ1xcnIaGhqioqISEhL6+fkRExIsXL1DVerlAhV4vTyttFO0B2gMNsQeo0BviWadtpj1Ae6Be9gAVer08rbRRtAdoDzTEHqBCb4hnnbaZ9gDtgXrZA1To9fK00kbRHqA90BB7gAq9IZ512mbaA7QH6mUPUKHXy9NKG0V7gPZAQ+yB+ib0/v37u7u7/2tn0urvP3I4MicA/99512LFuIf+J8WSG3urfforKVZWVtbFxaXaQ8TFxamoqOCWYZZljYyMpk2bVu3GfFZaWVlpaGjw2YD/S3xqyH/Hqq/+85P4z0uoWisBWUMeC/MPZxn9Wlvqcb99rcnfuP7ChQvCwsLkh1017vKtQi8tLR01ahT59YSkpOSoUaMuXLhQY+n/8gYHDx4UFhbGlIzcKV1ERES6du06ZswYPpMM/EBtuVb99oiseCjz7NmzyVP9fuCgZBfuoX+4kIodf1joL168aNOmTUFBAY5e8Szs/v37N2vW7MGDB1j5LQtU6N/SSz+8zbNnz8jTCrm/+6+xtPT0dJ7spBaFvmzZMp4nInz726fGmn/jBocOHTIzM2vatGnHjh19fHx4Hj/wtULIU3+rPgG/qKhIV1dXVFS0Xbt2bm5uVTOksrIyDw8PKSkpUVFRWVlZnuc93L17d/jw4a1bt27ZsuWgQYN4NDVo0KDBgwd/rUrc9d8k9DVr1jRp0qRTp07BwcF5eXkhISGSkpKioqJVf7LMLfrfX7a3t+/bty+OS+JvypQphYWFBQUF3t7eTZo0adOmTcVc6djmHy5wrfrp06e3b9/iqdZ8So6Pj//aM0X57MXzEvfQPC991781Cv3du3cfPnyoWmZSUlKrVq3evn2LlxiG8fT07NSpU2hoKFZ+y4LgCP3bT+LX2vXvi+lrNcH6nJwcMTEx8v7FyhoXNDQ0rKysuJt9/Pjx7du33C9k3Fe/a9nOzo77jAEyZcc3vn2+60Bf2/j06dNiYmK6urqZmZnBwcGioqI2NjZf2xjrP3782K1bt+bNm/MIPSMjg2GYXr16paenz5w5s1mzZtra2ty3xu3btzv//RcZGZmfnx8VFUWe60BKfvnypZKSUocOHeLi4hITEzt37iwjI4MfA7Msu2XLFoZhyIQqqEy1CzUL/dq1a82aNVNVVcUjeMjkVaqqqi1atKj6eIpqD/O9K6v9MTT/Qh4+fCgiIpKXl4fNiNC5kxCmpKQwDMN9yhI2/rGn9vyYVf9bQkcX8Sxoa2tj5gTyUkWUe3l5eXt7y8rKfteD7gRH6Dxt5Pn3W4JEAIVuaWk5ZMgQf39/POucp13V/ltV6NVu9mMrqwr9x8r54b369+8vKSmJJwHk5uZyn0H/tWIzMzPbtm3r6+vLFfr79+/FxcUtLS0R8xs3bmQYJiUlBeX079+/a9euXEfjJZZl4+LiuPMOXrp0SVhYmPtUSzI97LfkSTULfeLEiQzD7N+/n1sDlmX37dvHMMzkyZPJep6nQFSs5D51gWxTWFiop6cnJiYmISExcuRI7mMzyVv6xIkTFhYWTZs29fX1HTt2bNu2bXlywz59+igrK/PUhPxLnjR08+ZNvFpV6KWlpQzDTJgwoWIbUr0LFy44OTmJi4tjohY+lWRZNjs7W15eXkxMzNDQcP/+/VyhV30nX7p0afjw4e3atRMTE1NWVp41axaOi8dec1P1Hz40y7K3bt26dOkS2l51ISUlpWIqyKZNm4qLi+vr6y9btoxsQ/rh6tWrLi4urVu3btWqlaurK/cDlTtCTZ5/sm/fPkdHR4ZhxMTExowZ8/TpU1IUEfr69esrHvlEZjxANUpKSmxtbSUlJZs0aSIvLx8ZGcn9KoOzb2JiIiYmJicnl5mZiX1ZluU/4S+3hizLXvv7j7s7d/nJkyeBgYGamprNmzdv2bJlxdQW3AkfeE6ii4tL8+bNr1271r9//xYtWpCnpfOvLU8JZ8+edXFx6dq1q6ioaMeOHceNG8d9V9fY+SzL8o8KbtOqXb5165aQkFBxcTGZnqLqHGyFhYWGhoYkMCwsLMjEGrKystwQJak6d8jFy8urefPm3DhhWdbR0RFzLfE541ZWVtzCSarO028sy+7evdvc3LxZs2atW7ceNGgQd7yoxn4rLy+/dOkST/XQPy9evBAREeFe7Hn//n2LFi3ItK7YjGfhyZMnbdu2TU9PJ0fHoMrJkycZhqlYz92+RYsWpqamZA15KGZGRgbLsm/fvuVxWsUTOg3//uPu3rdvXwUFBe6awYMH4yFo3PU8yzULXUpKSk5Ojmc38q+cnJyMjAxZrlHo0dHRQkJCI0eOzMjIiIiIaNeunZycHMaRraysKp7r1r59ex8fn+zs7JKSkp07d/JMh/jgwQNhYeHIyMhqK+Pu7t62bVvuS1WFTlwzY8aMis3IWVFXV7e3t8/IyCDng38lyYQvpqamKSkpfn5+4uLi8vLy+FrKE5Fnz55t1apV27ZtZ86cmZ2dHRQURJ51d/bsWScnJ/JUVTL9Lsn7/smhK+aYJ28SbvO5yzk5OQzDDBs2LDs7e8GCBePHj8fULaQfdHV1hwwZkpGR4e7uzjBMUFAQdufqkghdS0tLRUWFYRhHR8dGjRohNyFCv3v3btVnhTs4OIwYMSI+Pj4zM3P48OGY7occxcrKSkpKqkOHDt7e3ikpKebm5gzD5Ofnk1drnPCXW0My2RDP13m0hUzbpqCgMGPGjOzs7MjISGlp6datW2MUjuckuri4iIqKKigouLi4ZGVlLVmyhHQ1n9rylJCQkGBhYREZGZmTk0Oe7t29e3ekcjV2Pv+o4Lbra8tz585t0aIFeSywgoKCp6cnd8vw8HCGYUxNTePj4xcsWODs7Dx9+nSWZdetWycjI6OqqkpCdMeOHRUN5wqdTGZdXFyM0l6/ft28eXMvLy+yhs8Z37FjR7du3dq1a0cKJ5Nv8PTbzp07RURElJWV582bR3QhISFx48YNUniN/UY2+Nr1W/L4STz7npRpbm6up6eH5lRd8PT01NDQqEhESOEQ+q+//sowDPdiEsuy7du3b9q0KRmeSk1NZRhmzZo1PXv2ZBhGWFjYxsYGbfn48aOoqCgyY3LckJAQhmG4sx5GR0c3atQIXymqVo+sqUHoZKotTOPCU8qgQYNwVP5Cv3nzprCwcExMDEo4f/68iIgI1hAfZWVlYYOPHz/KyMiMHDkSaxITE4WEhL42yGNubq6vr4+NEX8FBQXl5eX379/fvHmznJyckJAQeYQmOStOTk7YhX8lP3z40KFDh27dumFeXWLJrwnd0tKyZcuWt27dQvl4G1cdcvmHh65R6Pb29l+7jYT0A/cSzeDBg7kfjVxdEqHr6+vPnDmTYZiXL1/OmzePYZj169ezLEuEzrJskyZNeAIUzxknvTFx4sRmzZph4gJy9ufPn09eff/+fbdu3Tp06EBymRon/OXWsEahv3v3jjsKfOPGDVFRUWQJPFpxcXFhGIZkADiP/GvLUwJPw4uKirjfd/l3Pv+oQH34L2hpaWEGu1mzZrVr1+7PP/8ku1y9erVRo0aDBw/mdgiitOqQC1fonz59kpaWHjp0KI5OZs7DV3mehvOc8apDLjz9RgIATzw/e/Zso0aNMIsT/36rqBLZ4GtCX7VqFfcskCYMHz68U6dOaA7PwtmzZ4WFhcnXF1I4hF5eXi4kJMTN7n/77TfyFYR8G5syZUpFitO2bVsbG5uVK1fGx8e3aNFCQUGBfIEgM0MhAslx09PTKxIm7vxKy5cv507AzVM9/FuD0O/cuVMxGM8zVIqdR40aVTGCQbIb/kInLr569Sp32lY1NbXevXuT0qysrERFReFKsnL69OlNmzbFx5S+vr6ZmRmOzrPALY28ROKP++Wuffv2JMmq2ICclX379qEc/pUkn8Pcj5wPHz60bt26WqE/evSo6uQAOFBVof/DQ6Pkry2Q4ZRjx45V3YD0A/clMhMCcgGuLonQs7OzJ0+eXDH9DXmurIiIyMSJE7lC79ix4/Dhw6seq2LKgj/++KO8vHzp0qXcyS2trKxERES4I9SZmZkMwxw+fJhl2Ron/OXWsNqDVrvyr7/+evz4cXl5uba2toODA9mGRytE6NxPZfLZyae2PCXg0G/fvi0vLyevJicnk/X8O59/VKBkPgtk3s5NmzaRbc6fP4/JN1iWJXF4+vTpakvgL3SWZf38/Jo2bYqbQ4YOHVrtJEHVnnH+Qr9//z7P10SWZfv169euXTtSVf79Vm1zuCuXLFlSVY5jxoxp3bo1dzPuspWV1YABA8gacnQInWXZkSNHioiIJCQkXL9+ff/+/To6OmSa1jt37rAs6+bmxjCMhoYGPjjJ5zqZjvz27dsMw8TFxXEPl5+fzzAM99Rs3bqVYZjNmzdzN6u6XIPQa8zQhYSEiIX5C33y5MlcsWIZo0JWVlby8vI89btw4QLDMIsXL64YniMfelyf8myspqbWq1cv7koi9LCwsJ07d+7Zs+fcuXPITSo2I2eFO47Pv5LkHOzevZt7CF1d3WqFTqYoIyeMuz1Zrir0f3joqofgWXPx4kVpaWmGYRQVFT09PQ8ePIgNSD+UlZVhDbE2rkZwdUle2rNnD4TOsmznzp379evHFXqHDh1GjBiBAlmWLS0tdXBwaNWqFU49wzD4NLWysurSpQt3ezKzQVFREcuyNU74y60ht5Bqlz9+/JiYmKioqCgsLIzKWFtbk415dOzi4iIiIoL3IdmGf215Snjy5MmUKVM6dOiAYzEMExERQYri3/n8o6La1vGsnDZtWvPmzS9evPhlAuqrcnJy+FY6adKkRo0a8WRRKKFGoZMpRsnFGDKHn5+fH3bnf8b5C52UjDE3UiaZDol86vPvN9Thawvfm6GvWLGicePGly9fJgWSo3OF/vz5czJcQc7y6NGjhwwZUpHSkSFlLy8v7klnWfavv/4SEREZN24cucGEYZgaM3Ryo8uWLVu+1iiyvgahsywrJSX1tYvjcnJymA3d1dWVZ+CSDAORw0ycOFFISIhMRMuduZWkYCTrqXZMQF9fv0+fPhVdEBIS0qRJE1x/q9qqqkNgROjcu1y4e1U9K/wr+VOF/g8PzW3X15ZfvXq1YsUKV1fXjh07MgwTFhZGtqzaD8TaGOPj6hJC547xVRV6kyZNuGO1z549a9u2bdeuXZOTkzdu3Lhz505yWR/fiPkrssYJf7k1/FrzsT4qKophGDc3t6Kiou3bt+/cuZNrLh4dk4ui2Jcs8K8tTwm9evVq2rRpWFjY2rVrd+zYsW3bNu5kEfw7n39U8NSq6r+fPn2SkZHhfpCQ5WbNmpG0+h8KvWLePjk5OTIeSwYE8Hau8YzXitC5SuUJ2qq9wV3zvWPonTt3dnZ2vvHlj9zlcurUKVx6IYXfunVr3759JBMyMTFp3749WU8mO+VJRjt27Ei+F37jGPqyZcu4d8Jwm8Ndrlno5C6XAwcOcHdjWZZcFQkICCDr/f39eb6wjBkzBnOLkJFWfMTxFMVH6AsWLBAWFr5//768vDz/W+vd3d0lJCS4JX+v0PlXstohF3Fx8WozdP5DLgkJCdybW1iW/YeH5ra6xuX379/b2dkJCwuT+2T5O4UMSeOXouRtk52dTcZMzp49+/LlS54hl6oXRdetW8fNxyuyBHL5gSt0PoMYNU74+11C19HRQT5O+kpaWrrak0hmcG7evDlPl/IfIOIK/enTpzyp2ZUrV75d6PyjgqdWVf8l8R8ZGcmdgJr0fGFhYY1DLpqamugWUjgpEGeNZdmgoCBRUdEXL17Y29tzb52o8YwPGDCAJ//j9lu1Qy42NjY8Qy4/LPTnz59Xe5cL90oStz+rfiiSNTo6OtzNsPzs2bMmTZrgmxD5FOfedPj+/XsypyDZxcDAwNDQELtXzLbap08fnhELclGUTG3I3ZJnuWahX716tVmzZurq6tzbrZ48eaKurt6qVStcokxLS2MY5uzZs+QA9+/fb9GiBYR+7do1YWFhZ2dnXHIhPyVAmV+7E/nRo0ciIiLkvog1a9bw1J77Lxl14v7C6nuFzr+SHz58aN++fa1cFCUDxNwBsn946BpvW0Q/kx6bNm1ao0aNyMWJHxC6vr4+GQHLz88n0iE/MePetnjy5EmcnQ0bNjAM88svv5A15JonwzBQQ7WXGdu3b08uitY44S+P0Pnftqinp9ejRw/UjVzKg7m4WuEj9IopOnku4aK23BJevHhR8c4PDw/H4Tw9Pb9d6PyjAmV+bWH8+PHNmzfn/ryFbKmkpER+RMP/oqiRkRGPsKoKndyxl5KSIioqyr0zqsYzPnLkSHFxcW7Nuf3Gsmy3bt06duyIu+DOnz9f9aIoH6Hzv22RZVkbGxtJSUlcnyM3sG3dupVU6fXr15cuXUL56/7/38iRIxmGWbJkyZ49e7hNwDL56oPrUu/evevQoYO8vDzORXZ2NsMwuEdo7ty5DMNgvtPffvutIt8itxuhzMGDB/NMCYuXuAs1C51l2dWrVzdu3FhSUjIkJCQ/Pz80NFRKSqpp06bk3gZS3OPHj5s3by4vL5+cnBwbG9u5c2c9PT0InWXZOXPmkBuk5s2bl5mZGRQUROZmJLt/Tegsyw4YMIBhGHFxcdwUwW0AlsvKykRERLjzfH+v0GusJDkNZmZmKSkp/v7+/G9bPHPmTIsWLchtizk5ObNmzcLb49ixYxXfnmxtbZcsWVJUVESGBfn3D/9D13iXi56enq2tbUxMTF5eXmBgoKioKH6o9gNC19LSsrCwkJSUVFJSatSokbm5OfmcZhjG6O+/1q1bR0ZGRv39d+DAgcePH0tISMjKyvQ1eFoAACAASURBVM6fPz8xMVFXV1dHR4dH6ORGQB8fn9TUVHLbYk5ODjm5NU74yyN02b//EBg8C2FhYQzDuLq65uTk+Pj4tGnThs+9p18bcuFTWx4xWVpaNmvWLDg4OCMjw8HBgTR89uzZpFY1dj7/qCARjtK4LX337p24uDgu9nJfCgwMFBERefjwIcuyoaGh5F2ZkJCQmpo6duxY3NLj6ekpJCQUFRVVVFRELh1VFTrLsoqKii1btmQYhvsRXuMZJ3mAv7//8uXLN2zYUPHZydNv5LZFVVXV+Pj4yMjI9u3bS0hIIH2ssd/IBsgYuM0nyydPniQzqZJfioqJiVX9kXm1HVuxe9Wjz5kzZ9SoUSkpKRkZGX379q06fevixYsrLmkaGhqmpKRMnTq1cePGFhYW+CnGH3/8oaCg0KFDh3nz5iUlJXXu3FlKSor7Q84PHz60adMmJCSkakN41nyT0FmWPX/+vLOzc6dOnRo1akR+UVL1WS47duzQ1NRs0qSJiorK0qVLSbO5x1uzZo25uXnzv/9UVVW9vLwwCMNH6CSH8vDw4BZV7fKgQYO410V/QOgsy/KpJMuyGRkZ5EciBgYGNf6wqLS0dPDgweLi4mJiYhUPseJ+54qKipKWliadidHqHz50jULPzs62tLRs27Ytuat62rRpuImlanTyDEdydUle2rdvn4eHR9OmTRmGGTlyJO4tq/abaVRUVMVXyEOHDhkbGzdt2lRKSiooKGj79u08QtfQ0Dhx4gT5YZGsrGxaWhr3FPOf8Jdbw2+5bTEwMFBSUrJp06ZmZmaHDx/m8+uwrwmdT215xHT37l0SA61btx4+fDgZTIApaux8/gFJfpHIMzhL+m3NmjXce/m5nfnLL78wDLNgwQKysqCggDyEREJCwsrKaufOnWR9WVmZnZ0dkTX5BlOt0IODg8nFdu4hajzjr169cnZ2FhcXr5g7+2s/LNq1axd51kqrVq0GDhxY9YdFyKArTjpP0JKO5SN0lmUPHDhgamoqJibWvn17Ly8vZOsV7yY+n5QVzax61jZt2tS9e/eWLVs2a9bM2NgYqTe3T4qKinR0dMjvy7y9vbmHY1n2zp07w4YNa9WqVYsWLQYMGIAHUpESyC0uPCu5hWP5W4WOHViWXbx4sZCQ0JgxY7grf95ySUlJ1ZtGqz3c/v37GzVqxJ1zvdrN6Mof7gHytiHfDZ8/f96mTRvusxbID1KaNm16//79Hz6E4O/IJ/n4lys/bdo0GRkZ/t9c/+Uq0cP9jB6wt7ev9stW1WP9iNBZliWDPtynDVQturbW2NnZycvLcwff+ZRsY2Pzbz4+l09N6uVLXKGTMOB5fK6xsTH3F9X1shMER+gGBgbcMcZ62du0URcvXqz9x+fWSbcWFRWRXyTi62GdVIMeFD3AI3Ssb1ALgiP0BtXttLHf0gM/mKF/S9H/fBuGYcgTc7g/CPrnxdISfrgHqND53GL7w71Kd6Q9UFs9INBCr61G0nJoD9AeoD3QEHqACr0hnGXaRtoDtAcaRA9QoTeI00wbSXuA9kBD6AEq9IZwlmkbaQ/QHmgQPVD3Qi/Y83slO68UfCF++X4QXbADLN/3O9hy5jHYef4p2PfbC3D46ktw8vprcPb3V+DUlXJw5d5zcKPsBbhT/ge4/+Q14cK1O+D2w+fgwdPXoPzZO/D4xXtQ9uwlePTiZbU8/uM1uP2gHNwvfwaevnwLyp68AHcfPAJPnr0ET1+8AQ0ixn9CI4cEegNjh56g/3gnoGuhBazs+wEzJwfgm5IOxodHA7/UXBC7YR9YsOcMCCvaBEKKNoCw4l1g7vZLIPlIGWHBkTtg3i8XwaxV28GEuXGgt/NgMGDCGODg6wMCFxaD1NOPQPKJskp+vZb8hamLS0Bk8Q4QtfkUSDleDtKOPQI/4XzWnyKp0D9rHTY/daUcNr9y7zlsfqPsBWx+p/wPKvT68w74oZbA5kMCvWFzY4eesHn/8U6wua6FFmxuZd8PNjdzcoDNfVPSYfPx4dGwuV9qLmweu2EfbL5gzxnYPKxoE2weUrQBNg8r3gWbz91+iQr9h071f2wnKnQq9P9YyApCdanQB0wYg/TcwdcH6XngwmKk56mnH1Wm5yfKkJ4n/3oN6fnUxSVIzyOLdyA9j9p8Cul5yvFypOdpxx4JQgAIbB2o0KnQBTY4BbdiVOhU6IIZnXUv9OIj98Dqw7dBZslRELdoG1h7+AbYd/k5OHTlOTh85Sk4deMluHTvLbh87zU4d7UM3Hr4EmAc/MHT1w+fVfLk5TvC1Vv3wd1Hz0DZ05fgj9d/gtdv/wSPnjwFj589BX+8fgVevH4H7j58DMqfvQQv3/0FHj5+DsrKHoM3bz5U8vbPN18QzKAU/Frp2WgBJR0JoKbbCShptAeqekpA0UgZ9B01DFg79AO2Y4aDId6TgI37WGDtNAD0dRkJHAOmgaCclSBq02FC5NodYGx0PBjs5w1MBlqA7j10gFEvY6DZwxC4x8aAvFN3QPqJxyC25AjoNc4VuAYHAO+kfJBx+AFIPnALCH541GENqdA/ax02P3e1DDa/9fAlFXodhqYgHxo217PRgs2VdCRgczXdTrC5kkZ72FxVTwk2VzRShs37jhoGm1s79IPNbccMh82HeE+CzW3cx8Lm1k4DYPO+LiNhc8eAabB5UM5KKnRBjqjaqhsVOhV6bcVSAyqHCt2olzHSc80ehkjP3WNjkJ7nnbqD9Dz9xGOk57ElR5Ce9xrnivTcNTgA6bl3Uj7S84zDD5CeJx+41YDi7PubSoVOhf79UdPg96BCp0IXzDdB3Qt97dFboOTI7yB/42GQuGQz2Hz0Kjh67Sk4deMZOHzxLjh7vRzcePgKXLn9GJRevQtu3isH9x894/D0/qP/8ezVW8L12/cABrjvPnz88OkL8OzlG1BW/hhcuHgJPH5UBl6+eAZev30HHjwsB0+f/wHeffgLPHn6Aty/VwY+vP8TvH71FghmUAp+rfQs1YCSqjhQVW0PZBVbA3k1SdBZVRwo6sgBZS0ZoKovV4mxouoX1EzlgaaJDNDroQmM+5kByyF2YPDkCQR7N2egaawFVPXlgbKuFFDU6ABUdGSBjLoUMHHoB4IyF4Lgwq1genohUDBQA/q9tIC9xwSQvuM48MtaDgQ/POqwhlTon7UOm5devQub37xXzrH5M9j8/qOnVOh1GLKCcGjYXM9SDTZXUhWHzVVV28PmsoqtYXN5NUnYvLOqOGyuqCMHmytryVTaXF8ONlc1VoTN1UzlYXNNExnYXK+HJmxu3M8MNrccYkeFLgiR87PrQIVOhf6zY6welk+FrqIji/RcRl0K6bmJQz+k50GZC5GeBxduRXo+Pb0Q6bmCgRrSc/1eWkjP7T0mID1P33Ec6blf1vJ6GE+11yQqdCr02oumBlMSFToVumAGe90LfdPx38GGw7+BRRv3g9SlG8GOoxfB8ct3QemtcnD68i1w8cY9cLf8Gbh+5z64ePk6uHb9FnhQ9hjcuH0fPH/1lnDz7n2AB6fcffDo4ZPn4G75U7B+2w6wel0JuH/3Hnj54gV4x/krK3sInj59Bj58+BM8ffIU3L1zF7x/+w68+uMlEMygFPxaKWhJAxlFcSAtLw46ybcCcqqSQFa1JZCUbQ6k5FoCOfU2QLFbe6Bh0hHomXYEanqSQEVfBijodAJ97EwJo13sgaPTAGBsrgk6dm0FOsi1BtJKbUFHeQkgrSIF1Ex0gan9QODoPRlIK0sCOeW2QMdKBwyYMBqYD7YFgh8edVhDKvTPWofNL16+Dptfu34LNn9Q9hg2v3H7PhV6HYasIBwaNlfQkobNZRQrbS4tLw6bd5JvBZvLqUrC5rKqLWFzSdnmsLmUXEvYXE69DWyu2K09bK5hUmlzPdOOsLmaniRsrqIvA5sr6HSiQheEyPnZdaBCp0L/2TFWD8unQpdWaov0vKO8BNJzaRUppOdqJrpIz03tByI9d/SejPRcWlkS6bmccluk5zpWOkjPB0wYjfTcfLBtPYyn2msSFToVeu1FU4MpiQqdCl0wg73uhb7j9A2w/cRlsGzzPpC6eDXYffQcOHHxOrh86wE4feEyOH/pCnjwpBz8fvsWuHjpErhy+Sp4cK8MnC+9CMofPyXcvnMP3Lx1B5Q9fgpKb90FC4tLwIq1G8DNm/fAk8fPwFvO3wPOX3n5I/DmzWtQ9uABePSgDLx7/Qb88ew5EMygFPxadVYQB9IKLYGMYivQqWtrICUvAbooNANySh2AjGpnIKXaBsjrtgVKem3BwBEWQNtEAciotwL6Vkpgeog/Yd361ZWsW7vuC5GxkUBZTwl01pECcgYyoINyOyCt1BF0VesIZFU7AOM+hkBDXxl0Ve4EOmt2BO2UxIG8tjQQ/PCowxpSoX/WOmx+8dIl2PzK5auw+YN7ZbD5+dKLVOh1GLKCcGjYvLOCOGwurdASNpdRbAWbd+raGjaXkpeAzbsoNIPN5ZQ6wOYyqp1hcynVNrC5vG6lzZX02sLmA0dYwObaJgqwuYx6K9hc30qJCl0QIudn14EKnQr9Z8dYPSyfCl3OQAbpeQfldkjPpZUq0/Ouah2RnsuqdkB6btzHEOm5hr4y0vOuyp2QnnfW7Ij0vJ2SONJzeW3pehhPtdckKnQq9NqLpgZTEhU6FbpgBnvdC33fmWtgz8kLoHjrXpCYsxTsPXoKHC+9AK7evgXOX7oALl25CL48i+Xzz/iv37gCLl66WC13790Bhw8fASdPniKcPnsGnDpzCpQ/ewL2nTgN/EIiQUHRGvD7nfvg/sOH4PWbV+DevVuA09arL56Vgbu3r4MH9x+Aly/+AOVl94FgBqXg16qriiyQUegEJOXbAykFSdBaSgx07CoB+gx0AHYjR4NuZlpAu7sM6KLQAnQ31gCOox2Ab5AnyFuWD3YfOEI4e+4qOHLwOJgbEwf6DewF5PXbgY46rYCyUVfQzVQFGFqoArOemsCqtzbo0UsbGJurAgNTZaCqIwV0jeSB4IdHHdaQCv2z1qu1+cVLF2Hzu/fuwOaHDx+hQq/DkBWEQ8PmXVVkYXMZhU6wuaR8e9hcSkESNm8tJQabd+wqAZv3GegAm9uNHA2bdzPTgs21u8vA5l0UWsDm3Y01YHPH0Q6wuW+QJ2yetyyfCl0QIudn14EKnQr9Z8dYPSyfCr2jTiuk58pGXZGedzNVQXpuaKGK9NyspybSc6velel5j17aSM+NzVWRnhuYKiM9V9WRQnquayRfD+Op9ppEhU6FXnvR1GBKokKnQhfMYK97oR88UQr2Hj4GVm/cDmLiM8De/QfBseNHwe/XL4PLF86AG1fPg/KHV8GV386Ai6XnwaXfSgHncS/Xd+3aDkpK1hF27tkJdvyyG5wsPQd2/nIIzIiIA3GZ+WD11m1g656d4OrN6+DGzWvgt4unQPm9K+D21bPg1u9XwfPyB6D85m9AMINS8GulZ6QDFLUUgZymPFDXUwE6xorAuEc3MNHbB3h7BQE7m17AxrobsOupBYbYGYLIkCCwcfUOsHTxBpCZU0hYuXIz2LBxO0hLSgETXZ1ADwtFYGYqBxwGGYFRTj2Ak2MP4OraH0wYZwMmju0NJrn0Bu6jLIHLMCPgOtIcCH541GENqdA/ax02v1h6Hja/9FspFXodhqYgHxo21zPSgc0VtRRhczlNedhcXU8FNtcxVoTNjXt0g80nevvA5t5eQbC5nU0v2NzGuhtsbtdTCzYfYmcIm0eGBMHmG1fvgM2XLt5AhS7IEVVbdaNCp0KvrVhqQOVQoZuZyiE9dxhkhPR8lFNleu7k2APpuatrf6TnE8bZID2fOLYyPZ/k0hvpufsoS6TnLsOMkJ67jjRvQHH2/U2lQqdC//6oafB7UKFToQvmm6DuhX7i5Hlw6NejYO26jSBhXio4/sshcOX4CXDz1KlKThy/+YWy0jPgyY1z4NqZXys5d/IauHDq2heu/3YKHD38Czh56jhh9YaNYF56LnD3nwWGjvEE/Ya7A0uHscDawRGY9+kPJnn7gi1bt4Kzp46Bu79fAlfO/ApKD20Hz66fAo9L9wHBDErBr1XMNCcQHjQGRAVPAPNjA0BqYiDIXBAEFubMB/EJ6SAsJBTkZcwHi3PnVbIwafEX4uPmgrCQeBAVuQDEzUslJCRmgxlhkWBWSDCYHRwIIoM9QUKEH0iO9AGZcb6VJEzN/EJ6wjSQmjizWnIWBIOC1GCwMC0E5KaEAcEPjzqsIRX631qHzc+dhM2vXai0+fXfTsHmRw//QoVehyErCIeGzWOmOcHm4UFjYPOo4Amw+fzYANg8NTEQNs9cEASbL8yZD5vHJ6TD5mEhobB5Xsb8SpvnzoPNFy9Mgs3j4+bC5mEh8bB5VOQCKnRBiJyfXQcqdCr0nx1j9bB8KvSECD+k58mRPpXpeZwv0vPMhKlIz9MTplWbnqcmzkR6nrOgMj0vSA1Ger4wLQTpeW5KWD2Mp9prEhU6FXrtRVODKYkKnQpdMIO97oW+bs1GULxiDcjPWQTiYhJAybJisGP1OrBu0WJwaONGcHbPTlC6fxs4tXsTOHdgNyg9fAAc3bsd7Nu3o5JfD+77m8SshWDyzDjg5BUORnmHg2GTwsDQSWFg7JRw0MfeGQwa4ghmzgoBSxYWgK3rVoO1hXmgMD0OnN5TAg6sWwgEMygFv1aJyZEgITEapGUmg9ylSypZtiS3koW5y/5HVuEiUFBcAhLSskFmbjrIykkGGTnZIGLuHOA5NRBMmTED+E0LJSSk5IGY+CTgMtEd2I+wBzNm+YHw0EAwxcMRzA3xBGlzpoL8pFkgPTkCJCZFg4T50WBufBSYMy8KzE+KB4IfHnVYQyr0z1qHzc8d2A2blx4+AJsf3bu90ub7dhCb7/v1IGyemLUQNp88Mw42d/KqtPko73DYfBjH5kMnhcHmY6eEw+Z97J1h80FDHGHzmbNCYPMlCwtg863rVsPmawvzYPPC9DjY/PSeEtj8wLqFdRh5/+lDw+aJyZGweUJiNGyelplcafOlXJsvgc1zly2EzbMKF8HmBcUlsHlCWjZsnpmbDptn5STD5hk52bB5xNw5sLnn1EDYfMqMGVTo/+mQ+8bKU6FToX9jqNDNKnuACj08NBDp+RQPR6Tnc0M8kZ6nzZmK9Dw/aRbS8/TkCKTniUmV6XnC/Gik53PjK9PzOfOikJ7PT4qvPA10qUoPUKFToVcJCrqiph6gQqdCrylG6ub1uhd6QGAwCJwaBvwDgsGkyX5gsk8A8JoSAHz9AkD47HAQPycWpMyNBZkJcSA3NRnkZ2aB1KQUkFmwCGQsLiIExaYC9+nxYPyMZA4J42f8j+HekWCEd1QlHjNGfGHo6EkgPikdhIdHgZzMDJC9YD4ImuIJfDwng+jIcBA8Yxqom6D77x91zJQAMDlwOohLTAHxSWlgTnwSiEtKBBFxMSB/xRqwdfdhsCAlBcTNDQNzYsLA9OnTwIxZIWBmRBRIXbiUsP/YebB2/RaQlJICEpIWgMVLloLs7CwwduxoMNCuLwgJmAiSZ/uCeaHeIDJ4CgiPCAZhsbHAf2YoCJkdAf774fMTW0CF/lnrsHluajJsnp+ZBZunJqXA5pkFi6jQf2JI/heKhs3HTAmAzScHTofN4xJTYPP4pDTYfE58Emwel5QIm0fExcDm+SvWwOZbdx+GzRekpMDmcXMrbT4nJgw2nz59Gmw+Y1YIbD4zIooK/b8QWf+0jlToVOj/NIYa4P5U6NnZWUjPx44djfR8oF1fpOchARORnifP9kV6Pi/UG+l5ZPAUpOfhEcFIz8NiY5Ge+88MRXoeMjuiAcbbtzeZCp0K/dujhW75vx6gQqdCF8w3Q90LvecgJzBgpAewG+EGeg9xBEPHewHnyYFg2LhJwNndE4yZ4AU8fYKAh6c/mOgbCDwDgoFXUCwIiM4E3rNTCM4+4RxmO/v8j1FTZoPhXjOAjasv6DlyEnDxngUCpoeD8OhYMMV3CkhNjgeH924BoTMCwETfaWC0hw8YO8kPCGZQCn6tzG0GgYmTJoK8pDlg0bzQSpKjFn1hYUYUSIibCtJy8sHxc1fB2tXFICkyAKTGTAOxM6aA+NBZICIsFGQWLifs+fUM2LX3ONi09RcQMzcKxMfPBfPj5oPszEwwJyYKzI8JBXEhgaAgJQ7s2rQGnDh+DOzYux9EzosD8+ZEAcEPjzqsIRX6Z63D5hN9A2Fzz4Bg2NwrKBY2D4jOpEKvw5AVhEPD5uY2g2DziZMmwuZ5SXMqbT4vFDZflFxp84UZUbB5QtxU2DwtJx82P37uKmy+dnUxbJ4UGQCbp8ZMg81jZ0yBzeNDZ8HmEWGhVOiCEDk/uw5U6FToPzvG6mH5VOjz4+YjPc/OzER6PicmCun5/JhQpOdxIYFIzwtS4pCe79q0Bun5iePHkJ7v2Lsf6XnkvDik5/PmRNXDeKq9JlGhU6HXXjQ1mJKo0KnQBTPY617ohraOwHr4JGDnMgUMdPMEvuGJwHNWHBju5g/6Dh4LxkyaCvwjUoCL/2wwJjAUeEengcD4ZcArdhkYF5xJcJuRCFwCI4Hb1Nlg3PTZwNk/GAyfFADSC5aBnbv3go1bN4GUtETg5+MOThzaBnLSE4DLRB8wcrw3GD7eGwhmUAp+rQx62YCw0OkgLcoXJM50AXEzJ4CUSD+QHO4H5s5PBFsPHgMHDu4DcbO8OUyJm/U/EsICQErUdDA3IhikZOcTVm/cBZYVbwfL1+wCUfOjQWpGUiXzU1O/EBk8C+RlpoFdW9eDY4cOgls374LzpZfB8uL1YHpYDHCb5AFmTfEGgh8edVhDKvTPWofNxwSGwube0WmweWB8pc29YpdRoddhyArCoWFzg142sHlY6HTYPC3KFzZPnOkCm8fNnACbp0RW2jw53A82nzs/ETbfevAYbH7g4D6Ozb1h87hZU2DzhLAA2DwlajpsPjcimApdECLnZ9eBCp0K/WfHWD0snwo9dX4q0vPI4FlIz/My05Ce79q6Hun5sUMHkZ7funkX6fn50stIz5cXr0d6Pj0sBum52yQPpOezpnjXw3iqvSZRoVOh1140NZiSqNCp0AUz2Ote6KaD3cEIr0gw1j8a2I6ZBNynRVQSGOn+hYFjfMBwjyAwIy4HxGStArPTVwDvqEwwOTIXTJm7DLiF5oCR/vGEwd6RHEIHe/+PkQERwCU4oZKgWJcv+M2OA8XrNoID+/eBM6eOg327t4PZQX5gzZIssKFoEXBwGAaGu00G9hN8gGAGpeDXSsfIArg5DwUzx9qCJI9hIGDEAOA+wh6McxwC/PymguzFq8GxUxfBhnVrQXRkBJjgPh64jXMF4ydMBOl5hYQd+46ArXsOgoPHL4FlqzeAsIgYkJKcARLnLwARkTFgbck6cPjICXDg8GngMzUUqOlbAjlNY6Cirg8M1fSB4IdHHdaQCv2z1mFz76hM2HxyZC5sPmXuMtjcLTSHCr0OQ1YQDg2b6xhZwOZuzkNh85ljbWHzJI9hsHnAiAGwufsIe9h8nOMQ2NzPbypsnr14NWx+7NRF2HzDurWweXRkBGw+wX08bO42zhU2Hz9hIhW6IETOz64DFToV+s+OsXpYPhV6SnIG0vPE+QuQnkdExiA9X1uyDun54SMnkJ4fOHwa6bnP1FCk52r6lkjP5TSNkZ6rqFem54Zq+vUwnmqvSVToVOi1F00NpiQqdCp0wQz2uhe67bgZwGlKLBjpGQbsxniCIW7+oPewCaCfkzdwcJ8JnKZEgYnBC0DQvMXAN3YhmBCWDTyjFoPJkQXALSSd4BqcAtxmp1YStsDtCz5zckFAbAZIzF4MNm3eArZtWg/2btsMftm6GSzKTAPRs4JA8aJ84DDQAXB/CNPLyRUIZlAKfq0UlU2AsaYB6KnYFYzTNQC9NAxBVzV90FZRHdjZDQXeAbPBouWbwanS38Gxc1fA6k27QGxiOsgtXAX2HDpFOHTyPDh3+SrYdeAYyMwvBkmpuSA2Lh5EzUkCIZHzgE/gdDDazQvMipwPets7A0llAyCva12JjpX8F5TUTYHgh0cd1pAK/bPWYXPf2IWw+YSwbNjcM2oxbD45soAKvQ5DVhAODZsrKpvA5saaBrB5T8WusPk4XQPYvJeGIWzeVU0fNm+rqA6b29kNhc29A2bD5ouWb4bNT5X+DpsfO3cFNl+9aRdsHpuYDpvnFq6iQheEyPnZdaBCp0L/2TFWD8unQo+Ni0d6HjUnCel5SOQ8pOc+gdORno9280J6PityPtLz3vbOSM8llQ0q03Nda6Tn8jpWSM+V1E3rYTzVXpOo0KnQay+aGkxJVOhU6IIZ7HUv9IEes4H9hHAwxCMUDBoXAOxdpgIbR3/Q1zEQjPCKBT6RC8HMxBUgIrMExBRsA3GFe8DcpXvBnMV7QFT+dkLKqkMgbc1BkFK8B2Ss3AbSlqwGhSvXgI3r14HNa1eA7SWrQMmKZaB4aSGY4DYeOI8cCfr37QeMrHoBM7vBQDCDUvBrpahuCdTVTSuRV1P/grKiGuiqbAC6yBsBeXlDYGLeD4zz8AdLVmwCh09fAacv3wInLv4ODpy8AA6evAh2HzxF2LzrV7Bz33GwZMUGMMl7DvCflgzGecwCg4Z4gNDoeLBlzz6wfts+sHL9ThAckwS0TPoAWW1zIKNjDeT0+wDBD486rCEV+metw+YxBdtg87jCPbD53KV7YfM5i/dQoddhyArCoWFzRXXLSpurm8Lm6vKVNldWVIPNuyobwOZd5I1gc3l5Q9jcxLwfbD7Owx82X7JiE2x++PQV2Pz05Vuw+YmLv8PmB05egM0PnrxIhS4IkfOz60CFToX+s2OsHpZPhT7OYxbS80FDPJCeh0bHIz3fsqcyPV+/bR/S85XrdyI9D45JQnquZdIH6bmstjnScxkda6Tncvp93800UwAAGqJJREFU6mE81V6TqNCp0GsvmhpMSVToVOiCGex1L3TX4EwwNigdeM7OAZNCFgCfsGwQlbYRRGdtA/MW7QPJRUdB1rqTIHfjaZCz6QzI3Xq2km3ncr9QsL0UpK09QshY8yvI33AU5K07AFIWrQLTw2NBZMwckJIYD1YuzgXrVy4DK5YsBkXLV4DJ3v6gT9/+wM1lNBjh5AxshowAghmUgl+rqKQMEJdeAFJyCkDu4qUgf9kaULi8BKxataWSjbtXfWH7L4fBlRv3wY17T8C122Xg8s374Lff74KLV++A0t/uEpYX7wT2QyaDsa4zgbHhJKDYdTSQlR0CnMeEgZMXLoObZY/A3ccvwb3yV+DyjQdg486DYHrEfGDW1xmoGNkBwQ+POqwhFfpnrcPmOZvOVNp861nYPHfbOdi8YHspFXodhqwgHBo2j0rKgM3j0ittnpJTAJvnLl4Km+cvWwObFy4vqbT5qi2w+aqNu2Hz7b8chs2v3LgPm9+49wQ2v3a7DDa/fPM+bP7b73dh84tX71ChC0Lk/Ow6UKFTof/sGKuH5VOhy8oOQXruPCYM6fnJC5eRnt8se4T0/O7jl0jP75W/Qnp++cYDpOcbdx5Eej49Yj7Sc7O+zkjPVYzs6mE81V6T6l7onjHLwITQhSBwXhGIyioBEWnrwJyc7SB5+a8gqegoSCk+CTLWngE5G89VsuVcDth+LucL2dvPgMzNR0Hyqj2EyKxiEJtVDOJzVoLZ8WlgrIc3mDZjFkhJTgQLc7NB0bIiULhkGVhSWASi5yaC5AWp4Jedm0FOdhaY7O0Lai+QGlZJxy9cAUfP/gZ+PX4OHDpyAuw9dARsP3AIbN6zD6zfuhesXLsZLCosBlm5S0BqWi5ImJ8G4hNSQWzsAhATnU4Ij0wDU2ckgJDZmcDE2BO0lRgODIw9wZrNJ8Ct+8/BlZsPwcXb5eDynafg5r3noOzxW3D3wXMQn5gHVHV7goYVat/ZWir0v7UOm2+ptHnO9nOwefb2M7B55uajVOjfGWb1bXPY/PiFK7D50bO/wea/Hj8Hmx86cgI233voCGy+/cAh2Hzznn2w+fqte2HzlWs3w+aLCoth86zcJbB5aloubJ4wPw02j09Ihc1jYxdQode3KKyuPVToVOjVxQVdx7cHqNANjD2Rnq/ZfALp+a37z5GeX7n5EOn5xdvlSM8v33mK9PzmvedIz8sev0V6fvfBc6Tn8Yl5SM9VdXvyPTMN/UUqdCr0hv4e+IH2U6FTof9A2PwLu9S90F1C8oF3TDEImr8W+ETlA5ep88GYgCQQkbUFLCg+BtLXnQGZ686DjJKzIHnNMRBbtBeELdoMZuUUgeDMJYRZybkgJmMRyF2xAaQtWgmiElJBalY+WLKsCOQVLAL5hStBZu4SkJ23GKRn5oGFBQVgaUEGyM/KAGmpaeBfiLB6eYigqDiwbd8R4Ok/A1j2seXQ37LP/zCy7AW6GZkDNR0joKxpAORVuwGZrmpAsosKwEqZrmrYWF61m7a2EbA2tiY4DXYGgV5Tga/PDNDHdhxQ1x0MnCbMBAWrt4E1Ww+DbfvPge3HL4Ndp6+A/WeugJOXb4HLt8tA4MxIoKRtDuplRNVWo6jQP2sdNk9ecww2jy3aC5uHLdoMm8/KKaJCr634+4+WA5sHRcXB5tv2HYHNPf1ncGxuC5tb9ukPmxtZ9oLNuxmZw+ZqOkawubKmAVfQXHHD5pJdVLjrudvD5traRlTo/9Fg+65qU6FToX9XwNCNP/cAFbrThJlIzwtWb0N6vmbrYaTn2/afQ3q+/fhlpOe7Tlem5/vPXEF6fvLyLaTnl2+XIT0PnBmJ9FxJ25yGIJ8eoEKnQucTHvSl6nuACp0KvfrIqOu1dS90j4glwMk/DfR3DQd9x8wEI6bMA75zloLgtPUgYel+kLTyMIhYuAvMyNgApqWsAjPSikFY9moQs3A1mL+shJBRvAkkLloBsleUgIWrN4PMxcUgf+kasGzFOrB46WqQvWgFyCpYBnIKCkFySgaIio4BM2cGgVDOX3pGNqjr8PuvHn+QkwvYc+gEGOroCpq37gjadOgCxNvJgObinSpp17n5F1p2kAVY2bxd5xYdugCJLkqgs7oukNM2BMpaekBLTZNgYWgChtsMAmNthoOJ/Z3ApIEjgd9wdzB9cgjw9wwBgZNDKvEND/yCX8gc4BUcDYLjkkFsShYYNGIsUNKxAP/VoPlX6k2F/lnrsPm0lFWw+Yy0Ytg8LLvS5jELV1Oh/yvBKbgHgc0HObnA5nsOnYDNhzq6wubNW3eEzdt06AKbi7eTqbS5eCeuuGHzlh1kueth8xYdusDmEl2UYPPO6rqwuZy2IWyurKVHhS648VR7NaNCp0KvvWhqMCVRofsNd0d6Pn1yZXru78lJzyeHID0P9A1Heu4XMgfpuVdwNNLz4LhkpOexKVlIzweNGIv0XEnHosFE2Y80lAqdCv1H4qaB70OFToUumG+Buhf6CL8kYDF8GujnOhtMmbMchOfuAvOWHQKReTtAcGoJCEpcCbznF4KgzFUgetEGkFS0HWSt2QPy1u4F2at2ENKLNoG43GVgwZLVIGfFepBduAbkLF4NFhWuA0uXbwBZBUtBcmYeCI2cCyb7TgWj3SYCuyEjwYjRbiB6XjIQzKAU/FqZm/UFCXNTwUCbYaClhDRoJ6UAOkgrAUk5NdBFXR/IahoCOU1DoKhrCpS7WwIV4x5AzbQnUDW2Boo6poQuynqgq6Iu0O7WAxiZ9gbmVtZg4CAn4DXGGwSOGA9i3AMqmTQt5gt+XjOAs6sPcBzlASZM9AMOjq5ASdcSCH541GENqdA/ax02j160ATZPKtoOm2et2QOb563dS4VehyErCIeGzc3N+sLmCXNTYfOBNsNg85YS0rB5OykF2LyDtBJsLimnBpt3UdeHzWU5NpfTNITNFXVNYXPl7pawuYpxD9hczbQnbK5qbE2FLgiR87PrQIVOhf6zY6welk+FPnCQE9JzrzHeSM8DR4yvTM/dA5Cex0yahvTcz2sG0nNnVx+k546jPJCeT5joh/TcwdEV6bmSrmU9jKfaaxIVOhV67UVTgymJCp0KXTCDve6FPilmOZgYvQx4zVkBApJKQGBSCZiatBYEZ2wEQYnFYOq8pSB28TYwf+UekLxqN0hauR3MX7YZxGSuANNiMwhuUyOAk1cQiEzLBxlL14DMwjUgp3ANyFq4CizIWgKmhccAV28/4OzhCRxGuQBrOwfQb9Aw0N9hBLC2GQQEMygFv1YW1rZg2fJ1wN3dF3TsqgG4wykqemZAy6Qn0DDrA7hDJapG1kDNpBdQMbYG8voWoKueGZDVMQXSGqYEGS0zoKBvDVQsbICiRV/QRd8SqJj0BmaDhoDeQ4eBAUNHgoEjnIHtkNGVOIyx/cIwRzcw0N4RGPXsDzRM+gDBD486rCEV+metw+bJq3bD5kkrt8Pm85dths1jMldQoddhyArCoWFzC2tb2HzZ8nWwubu7L2zesasGFfrAEc6VNh8yGja3dRgDmw9zdIPNB9o7wuZGPfvD5homfQQhAAS2DlToVOgCG5yCWzEqdBWT3kjPzQYNQXree+gwpOcDho5Eek6F/u9EMxU6Ffq/E2n16ihU6FToghnQdS/08dHLgFfCauCbvL6SpHW+XwhIXgump5aA0MyNICyjBEyLXwpCU1ZVkrYq9AsROWtA1MJ1IDJvFRg1JQxYDBpLMLFzBMa2w0FgdCJIK1wN4rOXgMikLBAQNhe4+EwDIyZ6g6Huk0B/57HAdIADMLezB3ZDHIG+iRWQ7qoCBDMoBb9Wyt3NgKOHN7C0Gww6a3UHit2tgKZFX6Bh3gdgA8XuVvIGFkDB0BLI65kDBV0LoKhnCbrqmIEuGt2BnLohQdnAEmhY9APqVn0qMe+tDoxt1L+gpGcG5PVMgKKuBZBXMwKKmqZA06Q30LO2Bd172QFd815Ay7wXUDXqDQQ/POqwhlTon7UOm0fkrIHNoxaug80j81bB5qOmhFGh12HICsKhYXPl7mawuaOHN2xuaTcYNu+s1Z0ra9hc06IvbK5h3oe7DWwub2ABmysYWsLm8nrmsLmCrgVsrqhnCZt31TGDzbtodKdCF4TI+dl1oEKnQv/ZMVYPy6dCV9IzQ3our2eC9FxR1wLpubyaEdJzRU1TpOeaJr2RnutZ2yI9797LDum5Lic91zLvhfRc1ah3PYyn2msSFToVeu1FU4MpiQqdCl0wg73uhW45NgRMilsOpqZtAAEp68DUlHVg2oI1wCMiB4wKjAfDPCPBYI8wMGj8LOA3JwfE5K8FkTkrgWtAFBgwxpswdEIAGDEpAHiFxgLvkBjg6j8TOHr6g6EePmDwBG/Q19EFWNiPAPp97ICWVR9g0Ks/0DY0A12UNEAnWWUgmEEp+LWSVtcFUqo6QEZdD8jqmgM1835Aw7I/UDbuCbrqmYLO2oZAWssAyOoYAWW9HkDFwBrIaZkBGRV9IK/ZnaBu3AtoWw0E6uZ9gaqRJdAw7QkU9UxAZ3U9IK9tBFT0zYGCtjHABvLaRmoGFkDTyAqoG1oANeNeQNO8PxD88KjDGlKhf9Y6bO43Jwc2j8lfC5tH5qyEzV0DoqjQ6zBkBeHQsLm0ui5sLqWqA5vLqOvB5rK65rC5mnk/2FzDsj9srmzcEzbvqmcKm3fWNoTNpbUMYHNZHSPYXFmvB2yuYmANm8tpmcHmMir6VOiCEDk/uw5U6FToPzvG6mH5VOiKeiZIzzur63Gzb6TnKvrmSM8VtI252yA9VzOwQHquaWSF9Fzd0ALpuZpxL6Tnmub962E81V6TqNCp0GsvmhpMSVToVOiCGex1L3STEb7ANTQDeMYuApNjFwKvuEIwKaYAWI+eCgwHugOzIZNADyc/0Ht0IJgSlQnmZK8GMRkrQGB0OnALjCI4ek4H9uO8wCBXT+AwzhMMHu8JHCZ4g74u7sDIfhjQNO8DdHv0B1rmvYGaiTWQ1zECXZQ1gbS8KugkqwQEMygFv1ZSat2AnHZ3oGxgDtTN+gJNS1ugZtYPKBn1BPL6pkBGywB00ekOFA3MgaphT6CkZwVkNU2BnLYpwCN2Na1sgUaPgUDVrA9AK5QNzDForqhnIq2mC9rLqwMpFR0gq2kAuFm8lJI2kFHWAfKahkBR2whw78tUM+kLBD886rCGVOiftQ6bT4nKhM3nZK+GzWMyVsDmgdHpVOh1GLKCcGjYXEqtG2wup92d60HYXN2sL2yuaWkLm6uZ9YPNlYx6wuby+qawuYyWAWzeRac7bK5oYA6bqxr2hM2V9Kxgc1nNSpvLaZtSoQtC5PzsOlChU6H/7Birh+VToUur6SI9by+vjvRcSkUH6bmspgHN0P/l6KdCp0L/l0OuPhyOCp0KXTDjuO6Fbu3sD5ynzgOTIjLB5Kgc4BO3uJJ5S3y+YO8ZDvqPmw6Ge0cAx6lzgVtIMvAMSwFu/tFgqEsA6D1sArAe6kbo6zQB2I6eCAa7+YAh7t7AZvR4oG/rANR62QDNPnbAwnY4MOo5EKjoWwAFbVMgp2EAuihrAWkFNSAppwIEMygFv1aK+uZAydASqJv0AprmNkDdpG8lpv3Uv6Bq3BsoGFgA7i2MWKlgYKFq3BOoGfcBinpWQF7XEqiZ9gXa1nYELesBQNmsD1AytAKKOsbg/9q7tx83zjIA4xdtmiAoFRCa9Wlsz3nGY3tm7Jmxx+fTrndzDmlSSGkpoS30AgFCiIsKJNQL7pAQEhL/bNGy3ccDcm9aqf5MX+l3sbKSzKdv331kfZkdV50Qb+p+QfCm/rma14PWSlDz+ztuXLvGAXrV7lasDmpuBK09gNGbQ/3xOOAKJeiXWafmH//p79T857/9lJr/6L3fUfP10w8k6AccWRUuTc3N3piaW8mUmvvDFTUPxttdzYen1NzPz6i5O1gXwy1Br7kRNdfaA2pu9OYqDICya5CgS9CVHU51FyZB/8/7dHmHrtyIStAl6MoNpfoLkqBL0NWc0sMHffXO7/H8N3/Fr/7yL3z053/iw0/+gZd//Bve/vWnePzhJ7j3/h+w+clHGD16geG958jvPsPs0Qssn77E6YsPrmzf+wDrH7/E9PG7SM+foLPYorvYIlpdIJhsMNg8QCdfQ/P7qLoxan4PJTfEidGFZoVQcyjVX1Vrco5ger4z2QbX/MEGTrLcy+rP0YwmaIRj6PEUVrqEna3Ai1a65NDcy0+7i/vozO9f8UdnaHSHqHkxNDdCSW/tVfcTFJ9DYEVT1FsDaF4PxTP0khHsVfVTWMkK6o/HAVcoQb/MOjUf3ntOzfO7z6j57NELar58+lKCfsCRVeHS1Lw1KdR8ek7Ng8mWmvuDzd6aO8mSmlv9OTVvRhNq3gjH1FyPp8VwU3M7WxVfl6CrMCGHWoMEXYJ+qNk74utK0Et6i7fndT+Rd+iKTLMEXYKuyCge0zIk6BJ0Nef18EFP7/0M+cNfYPHsY+QPXiK7eAfx5hna8ycIZo/RWTxB7/QhsovHyO8/xfTxc8yfvABn4tPH7+aP3r7SO78Pe7SGla0Rru+Bg/JodRHOtvDTOex4BC+dodFOUXEjcIBedWOes1HxIg7QS25YdfqoWyHUHEr1V9VdPkDx1/qd4QZWPIcZTmFFs53CnynemWf2F7CSJcxkCb0/h5Wt0JpeIJjehZNsrujtHDUrRKnh407dw0nTR9XqwGgP4faXcHpLNNsjcICueb0vOkPnYS9lq1O8bdEdbKD+eBxwhRL0y6xT8/z+U2o+ffycms+fvJCgH3BMVbs0Ne8uH0jQjfaQmrv9Xc2d3pKaN9sjCfrXMMYSdAn61zBm/2+XkKBXrQ5vzyXo6sy3BF2Crs40Hs1KJOgSdDWH9fBB19oj1FpDlN0UFT9D8ZO9Gv0JmskUTr5GtH6A/tlDJNuH6J3eB/eJdxZbd7SGnW/gjpZX7MEEwewMy7feR3b+BDy43BsurN4YPDfD7A6s7hD1IAGH5hU3Kjshiq9XvRiaH6Ppx7hTM6DmUKq/qtbsAka2RD2egAeq6NHUjOewegu46XpneOZe80fneznDMxjpCtZgAy/fggtZvUXdz66UjS5KjRbKzWBH75SvVc0Qmh2Dg3i9nTu9xV6NIEfN7eGLztB5aEzVCZvhGN5wC/XH44ArlKBfZp2a907vS9APOI7Hcmlq3ppdUHMjW1LzejyRoDu9BTVvBDk1r7lf+J+iEvSv+CMgQZegf8UR+ib+dQm6ZsfyDl3B0ZegS9AVHEvVlyRBl6CrOaOHD3qzFaPuhqiYAap2eyeIqte0MEE9StCIMxhJjmZ/BC0a7KUnYzijJbzpGdqT9RU/G6G/uYvzd3+JaHkXWpCg+IHodjdHw+2h4kTg0LzshMVzcx7eUvN7mhfD7iQoNyy8/v3bUHMo1V9V8ReLuAHcylbcGK73d8/vNnpzbiS3kqWdruANz+BP7sIbX8AdncMZbmFmG1jpBm5yCr0zAsfWex+cUjKCihlCc1LU3QwNN4PeHqF4gF68hVHvjKG5fVTtEBWrC83toRlO4OfnUH88DrhCCfr/Zp2a68mYmjujJTX3pmcS9AOOrAqXlqA33Iya6+2RBF2Fsfzss88k6BJ0RUbxmJYhQZegqzmvEnQJupqTqfSqJOgSdDUH9PBBr7ttaE6AsuHumF75WskJdrxO6VrZ66DSClHr9NDoDWENZnDzBfzJGt5kDXe8hp9NrjidGJ3xEvO3fgo7naHqRjA7A/CAcs0Ka2YXZbuLkt1F8Qy96vfQbPVhuR186/Xv4tWbN6DmUKq/Kn+0hZ2tYfQX4GEsZn/BobmdrpxsvRf/iJ2trXTHzjY7g429j9lfwuhOUfdS8LmdxTP0stlG1Y5Q9wbQW/lezSAHT6oxw2nxDN2OFzA6IzRaWUHaaH2uGQxgRDM42SnUH48DrlCCfpl1au7mC2ruF2ruTXY1d8drCfoBR1aFS1Nzf7QthpiaG4Wna0nQr5pOzY3OqFDzjJo3Wik1bwYDam5EM2ruZKcqDICya5CgS9CVHU51FyZB11u7t+fNIJd36IoMqwRdgq7IKB7TMiToEnQ15/XwQb+jO6jYLZRMD1W3DS2I0eim0KMBrN4ITjrdGc6dazyPxR0tedEZzu0CI5tA6+VotqIr1boJM0wwfPAWzHgEbhLXvJjnUF9+YXT3OrE6e90x26h4Mcx2ih/cPsGrr72CGzdfgZpDqf6q3GwNq7+A2ZujeO958dC8+Hrx4+UanRx6NIadzOGkS1jJHPVggIodg2e2lI1u8eicr0/0FipWCG48r7tZ8QDdCEbgAL0Z5NxsrnfGxU8v8pIVnP4CZjyDEU13wolxjf8VMPtLK9lA/fE44Aol6JeP2ZKgH3AEj/HS1NzN1tTc6i+oufnfv0wkQfeSFTV3+gtqbsazXc2jKTU3wokE/Uv8aEjQJehfYmy+6X9Fgm4EI3mHruCPgQRdgq7gWKq+JAm6BF3NGT180KteF1orRqPdh95N0QwH0MMBjHAAK8phx/lOL7OvmVECvR1Dc9s40R28Udbwne/dvnLr1rfxg0oT7dkWjSBFqRmgorf3qhodnBgBfqgHuK23oAd9lOoWbrx2C6/eeAU3b92EmkOp/qqseAYzmoIPEb38ovBZoMWv9XgGrZOj5idotDNY8QR2fwojGqH4ZNqy3kVJb+8YAUfnfMEB+one4gC9YoU8yEVz0oY32EvzBih+1NzuE1OjWfGedDfdwEk3sNM1rP4KZn8FO91A/fE44Aol6JdZp+Z6O6bmmtum5ie6Q83fKGsS9AOOrAqXpuZWPKPmZjSVoDfbIwn6AUdUgi5BP+D4HeulJeiNwttzzRvIO3RFRlmCLkFXZBSPaRkSdAm6mvN6+KCruS+yKtkB2QHZgaPbAQn60X3LZMGyA7IDsgP7d0CCvn9f5FXZAdkB2YGj2wEJ+tF9y2TBsgOyA7ID+3dAgr5/X+RV2QHZAdmBo9sBCfrRfctkwbIDsgOyA/t3QIK+f1/kVdkB2QHZgaPbAQn60X3LZMGyA7IDsgP7d0CCvn9f5FXZAdkB2YGj2wEJ+tF9y2TBsgOyA7ID+3fg37mB4d91B7EKAAAAAElFTkSuQmCC)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lABOOwOQn_hZ"},"outputs":[],"source":["num_queries = 10  # Number of queries to classify and explain\n","classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]  # CIFAR-10 classes\n","stair = 0\n","# Iterate through the first `num_queries` test samples\n","for i in range(num_queries):\n","    query = X_test[i+stair].unsqueeze(0)  # Add batch dimension for the query\n","    true_label = y_test[i+stair].item()\n","    results = classify_and_explain(model, query, model.case_nets, classes)\n","\n","    print(f\"Query {i + stair+ 1}:\")\n","    print(f\"  True Class: {classes[true_label]}\")\n","    print(f\"  Predicted Class: {results['query_prediction']}\")\n","    print(f\"  Most Activated Case Label: {results['most_activated_case_label']}\")\n","    print(f\"  Most Activated Activation: {results['most_activated_activation']:.4f}\")\n","    print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"smPhW0ItrEfe"},"outputs":[],"source":["num_queries = 10  # Number of queries to classify and explain\n","classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]  # CIFAR-10 classes\n","stair = 10\n","# Iterate through the first `num_queries` test samples\n","for i in range(num_queries):\n","    query = X_test[i+stair].unsqueeze(0)  # Add batch dimension for the query\n","    true_label = y_test[i+stair].item()\n","    results = classify_and_explain(model, query, model.case_nets, classes)\n","\n","    print(f\"Query {i + stair+ 1}:\")\n","    print(f\"  True Class: {classes[true_label]}\")\n","    print(f\"  Predicted Class: {results['query_prediction']}\")\n","    print(f\"  Most Activated Case Label: {results['most_activated_case_label']}\")\n","    print(f\"  Most Activated Activation: {results['most_activated_activation']:.4f}\")\n","    print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qPfgnGlqt1Kh"},"outputs":[],"source":["num_queries = 10  # Number of queries to classify and explain\n","classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]  # CIFAR-10 classes\n","stair = 10\n","# Iterate through the first `num_queries` test samples\n","for i in range(num_queries):\n","    query = X_test[i+stair].unsqueeze(0)  # Add batch dimension for the query\n","    true_label = y_test[i+stair].item()\n","    results = classify_and_explain(model, query, model.case_nets, classes)\n","\n","    print(f\"Query {i + stair+ 1}:\")\n","    print(f\"  True Class: {classes[true_label]}\")\n","    print(f\"  Predicted Class: {results['query_prediction']}\")\n","    print(f\"  Most Activated Case Label: {results['most_activated_case_label']}\")\n","    print(f\"  Most Activated Activation: {results['most_activated_activation']:.4f}\")\n","    print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ZxaAtyBuqRk"},"outputs":[],"source":["num_queries = 10  # Number of queries to classify and explain\n","classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]  # CIFAR-10 classes\n","stair = 8000\n","# Iterate through the first `num_queries` test samples\n","for i in range(num_queries):\n","    query = X_test[i+stair].unsqueeze(0)  # Add batch dimension for the query\n","    true_label = y_test[i+stair].item()\n","    results = classify_and_explain(model, query, model.case_nets, classes)\n","\n","    print(f\"Query {i + stair+ 1}:\")\n","    print(f\"  True Class: {classes[true_label]}\")\n","    print(f\"  Predicted Class: {results['query_prediction']}\")\n","    print(f\"  Most Activated Case Label: {results['most_activated_case_label']}\")\n","    print(f\"  Most Activated Activation: {results['most_activated_activation']:.4f}\")\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"E0OX7knydw0F"},"source":["## SST"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TSer96MRdw0F"},"outputs":[],"source":["def classify_and_explain_sst(model, query, vocab, classes, device='cuda'):\n","    \"\"\"\n","    Classify a query sentence and provide the most activated case as an explanation.\n","\n","    Args:\n","        model (CaseNetsClassifier): Trained model for classification.\n","        query (torch.Tensor): Query tensor of shape [seq_len].\n","        case_nets (list): List of CaseNet objects.\n","        vocab (torchtext.vocab.Vocab): Vocabulary used for numericalization.\n","        classes (list): List of class names for the dataset.\n","        device (str): Device to run the inference on ('cuda' or 'cpu').\n","\n","    Returns:\n","        dict: Results containing predictions and explanation.\n","    \"\"\"\n","    model = model.to(device)\n","    query = query.unsqueeze(0).to(device)  # Add batch dimension [1, seq_len]\n","\n","    # Classify query and get explanation\n","    final_predictions, predicted_class, most_activated_cases, most_activated_case_labels, most_activated_activations = model(query)\n","\n","    results = {\"query\": None,\n","                \"query_prediction\": classes[predicted_class.item()],\n","                \"explanations\": []}\n","    # Get the most activated case and its label\n","    for i, (case, label, activation) in enumerate(zip(most_activated_cases[0], most_activated_case_labels[0], most_activated_activations[0])):\n","        most_activated_case = case.cpu().squeeze()\n","        most_activated_label = torch.argmax(label).item()\n","        most_activated_activation = activation.item()\n","\n","        # Decode query and most activated case from indices to tokens\n","        def decode(tokens, vocab):\n","            reverse_vocab = {idx: token for token, idx in vocab.items()}  # Create reverse mapping\n","            return \" \".join([reverse_vocab[token.item()] for token in tokens if token.item() != vocab[\"<pad>\"]])\n","\n","        query_text = decode(query.squeeze().cpu(), vocab)\n","        results[\"query\"] = query_text\n","        most_activated_case_text = decode(most_activated_case, vocab)\n","        # Append explanation to results\n","        results[\"explanations\"].append({\n","            \"most_activated_case\": most_activated_case_text,\n","            \"most_activated_case_label\": classes[most_activated_label],\n","            \"most_activated_activation\": most_activated_activation\n","        })\n","    # Return detailed results\n","    return results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5ezqSJt1dw0F","outputId":"e7513e38-50b5-4360-de07-6ab99783f0e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Example 67 ---\n","Query Sentence: A taut , intelligent psychological drama .\n","True Class: Positive\n","Predicted Class: Positive\n","0-th most Activated Case Sentence: A poignant and gently humorous parable that loves its characters and communicates something rather beautiful about human nature .\n","0-th most Activated Case Label: Positive\n","0-th most Activated Activation: 0.2551\n","\n","1-th most Activated Case Sentence: A dark , quirky road movie that constantly defies expectation .\n","1-th most Activated Case Label: Positive\n","1-th most Activated Activation: 0.2331\n","\n","2-th most Activated Case Sentence: A sexy , peculiar and always entertaining costume drama set in <unk> Spain , and the fact that it 's based on true events somehow makes it all the more compelling .\n","2-th most Activated Case Label: Positive\n","2-th most Activated Activation: 0.2268\n","\n","3-th most Activated Case Sentence: A must-see for fans of thoughtful war films and those interested in the sights and sounds of battle .\n","3-th most Activated Case Label: Positive\n","3-th most Activated Activation: 0.2014\n","\n","--- Example 2135 ---\n","Query Sentence: <unk> when I get this much <unk> , I like <unk> to go with it .\n","True Class: Somewhat Negative\n","Predicted Class: Neutral\n","0-th most Activated Case Sentence: <unk> John McKay is never able to pull it back on course .\n","0-th most Activated Case Label: Somewhat Negative\n","0-th most Activated Activation: 0.1710\n","\n","1-th most Activated Case Sentence: A very capable <unk> .\n","1-th most Activated Case Label: Somewhat Positive\n","1-th most Activated Activation: 0.1544\n","\n","2-th most Activated Case Sentence: <unk> <unk> August ... depicts this relationship with economical grace , letting his superb actors convey Martin 's <unk> and <unk> 's sadness -- and , occasionally , anger .\n","2-th most Activated Case Label: Neutral\n","2-th most Activated Activation: 0.1302\n","\n","3-th most Activated Case Sentence: A <unk> observant , carefully nuanced and intimate French coming-of-age film that is an encouraging debut feature but has a needlessly downbeat ending that is too heavy for all that has preceded it .\n","3-th most Activated Case Label: Neutral\n","3-th most Activated Activation: 0.1291\n","\n","--- Example 1938 ---\n","Query Sentence: I loved looking at this movie .\n","True Class: Somewhat Positive\n","Predicted Class: Somewhat Positive\n","0-th most Activated Case Sentence: I loved this film .\n","0-th most Activated Case Label: Positive\n","0-th most Activated Activation: 0.4730\n","\n","1-th most Activated Case Sentence: I think it was <unk> who said , ' I think , therefore I know better than to rush to the theatre for this one . '\n","1-th most Activated Case Label: Somewhat Negative\n","1-th most Activated Activation: 0.1676\n","\n","2-th most Activated Case Sentence: I know that I 'll never listen to <unk> <unk> or the <unk> the same way again\n","2-th most Activated Case Label: Somewhat Positive\n","2-th most Activated Activation: 0.1524\n","\n","3-th most Activated Case Sentence: <unk> , I 'd rather watch them on the Animal Planet .\n","3-th most Activated Case Label: Negative\n","3-th most Activated Activation: 0.1083\n","\n","--- Example 1104 ---\n","Query Sentence: <unk> of a plot and jokes done too often by people far more talented than Ali <unk>\n","True Class: Somewhat Negative\n","Predicted Class: Somewhat Negative\n","0-th most Activated Case Sentence: <unk> of Alfred Hitchcock 's thrillers , most of the scary parts in ` Signs ' occur while waiting for things to happen .\n","0-th most Activated Case Label: Somewhat Positive\n","0-th most Activated Activation: 0.1767\n","\n","1-th most Activated Case Sentence: <unk> to <unk> , soap opera-ish dialogue , the rest of the cast comes across as stick figures reading lines from a <unk> .\n","1-th most Activated Case Label: Negative\n","1-th most Activated Activation: 0.1260\n","\n","2-th most Activated Case Sentence: <unk> has a <unk> sense of narrative <unk> .\n","2-th most Activated Case Label: Somewhat Positive\n","2-th most Activated Activation: 0.1117\n","\n","3-th most Activated Case Sentence: <unk> of <unk> and hack work from start to finish .\n","3-th most Activated Case Label: Neutral\n","3-th most Activated Activation: 0.1092\n","\n","--- Example 570 ---\n","Query Sentence: This romantic thriller is steeped in the atmosphere of wartime England , and ably captures the <unk> <unk> , moral <unk> and <unk> of the 1940s .\n","True Class: Somewhat Positive\n","Predicted Class: Somewhat Positive\n","0-th most Activated Case Sentence: This film is so different from The <unk> and so striking that it can only encourage us to see <unk> <unk> as a very distinctive sensibility , working to develop her own film language with conspicuous success .\n","0-th most Activated Case Label: Somewhat Positive\n","0-th most Activated Activation: 0.2520\n","\n","1-th most Activated Case Sentence: The Wild Thornberrys Movie is pleasant enough and the message of our close ties with animals can certainly not be <unk> enough .\n","1-th most Activated Case Label: Somewhat Positive\n","1-th most Activated Activation: 0.1548\n","\n","2-th most Activated Case Sentence: ( A ) strong piece of work .\n","2-th most Activated Case Label: Somewhat Positive\n","2-th most Activated Activation: 0.1508\n","\n","3-th most Activated Case Sentence: ( Has ) an immediacy and an intimacy that sucks you in and dares you not to believe it 's all true .\n","3-th most Activated Case Label: Somewhat Positive\n","3-th most Activated Activation: 0.1468\n","\n","--- Example 1947 ---\n","Query Sentence: It 's the kind of movie you ca n't quite recommend because it is all <unk> and not much of a pitch , yet you ca n't bring yourself to <unk> it .\n","True Class: Somewhat Negative\n","Predicted Class: Somewhat Negative\n","0-th most Activated Case Sentence: It 's pretentious in a way that verges on the amateurish .\n","0-th most Activated Case Label: Negative\n","0-th most Activated Activation: 0.1299\n","\n","1-th most Activated Case Sentence: It 's kind of sad that so many people put so much time and energy into this turkey .\n","1-th most Activated Case Label: Somewhat Negative\n","1-th most Activated Activation: 0.0919\n","\n","2-th most Activated Case Sentence: It 's too bad nothing else is .\n","2-th most Activated Case Label: Neutral\n","2-th most Activated Activation: 0.0755\n","\n","3-th most Activated Case Sentence: This Tuxedo ... should have been sent back to the tailor for some major <unk> .\n","3-th most Activated Case Label: Negative\n","3-th most Activated Activation: 0.0735\n","\n","--- Example 1700 ---\n","Query Sentence: <unk> on in a disjointed , <unk> fashion from one poorly executed action sequence to the next .\n","True Class: Negative\n","Predicted Class: Neutral\n","0-th most Activated Case Sentence: <unk> on writer\\/director <unk> <unk> for making a florid biopic about <unk> queens , obsessive relationships , and rampant <unk> so dull .\n","0-th most Activated Case Label: Somewhat Negative\n","0-th most Activated Activation: 0.1538\n","\n","1-th most Activated Case Sentence: <unk> The Tuxedo 's 90 minutes of screen time , there is n't one true ` Chan moment ' .\n","1-th most Activated Case Label: Somewhat Negative\n","1-th most Activated Activation: 0.1354\n","\n","2-th most Activated Case Sentence: <unk> ?\n","2-th most Activated Case Label: Neutral\n","2-th most Activated Activation: 0.1327\n","\n","3-th most Activated Case Sentence: <unk> does have a gift for generating nightmarish images that will be hard to burn out of your brain .\n","3-th most Activated Case Label: Neutral\n","3-th most Activated Activation: 0.1224\n","\n","--- Example 885 ---\n","Query Sentence: The <unk> <unk> atmosphere has a way of <unk> the entire crowd as the film rolls on .\n","True Class: Neutral\n","Predicted Class: Somewhat Positive\n","0-th most Activated Case Sentence: The film sometimes <unk> ... but there is enough secondary action to keep things moving along at a brisk , amusing pace .\n","0-th most Activated Case Label: Neutral\n","0-th most Activated Activation: 0.1690\n","\n","1-th most Activated Case Sentence: A <unk> <unk> ride of glamour and <unk> .\n","1-th most Activated Case Label: Neutral\n","1-th most Activated Activation: 0.1576\n","\n","2-th most Activated Case Sentence: <unk> games are more involving than this mess .\n","2-th most Activated Case Label: Somewhat Negative\n","2-th most Activated Activation: 0.1299\n","\n","3-th most Activated Case Sentence: <unk> II -- <unk> of the <unk> is a technological exercise that lacks juice and delight .\n","3-th most Activated Case Label: Somewhat Negative\n","3-th most Activated Activation: 0.1234\n","\n","--- Example 409 ---\n","Query Sentence: <unk> it up to my <unk> for both De Niro and Murphy , but I had a pretty good time with this movie - despite its <unk> flaws .\n","True Class: Neutral\n","Predicted Class: Somewhat Positive\n","0-th most Activated Case Sentence: <unk> ' about dragons\n","0-th most Activated Case Label: Neutral\n","0-th most Activated Activation: 0.1961\n","\n","1-th most Activated Case Sentence: <unk> da <unk> !\n","1-th most Activated Case Label: Neutral\n","1-th most Activated Activation: 0.1876\n","\n","2-th most Activated Case Sentence: As it turns out , you can go home again .\n","2-th most Activated Case Label: Somewhat Positive\n","2-th most Activated Activation: 0.1389\n","\n","3-th most Activated Case Sentence: But it could be , by its art and heart , a necessary one .\n","3-th most Activated Case Label: Somewhat Positive\n","3-th most Activated Activation: 0.1266\n","\n","--- Example 1731 ---\n","Query Sentence: High Crimes <unk> nearly every leading character .\n","True Class: Somewhat Negative\n","Predicted Class: Somewhat Positive\n","0-th most Activated Case Sentence: High Crimes steals so freely from other movies and combines enough disparate types of films that it ca n't help but engage an audience .\n","0-th most Activated Case Label: Somewhat Positive\n","0-th most Activated Activation: 0.4249\n","\n","1-th most Activated Case Sentence: High Crimes is a cinematic misdemeanor , a routine crime thriller remarkable only for its lack of logic and <unk> of two fine actors , <unk> Freeman and <unk> Judd .\n","1-th most Activated Case Label: Negative\n","1-th most Activated Activation: 0.2221\n","\n","2-th most Activated Case Sentence: An impeccable study in perversity .\n","2-th most Activated Case Label: Somewhat Positive\n","2-th most Activated Activation: 0.1306\n","\n","3-th most Activated Case Sentence: <unk> run-of-the-mill .\n","3-th most Activated Case Label: Somewhat Negative\n","3-th most Activated Activation: 0.1276\n","\n","--- Example 830 ---\n","Query Sentence: A dream cast of solid female talent who build a <unk> ensemble .\n","True Class: Positive\n","Predicted Class: Somewhat Positive\n","0-th most Activated Case Sentence: A <unk> visual style and <unk> of charm make ` Cherish ' a very good ( but not great ) movie .\n","0-th most Activated Case Label: Somewhat Positive\n","0-th most Activated Activation: 0.1958\n","\n","1-th most Activated Case Sentence: A solid , spooky entertainment worthy of the price of a ticket .\n","1-th most Activated Case Label: Somewhat Positive\n","1-th most Activated Activation: 0.1936\n","\n","2-th most Activated Case Sentence: A whole lot of fun and funny in the middle , though somewhat less hard-hitting at the start and finish .\n","2-th most Activated Case Label: Somewhat Positive\n","2-th most Activated Activation: 0.1621\n","\n","3-th most Activated Case Sentence: A story about intelligent high school students that deals with first love sweetly but also seriously .\n","3-th most Activated Case Label: Somewhat Positive\n","3-th most Activated Activation: 0.1534\n","\n","--- Example 461 ---\n","Query Sentence: <unk> and brilliant documentary .\n","True Class: Positive\n","Predicted Class: Positive\n","0-th most Activated Case Sentence: <unk> and predictable .\n","0-th most Activated Case Label: Negative\n","0-th most Activated Activation: 0.1182\n","\n","1-th most Activated Case Sentence: <unk> honest and told with humor and poignancy , which makes its message resonate .\n","1-th most Activated Case Label: Positive\n","1-th most Activated Activation: 0.0823\n","\n","2-th most Activated Case Sentence: <unk> inane , humorless and under-inspired .\n","2-th most Activated Case Label: Negative\n","2-th most Activated Activation: 0.0715\n","\n","3-th most Activated Case Sentence: <unk> derivative and <unk> acted .\n","3-th most Activated Case Label: Negative\n","3-th most Activated Activation: 0.0674\n","\n","--- Example 1525 ---\n","Query Sentence: It 's never a good sign when a film 's star spends the <unk> of the film in a coma .\n","True Class: Negative\n","Predicted Class: Somewhat Positive\n","0-th most Activated Case Sentence: It 's a satisfying summer blockbuster and worth a look .\n","0-th most Activated Case Label: Somewhat Positive\n","0-th most Activated Activation: 0.3502\n","\n","1-th most Activated Case Sentence: It 's a square , sentimental drama that satisfies , as comfort food often can .\n","1-th most Activated Case Label: Somewhat Positive\n","1-th most Activated Activation: 0.2882\n","\n","2-th most Activated Case Sentence: It 's <unk> directed with verve ...\n","2-th most Activated Case Label: Somewhat Positive\n","2-th most Activated Activation: 0.2763\n","\n","3-th most Activated Case Sentence: It 's excessively quirky and a little <unk> in its delivery , but otherwise this is the best ` old neighborhood ' project since Christopher <unk> kinda <unk> <unk> <unk> in The <unk> .\n","3-th most Activated Case Label: Somewhat Positive\n","3-th most Activated Activation: 0.2478\n","\n","--- Example 1045 ---\n","Query Sentence: It 's haunting .\n","True Class: Neutral\n","Predicted Class: Somewhat Positive\n","0-th most Activated Case Sentence: It 's uninteresting .\n","0-th most Activated Case Label: Negative\n","0-th most Activated Activation: 0.1907\n","\n","1-th most Activated Case Sentence: It 's funny , as the old saying goes , because it 's true .\n","1-th most Activated Case Label: Somewhat Positive\n","1-th most Activated Activation: 0.1836\n","\n","2-th most Activated Case Sentence: It 's no lie -- Big Fat Liar is a real charmer .\n","2-th most Activated Case Label: Positive\n","2-th most Activated Activation: 0.1608\n","\n","3-th most Activated Case Sentence: It 's at once laughable and compulsively watchable , in its committed dumbness .\n","3-th most Activated Case Label: Somewhat Positive\n","3-th most Activated Activation: 0.1529\n","\n","--- Example 356 ---\n","Query Sentence: As <unk> and <unk> demonstrate with such insight and <unk> verve , the Cockettes were n't as much about gender , sexual <unk> or political <unk> as they were simply a triumph of the <unk> human will to rebel , connect and create .\n","True Class: Positive\n","Predicted Class: Somewhat Negative\n","0-th most Activated Case Sentence: As spent screen series go , Star Trek : Nemesis is even more suggestive of a <unk> class reunion <unk> where only eight surviving members show up -- and there 's nothing to drink .\n","0-th most Activated Case Label: Neutral\n","0-th most Activated Activation: 0.2032\n","\n","1-th most Activated Case Sentence: As plain and pedestrian as <unk> --\n","1-th most Activated Case Label: Negative\n","1-th most Activated Activation: 0.1977\n","\n","2-th most Activated Case Sentence: As a movie , it never seems fresh and vital .\n","2-th most Activated Case Label: Neutral\n","2-th most Activated Activation: 0.1497\n","\n","3-th most Activated Case Sentence: A sometimes incisive and sensitive portrait that is undercut by its awkward structure and a final <unk> toward melodrama .\n","3-th most Activated Case Label: Somewhat Negative\n","3-th most Activated Activation: 0.1179\n","\n","--- Example 1997 ---\n","Query Sentence: Once the audience figure out what 's being said , the filmmaker 's relative <unk> will make it tough for them to really care .\n","True Class: Somewhat Negative\n","Predicted Class: Somewhat Negative\n","0-th most Activated Case Sentence: Once again , the intelligence of gay audiences has been grossly underestimated , and a meaty plot and well-developed characters have been sacrificed for skin and flash that barely fizzle .\n","0-th most Activated Case Label: Neutral\n","0-th most Activated Activation: 0.2241\n","\n","1-th most Activated Case Sentence: It appears to have been made by people to whom the idea of narrative logic or cohesion is an entirely foreign concept .\n","1-th most Activated Case Label: Negative\n","1-th most Activated Activation: 0.0868\n","\n","2-th most Activated Case Sentence: It merely <unk> in the worst elements of all of them .\n","2-th most Activated Case Label: Somewhat Negative\n","2-th most Activated Activation: 0.0855\n","\n","3-th most Activated Case Sentence: A limp Eddie Murphy vehicle that even he seems embarrassed to be part of .\n","3-th most Activated Case Label: Negative\n","3-th most Activated Activation: 0.0825\n","\n","--- Example 1881 ---\n","Query Sentence: At times , however , Dogtown and Z-Boys lapses into an insider 's <unk> and <unk> that the <unk> may find hard to follow , or care about .\n","True Class: Somewhat Negative\n","Predicted Class: Somewhat Negative\n","0-th most Activated Case Sentence: At its worst , the movie is pretty diverting ; the pity is that it rarely achieves its best .\n","0-th most Activated Case Label: Neutral\n","0-th most Activated Activation: 0.1691\n","\n","1-th most Activated Case Sentence: At once emotional and richly analytical , the <unk> encounter alone confirms the serious weight behind this superficially loose , larky documentary .\n","1-th most Activated Case Label: Neutral\n","1-th most Activated Activation: 0.1327\n","\n","2-th most Activated Case Sentence: At its worst the screenplay is callow , but at its best it is a young artist 's thoughtful consideration of <unk> .\n","2-th most Activated Case Label: Neutral\n","2-th most Activated Activation: 0.1246\n","\n","3-th most Activated Case Sentence: At once subtle and visceral , the film never succumbs to the trap of the maudlin or <unk> , offering instead with its unflinching gaze a measure of faith in the future .\n","3-th most Activated Case Label: Positive\n","3-th most Activated Activation: 0.1229\n","\n","--- Example 750 ---\n","Query Sentence: Pretty <unk> good , despite its <unk> <unk> .\n","True Class: Somewhat Positive\n","Predicted Class: Somewhat Negative\n","0-th most Activated Case Sentence: <unk> along , minus the twisted humor and eye-popping visuals that have made Miike ... a cult hero .\n","0-th most Activated Case Label: Neutral\n","0-th most Activated Activation: 0.1054\n","\n","1-th most Activated Case Sentence: The humor and humanity of Monsoon Wedding are in perfect balance .\n","1-th most Activated Case Label: Somewhat Positive\n","1-th most Activated Activation: 0.1004\n","\n","2-th most Activated Case Sentence: The plot grows thin soon , and you find yourself <unk> for a quick resolution .\n","2-th most Activated Case Label: Somewhat Negative\n","2-th most Activated Activation: 0.0980\n","\n","3-th most Activated Case Sentence: The <unk> thing about Clockstoppers is that it does n't make any sense .\n","3-th most Activated Case Label: Somewhat Negative\n","3-th most Activated Activation: 0.0970\n","\n","--- Example 1324 ---\n","Query Sentence: Both stars manage to be funny , but , like the recent I Spy , the star chemistry <unk> the question of whether random gags add up to a movie .\n","True Class: Neutral\n","Predicted Class: Somewhat Negative\n","0-th most Activated Case Sentence: All the small moments and flashbacks do n't add up to much more than trite observations on the human condition .\n","0-th most Activated Case Label: Somewhat Negative\n","0-th most Activated Activation: 0.1589\n","\n","1-th most Activated Case Sentence: It stars <unk> Chris Rock and stolid Anthony Hopkins , who seem barely in the same movie .\n","1-th most Activated Case Label: Somewhat Negative\n","1-th most Activated Activation: 0.1403\n","\n","2-th most Activated Case Sentence: A beautiful paean to a time long past .\n","2-th most Activated Case Label: Somewhat Positive\n","2-th most Activated Activation: 0.1340\n","\n","3-th most Activated Case Sentence: Though the film is well-intentioned , one could rent the original and get the same love story and parable .\n","3-th most Activated Case Label: Somewhat Positive\n","3-th most Activated Activation: 0.1290\n","\n","--- Example 212 ---\n","Query Sentence: Tsai Ming-liang has taken his trademark style and refined it to a <unk> point .\n","True Class: Somewhat Positive\n","Predicted Class: Somewhat Negative\n","0-th most Activated Case Sentence: A laughable -- or rather , <unk> -- excuse for a film .\n","0-th most Activated Case Label: Negative\n","0-th most Activated Activation: 0.1255\n","\n","1-th most Activated Case Sentence: Although no pastry is <unk> , this nasty comedy pokes fun at the same easy <unk> as other rowdy <unk> -- farts , boobs , <unk> -- without much success .\n","1-th most Activated Case Label: Somewhat Negative\n","1-th most Activated Activation: 0.1107\n","\n","2-th most Activated Case Sentence: Triple X is a double agent , and he 's one bad dude .\n","2-th most Activated Case Label: Somewhat Positive\n","2-th most Activated Activation: 0.1103\n","\n","3-th most Activated Case Sentence: Manages to please its intended audience -- children -- without placing their parents in a <unk> state .\n","3-th most Activated Case Label: Somewhat Positive\n","3-th most Activated Activation: 0.1102\n","\n"]}],"source":["import random\n","random_indices = random.sample(range(len(X_test)), 20)\n","\n","model.explanation_mode = True\n","# Loop through the randomly selected queries\n","for i, query_idx in enumerate(random_indices):  # Loop through the first 20 test queries\n","    query = X_test[query_idx]  # Get numericalized query tensor\n","    true_class = y_test[query_idx]  # Get true class label\n","    # Run the classify_and_explain_sst function\n","    results = classify_and_explain_sst(model, query, word2idx, classes, device)\n","\n","    # Print the classification results\n","    print(f\"--- Example {query_idx + 1} ---\")\n","    print(f\"Query Sentence: {results['query']}\")\n","    print(f\"True Class: {classes[true_class]}\")\n","    print(f\"Predicted Class: {results['query_prediction']}\")\n","    for j in range(4):\n","        print(f\"{j}-th most Activated Case Sentence: {results['explanations'][j]['most_activated_case']}\")\n","        print(f\"{j}-th most Activated Case Label: {results['explanations'][j]['most_activated_case_label']}\")\n","        print(f\"{j}-th most Activated Activation: {results['explanations'][j]['most_activated_activation']:.4f}\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TYf9dY-8dw0F"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":["vHknYLrK33ES","2MNAEUwC30I0","r3LIZuDx1nTb"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}