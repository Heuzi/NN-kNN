{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6MEBduUKpGrg"
   },
   "source": [
    "Introduction for Psychologists:\n",
    "\n",
    "Hello. This is a demo of our model on predicting depression risk and explaining with features and cases. It is trained on a data set of cases.\n",
    "\n",
    "**Case**: a survey participant who answered 102 questions of depression screening survey (self-reporting). Each participant has a depression risk score 0,1,2 (judged by a psychologist, based on number of depression-related physical symptoms)\n",
    "\n",
    "**Feature**: Answers to survey questions (yes/no)\n",
    "\n",
    "**Query**: the new client who we are making a prediction on.\n",
    "\n",
    "**How does it work:**\n",
    " Our model learns about important features and cases during training. Given a new query (a new client), our model makes a prediction by retrieving the most relevant cases. It can explain in two main ways: highlighting (non-)important features, or highlighting (non-)important cases.\n",
    "\n",
    "**Goal**: The Goal of this demo is not to show you how good or how bad our model performs but more to open up a discussion about what you feel about using such models (part 2 of the interview). Please ignore the non-existing User-experience (UI) and the software code aspects because it is just a prototype. I will do my best to show you only the relevant parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxoHWNZEmG4g"
   },
   "source": [
    "# 1 Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CsfLxAVaPOTf"
   },
   "source": [
    "On google colab, you have to restart runtime after running the following line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9816,
     "status": "ok",
     "timestamp": 1736957620463,
     "user": {
      "displayName": "Xiaomeng Ye",
      "userId": "13514710516313163849"
     },
     "user_tz": 300
    },
    "id": "T3Y5CLhymG4l",
    "outputId": "633e2942-a7d8-4abe-90c6-cbb1d9228dee"
   },
   "outputs": [],
   "source": [
    "# !pip install omegaconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1736957637360,
     "user": {
      "displayName": "Xiaomeng Ye",
      "userId": "13514710516313163849"
     },
     "user_tz": 300
    },
    "id": "q-0ffsjpbDLE"
   },
   "outputs": [],
   "source": [
    "##This is added because my Rdata uses Cdata for the covid data set.\n",
    "##Rdata use Cdata function to load the data set, then convert it to regression problem\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(folder_name + 'dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 32026,
     "status": "ok",
     "timestamp": 1736957669384,
     "user": {
      "displayName": "Xiaomeng Ye",
      "userId": "13514710516313163849"
     },
     "user_tz": 300
    },
    "id": "oDGrACwVmG4o"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "from dataset import cls_small_data as Cdata\n",
    "from dataset import cls_medium_data\n",
    "\n",
    "from dataset import reg_data as Rdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 969,
     "status": "ok",
     "timestamp": 1736957670350,
     "user": {
      "displayName": "Xiaomeng Ye",
      "userId": "13514710516313163849"
     },
     "user_tz": 300
    },
    "id": "bzTxZZJnmG4p"
   },
   "outputs": [],
   "source": [
    "conf_file = OmegaConf.load(os.path.join(folder_name, 'config.yaml'))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "random_seed = 43\n",
    "is_transformed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1736957670350,
     "user": {
      "displayName": "Xiaomeng Ye",
      "userId": "13514710516313163849"
     },
     "user_tz": 300
    },
    "id": "yT3W4iqSmG4p"
   },
   "outputs": [],
   "source": [
    "debug_print = False\n",
    "def dprint(*args):\n",
    "  global debug_print\n",
    "  if debug_print:\n",
    "    print(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# importlib.reload(cls_medium_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46TjfSz-mG4q"
   },
   "source": [
    "# 2 Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NK9RJK0lKZw9"
   },
   "source": [
    "## SST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"sst1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5 if dataset_name == \"sst1\" else 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = conf_file['dataset'][dataset_name]\n",
    "cfg.freeze_feature_extractor = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = cls_medium_data.Cls_medium_data(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt_tab')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def build_vocab(dataset, min_freq=1):\n",
    "    \"\"\"\n",
    "    Build a vocabulary from the 'sentence' field of the dataset.\n",
    "    Returns:\n",
    "      word2idx: dict mapping token -> integer index\n",
    "      idx2word: list or dict mapping integer index -> token\n",
    "    \"\"\"\n",
    "    special_tokens = [\"<pad>\", \"<unk>\"]\n",
    "    counter = Counter()\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        text = dataset[i]['sentence']\n",
    "        tokens = word_tokenize(text)\n",
    "        counter.update(tokens)\n",
    "    \n",
    "    vocab = [word for word, freq in counter.items() if freq >= min_freq]\n",
    "    vocab = sorted(vocab)\n",
    "\n",
    "    # Build mapping\n",
    "    word2idx = {}\n",
    "    for i, sp_tok in enumerate(special_tokens):\n",
    "        word2idx[sp_tok] = i\n",
    "\n",
    "    for i, word in enumerate(vocab, start=len(special_tokens)):\n",
    "        word2idx[word] = i\n",
    "\n",
    "    return word2idx\n",
    "\n",
    "word2idx = build_vocab(train_data, min_freq=2)\n",
    "idx2word = {v:k for k,v in word2idx.items()}\n",
    "\n",
    "PAD_IDX = word2idx[\"<pad>\"]\n",
    "UNK_IDX = word2idx[\"<unk>\"]\n",
    "vocab_size = len(word2idx)\n",
    "print(f\"Vocab size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def prepare_dataset(data, vocab, tokenizer):\n",
    "    texts = data[\"sentence\"]\n",
    "    labels = data[\"label\"]\n",
    "    tokenized_texts = [\n",
    "        torch.tensor([vocab.get(token, vocab[\"<unk>\"])\n",
    "                      for token in tokenizer(text)], dtype=torch.long)\n",
    "        for text in texts\n",
    "    ]\n",
    "    padded_texts = pad_sequence(tokenized_texts, batch_first=True, padding_value=vocab[\"<pad>\"])\n",
    "    \n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    return padded_texts, labels\n",
    "\n",
    "X_train, y_train = prepare_dataset(train_data, word2idx, word_tokenize)\n",
    "X_val,   y_val   = prepare_dataset(val_data,   word2idx, word_tokenize)\n",
    "X_test,  y_test  = prepare_dataset(test_data,  word2idx, word_tokenize)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset   = TensorDataset(X_val,   y_val)\n",
    "test_dataset  = TensorDataset(X_test,  y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = len(train_data)\n",
    "val_len   = len(val_data)\n",
    "test_len  = len(test_data)\n",
    "doc_count = train_len + val_len + test_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=128, num_classes=2, pad_idx=0):\n",
    "        super().__init__()\n",
    "\n",
    "        # feature extractor\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embed_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        # classifier\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        embedded = self.embedding(tokens)\n",
    "        \n",
    "        _, (h_n, _) = self.lstm(embedded)\n",
    "        \n",
    "        h_n = h_n.transpose(0, 1).contiguous().view(tokens.size(0), -1)\n",
    "\n",
    "        h_n = self.dropout(h_n)\n",
    "        logits = self.fc(h_n)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=32, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=32, shuffle=False)\n",
    "\n",
    "PAD_IDX = word2idx[\"<pad>\"]  # the integer used for padding\n",
    "model = BiLSTMClassifier(\n",
    "    vocab_size=len(word2idx),\n",
    "    embed_dim=128,\n",
    "    hidden_dim=128,\n",
    "    num_classes=num_classes,\n",
    "    pad_idx=PAD_IDX\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        seq_lengths = (X_batch != PAD_IDX).sum(dim=1)\n",
    "        logits = model(X_batch)\n",
    "\n",
    "        loss = criterion(logits, y_batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            logits = model(X_batch)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "    val_acc = correct / total\n",
    "    print(f\"Epoch {epoch+1} - Train Loss: {total_loss:.4f} Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        logits = model(X_batch)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "test_acc = correct / total\n",
    "print(f\"Epoch {epoch+1} - Test Acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxSpBPTBsRfR"
   },
   "source": [
    "# GO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9Z9vzQI8bdu"
   },
   "source": [
    "## Feature Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_RvkFavIgmc"
   },
   "source": [
    "# Text Classification Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2brzhaOcN1cl"
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bg22h24xODjs"
   },
   "outputs": [],
   "source": [
    "class BiLSTMFeatureExtractor(nn.Module):\n",
    "    def __init__(self, lstm_classifier=None):\n",
    "        super().__init__()\n",
    "\n",
    "        if lstm_classifier is None:\n",
    "            lstm_classifier = BiLSTMClassifier(\n",
    "                                vocab_size=len(word2idx),\n",
    "                                embed_dim=128,\n",
    "                                hidden_dim=128,\n",
    "                                num_classes=2,\n",
    "                                pad_idx=PAD_IDX)\n",
    "\n",
    "        self.embedding = lstm_classifier.embedding\n",
    "        self.lstm = lstm_classifier.lstm\n",
    "        self.feature_dim = None\n",
    "        \n",
    "    def forward(self, tokens):\n",
    "        w_emb = self.embedding(tokens)\n",
    "\n",
    "        _, (h_n, c_n) = self.lstm(w_emb)\n",
    "        \n",
    "        h_n = h_n.transpose(0, 1).contiguous()\n",
    "        h_n = h_n.view(h_n.size(0), -1)\n",
    "\n",
    "        return h_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: to load pretrained feature extractor, use this line\n",
    "feature_extractor = BiLSTMFeatureExtractor(model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: initialize a new feature extractor\n",
    "feature_extractor = BiLSTMFeatureExtractor(None).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.freeze_feature_extractor == True:\n",
    "  for param in feature_extractor.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxFFP2wGd_Cj"
   },
   "source": [
    "# Sanity Check\n",
    "Sanity check with a standard NN classifier using the feature extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained Feature for KNN (Pretrained Conv + KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmIRcBiHjnFj"
   },
   "source": [
    "Run the following if you want to transform the features for vanilla knn or vanilla nnknn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1567,
     "status": "ok",
     "timestamp": 1736545681816,
     "user": {
      "displayName": "Xiaomeng Ye",
      "userId": "13514710516313163849"
     },
     "user_tz": 300
    },
    "id": "yaby7Ru7qUN6",
    "outputId": "d3f7d0b0-329d-411e-974d-94d7929281e0"
   },
   "outputs": [],
   "source": [
    "# Step 1: Freeze the feature extractor's weights\n",
    "for param in feature_extractor.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Step 2: Convert X_train and X_test\n",
    "def transform_dataset(X, feature_extractor, batch_size=128, device='cuda'):\n",
    "    \"\"\"\n",
    "    Transform a dataset using the feature extractor.\n",
    "\n",
    "    Args:\n",
    "        X (torch.Tensor): Input dataset of shape (num_samples, channels, height, width).\n",
    "        feature_extractor (nn.Module): Feature extractor model.\n",
    "        batch_size (int): Batch size for processing.\n",
    "        device (str): Device to perform computations ('cuda' or 'cpu').\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Transformed dataset of shape (num_samples, feature_dim).\n",
    "    \"\"\"\n",
    "    feature_extractor.eval()  # Ensure the feature extractor is in evaluation mode\n",
    "    X = X.to(device)\n",
    "    transformed_features = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for efficiency\n",
    "        for i in range(0, X.size(0), batch_size):\n",
    "            batch = X[i:i + batch_size]\n",
    "            features = feature_extractor(batch)  # Extract features\n",
    "            transformed_features.append(features)\n",
    "\n",
    "    return torch.cat(transformed_features, dim=0)\n",
    "\n",
    "# Transform the datasets\n",
    "X_train_transformed = transform_dataset(X_train, feature_extractor, batch_size=128, device=device)\n",
    "X_test_transformed = transform_dataset(X_test, feature_extractor, batch_size=128, device=device)\n",
    "\n",
    "# Print shapes to verify\n",
    "print(f\"Transformed X_train shape: {X_train_transformed.shape}\")\n",
    "print(f\"Transformed X_test shape: {X_test_transformed.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ycSFx7yGqXTn"
   },
   "outputs": [],
   "source": [
    "X_train = X_train_transformed\n",
    "X_test = X_test_transformed\n",
    "\n",
    "is_transformed = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIH5bd_O3eg3"
   },
   "source": [
    "Sanity check using a vanilla knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 908,
     "status": "ok",
     "timestamp": 1736545686346,
     "user": {
      "displayName": "Xiaomeng Ye",
      "userId": "13514710516313163849"
     },
     "user_tz": 300
    },
    "id": "DD4hFap-tQ1Y",
    "outputId": "42e6b4b6-48a2-4345-895f-2235046a5b87"
   },
   "outputs": [],
   "source": [
    "# prompt: knn on the train and test data set\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Assuming X_train, y_train, X_test, and y_test are defined from the previous code\n",
    "# and contain the training and testing data.\n",
    "\n",
    "# Initialize the k-NN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors\n",
    "\n",
    "# Reshape X_train and X_test to 2D arrays before fitting the k-NN model\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], -1)  # Reshape to (num_samples, height * width)\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], -1)    # Reshape to (num_samples, height * width)\n",
    "\n",
    "# Train the classifier on the reshaped training data\n",
    "knn.fit(X_train_reshaped.cpu(), y_train)\n",
    "\n",
    "# Make predictions on the reshaped test data\n",
    "y_pred = knn.predict(X_test_reshaped.cpu())\n",
    "\n",
    "# Evaluate the model (example: accuracy)\n",
    "accuracy = accuracy_score(y_test.cpu().numpy(), y_pred)\n",
    "print(f\"k-NN Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del X_train_transformed, X_test_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZUXibQNLGTj"
   },
   "source": [
    "# Param Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLr1V5cGBSVb"
   },
   "source": [
    "### Shared Param Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Must run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1736959411638,
     "user": {
      "displayName": "Xiaomeng Ye",
      "userId": "13514710516313163849"
     },
     "user_tz": 300
    },
    "id": "_3YnWoOwLHs6"
   },
   "outputs": [],
   "source": [
    "def get_feature_dim(case, feature_extractor):\n",
    "        if feature_extractor is None:\n",
    "            return torch.prod(torch.tensor(case.shape)).item()\n",
    "        else:\n",
    "            return feature_extractor.feature_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1736959411638,
     "user": {
      "displayName": "Xiaomeng Ye",
      "userId": "13514710516313163849"
     },
     "user_tz": 300
    },
    "id": "YZHloHXQLMBK"
   },
   "outputs": [],
   "source": [
    "if is_transformed:\n",
    "    X_train, y_train = prepare_dataset(train_data, word2idx, word_tokenize)\n",
    "    X_test,  y_test  = prepare_dataset(test_data,  word2idx, word_tokenize)\n",
    "    \n",
    "if 'Xs' not in locals():\n",
    "    Xs = X_train\n",
    "    ys = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_activation_by_top_k_average = True\n",
    "bias_manual_set = False\n",
    "bias_manual_value = 6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmTmWAaqBWjz"
   },
   "source": [
    "### Non-shared setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QS33BQbPiSYH"
   },
   "outputs": [],
   "source": [
    "#For SST\n",
    "\n",
    "glocal_fw_set_num = 4\n",
    "sampling_cases_flag = True\n",
    "top_k_for_case_activation = 5\n",
    "num_samples=500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MUST RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = BiLSTMFeatureExtractor(None).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHknYLrK33ES"
   },
   "source": [
    "## Glocal Feature Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 398,
     "status": "ok",
     "timestamp": 1736959412035,
     "user": {
      "displayName": "Xiaomeng Ye",
      "userId": "13514710516313163849"
     },
     "user_tz": 300
    },
    "id": "lOL2WF2x4Ug3"
   },
   "outputs": [],
   "source": [
    "class GlocalFeatureWeight(nn.Module):\n",
    "    def __init__(self, feature_dim, set_num):\n",
    "        \"\"\"\n",
    "        Glocal feature weighting module for batched operations.\n",
    "\n",
    "        Args:\n",
    "            feature_dim: Dimensionality of the features.\n",
    "            set_num: Number of glocal weight sets.\n",
    "        \"\"\"\n",
    "        super(GlocalFeatureWeight, self).__init__()\n",
    "        self.feature_dim = feature_dim\n",
    "\n",
    "        # Initialize feature weights\n",
    "        self.feature_weights = nn.Parameter(torch.rand((set_num, feature_dim)), requires_grad=True)\n",
    "        if glocal_fw_set_num == 1:\n",
    "            self.feature_weights = nn.Parameter(torch.ones((set_num, feature_dim)), requires_grad=True)  # Shape: (set_num, feature_dim)\n",
    "\n",
    "    def forward(self, case_distance, glocal_weights):\n",
    "        \"\"\"\n",
    "        Apply feature weighting to the case distance in a batched manner.\n",
    "\n",
    "        Args:\n",
    "            case_distance: Tensor of shape (batch_size, sample_num, feature_dim).\n",
    "            glocal_weights: Tensor of shape (sample_num, set_num).\n",
    "\n",
    "        Returns:\n",
    "            weighted_distance: Weighted case distance, shape (batch_size, sample_num, feature_dim).\n",
    "        \"\"\"\n",
    "        global debug_print\n",
    "        debug_print = False\n",
    "\n",
    "        # Ensure positive feature weights using LeakyReLU\n",
    "        pos_feature_weights = F.leaky_relu(self.feature_weights, negative_slope=0.001)  # Shape: (set_num, feature_dim)\n",
    "        glocal_weights = F.leaky_relu(glocal_weights, negative_slope=0.001)  # Shape: (sample_num, set_num)\n",
    "\n",
    "        # Compute weight factors for all cases\n",
    "        # Resulting shape: (sample_num, feature_dim)\n",
    "        weight_factors = torch.matmul(glocal_weights, pos_feature_weights)  # Shape: (sample_num, feature_dim)\n",
    "\n",
    "        # Expand weight_factors to match batch size and elementwise multiply\n",
    "        weighted_distance = case_distance * weight_factors.unsqueeze(0)  # Shape: (batch_size, sample_num, feature_dim)\n",
    "\n",
    "        if debug_print:\n",
    "            print(\"case_distance:\", case_distance)\n",
    "            print(\"glocal_weights:\", glocal_weights)\n",
    "            print(\"feature_weights:\", self.feature_weights)\n",
    "            print(\"weighted_distance:\", weighted_distance)\n",
    "\n",
    "        return weighted_distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vr-zruqOgsQJ"
   },
   "source": [
    "## Case Bias Setup and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1736959412035,
     "user": {
      "displayName": "Xiaomeng Ye",
      "userId": "13514710516313163849"
     },
     "user_tz": 300
    },
    "id": "qBMS10DHoWVW"
   },
   "outputs": [],
   "source": [
    "# prompt: a class recording a case's How often it is activated, how often it is sampled, how often it correctly classifies a query.\n",
    "\n",
    "class CaseRecord:\n",
    "    def __init__(self, case_id = None):\n",
    "        self.case_id = case_id\n",
    "        self.activation_count = 0\n",
    "        self.sample_count = 0\n",
    "        self.correct_classification_count = 0\n",
    "\n",
    "    def activate(self):\n",
    "        self.activation_count += 1\n",
    "\n",
    "    def sample(self):\n",
    "        self.sample_count += 1\n",
    "\n",
    "    def correct_classification(self):\n",
    "        self.correct_classification_count += 1\n",
    "\n",
    "    def get_activation_rate(self):\n",
    "        return self.activation_count / (self.sample_count + 1e-10) # avoid division by zero\n",
    "\n",
    "    def get_sampling_rate(self):\n",
    "      return self.sample_count\n",
    "\n",
    "    def get_accuracy(self):\n",
    "        return self.correct_classification_count / (self.sample_count + 1e-10) # avoid division by zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1736959412035,
     "user": {
      "displayName": "Xiaomeng Ye",
      "userId": "13514710516313163849"
     },
     "user_tz": 300
    },
    "id": "-Ge7LLx-f0mm"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def find_default_bias(X, feature_extractor = None,num_samples=500, case_activation_default_percentage=0.1):\n",
    "    \"\"\"\n",
    "    Estimates the default bias for CaseNets by randomly comparing pairwise distances.\n",
    "    Handles both image (e.g., MNIST) and tabular data.\n",
    "\n",
    "    Args:\n",
    "        X: The feature tensor. Shape can be (num_cases, feature_dim) or (num_cases, 1, H, W).\n",
    "        num_samples: The number of random case pairs to compare.\n",
    "        case_activation_default_percentage: Percentage of sorted distances to select.\n",
    "\n",
    "    Returns:\n",
    "        The estimated default bias.\n",
    "    \"\"\"\n",
    "    num_cases = X.shape[0]\n",
    "    distances = []\n",
    "\n",
    "    # Flatten if data is image-like (e.g., (num_cases, 1, 28, 28))\n",
    "    if len(X.shape) > 2:\n",
    "        X_flat = X.view(num_cases, -1)  # Flatten to (num_cases, feature_dim)\n",
    "    else:\n",
    "        X_flat = X  # Already in tabular form\n",
    "    if feature_extractor is not None:\n",
    "        # Extract features using the feature extractor\n",
    "        with torch.no_grad():  # Disable gradient computation for efficiency\n",
    "            X_flat = feature_extractor(X).view(X.shape[0], -1)  # Flatten to (num_cases, feature_dim)\n",
    "\n",
    "    # Compute random pairwise distances\n",
    "    for _ in range(num_samples):\n",
    "        idx1, idx2 = torch.randint(0, num_cases, (2,))\n",
    "\n",
    "        # Calculate the pairwise distance\n",
    "        distance = F.pairwise_distance(X_flat[idx1].unsqueeze(0), X_flat[idx2].unsqueeze(0))\n",
    "        distances.append(distance.item())\n",
    "\n",
    "    # Sort distances and select top 10% based on case_activation_default_percentage\n",
    "    distances.sort()\n",
    "    percentile_index = int(len(distances) * case_activation_default_percentage)\n",
    "    default_bias = distances[percentile_index]\n",
    "\n",
    "    return default_bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1736959412035,
     "user": {
      "displayName": "Xiaomeng Ye",
      "userId": "13514710516313163849"
     },
     "user_tz": 300
    },
    "id": "Fv3FXZfghhf3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def find_default_bias_knn(X, feature_extractor=None, k=5, num_samples=500, batch_size=64):\n",
    "    \"\"\"\n",
    "    Efficiently estimates the default bias for CaseNets by computing the average distance\n",
    "    to the k-th nearest neighbor for each case, using a randomly sampled subset of cases.\n",
    "\n",
    "    Args:\n",
    "        X: The feature tensor, shape (num_cases, channels, height, width) for MNIST or CIFAR-10.\n",
    "        feature_extractor: Optional feature extractor to transform the input tensor.\n",
    "        k: The number of nearest neighbors to consider.\n",
    "        num_samples: Number of random cases to compare against.\n",
    "        batch_size: Batch size for processing cases.\n",
    "\n",
    "    Returns:\n",
    "        The estimated default bias (average distance to the k-th nearest neighbor).\n",
    "    \"\"\"\n",
    "    num_cases = X.shape[0]\n",
    "    all_kth_distances = []\n",
    "\n",
    "    # Extract features using the feature extractor, if provided\n",
    "    if feature_extractor is not None:\n",
    "        feature_list = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, num_cases, batch_size):\n",
    "                batch = X[i:i + batch_size]  # Shape: (batch_size, channels, height, width)\n",
    "                batch_features = feature_extractor(batch)  # Shape: (batch_size, feature_dim)\n",
    "                feature_list.append(batch_features)\n",
    "        X = torch.cat(feature_list, dim=0)  # Concatenate all batches\n",
    "\n",
    "    # Flatten the features for distance computation\n",
    "    X_flat = X.view(X.shape[0], -1)  # Shape: (num_cases, feature_dim)\n",
    "\n",
    "    # Randomly sample `num_samples` cases to form the comparison set\n",
    "    sampled_indices = torch.randperm(num_cases)[:num_samples]\n",
    "    sampled_cases = X_flat[sampled_indices]  # Shape: (num_samples, feature_dim)\n",
    "\n",
    "    # Process cases in batches to reduce memory usage\n",
    "    for i in range(0, num_cases, batch_size):\n",
    "        # Get the batch of cases\n",
    "        batch = X_flat[i:i + batch_size]  # Shape: (batch_size, feature_dim)\n",
    "\n",
    "        # Compute pairwise distances with the sampled cases\n",
    "        distances = torch.cdist(batch, sampled_cases)  # Shape: (batch_size, num_samples)\n",
    "\n",
    "        # Set self-distances to infinity for sampled cases\n",
    "        batch_indices = torch.arange(i, min(i + batch_size, num_cases))\n",
    "        mask = (batch_indices.unsqueeze(1) == sampled_indices.unsqueeze(0))  # Match indices in the batch\n",
    "        distances[mask] = float('inf')\n",
    "\n",
    "        # Get the k-th smallest distance for each case in the batch\n",
    "        k_actual = min(k, num_samples)  # Ensure k does not exceed the number of samples\n",
    "        kth_distances = torch.topk(distances, k=k_actual, largest=False).values[:, -1]\n",
    "        all_kth_distances.extend(kth_distances.tolist())\n",
    "\n",
    "    # Return the average k-th neighbor distance as the default bias\n",
    "    return sum(all_kth_distances) / len(all_kth_distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 620,
     "status": "ok",
     "timestamp": 1736959412654,
     "user": {
      "displayName": "Xiaomeng Ye",
      "userId": "13514710516313163849"
     },
     "user_tz": 300
    },
    "id": "U79sZXV9gNLp"
   },
   "outputs": [],
   "source": [
    "# feature_extractor = feature_extractor.to(device)\n",
    "\n",
    "case_default_bias = 0\n",
    "if bias_manual_set:\n",
    "  case_default_bias = bias_manual_value\n",
    "elif case_activation_by_top_k_average:\n",
    "  case_default_bias = find_default_bias_knn(Xs.to(device), feature_extractor, top_k_for_case_activation, num_samples)\n",
    "else:\n",
    "  case_default_bias = find_default_bias(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1736959412654,
     "user": {
      "displayName": "Xiaomeng Ye",
      "userId": "13514710516313163849"
     },
     "user_tz": 300
    },
    "id": "njMPzLMbhQKj",
    "outputId": "87f6a734-4dc6-4c95-d7f1-f7bfafccc986"
   },
   "outputs": [],
   "source": [
    "case_default_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1736959412655,
     "user": {
      "displayName": "Xiaomeng Ye",
      "userId": "13514710516313163849"
     },
     "user_tz": 300
    },
    "id": "Q6VKiDPGwQT3"
   },
   "outputs": [],
   "source": [
    "# Initialize case_default_bias as a GLOBAL trainable parameter\n",
    "# case_default_bias = nn.Parameter(torch.tensor(find_default_bias(Xs), dtype=torch.float32, device=device), requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2MNAEUwC30I0"
   },
   "source": [
    "## Case Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DC6Xhx6t19y1"
   },
   "source": [
    "### Custom Case Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1736959412655,
     "user": {
      "displayName": "Xiaomeng Ye",
      "userId": "13514710516313163849"
     },
     "user_tz": 300
    },
    "id": "74B8d3Xtz1vt"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from functools import partial\n",
    "\n",
    "def scaled_sigmoid(x):\n",
    "    \"\"\"\n",
    "    Scaled and shifted sigmoid as a PyTorch operation.\n",
    "\n",
    "    Args:\n",
    "        x: The input tensor.\n",
    "        A: The value at which the output should be close to 1.\n",
    "\n",
    "    Returns:\n",
    "        The scaled and shifted sigmoid output tensor.\n",
    "    \"\"\"\n",
    "    A = case_default_bias\n",
    "    s = 8 / A  # Scaling factor\n",
    "    b = 0 - 4      # Shift value\n",
    "    return torch.sigmoid(s * x + b)\n",
    "\n",
    "\n",
    "# Now you can use sigmoid_with_preset_A with variable x\n",
    "x = torch.randn(10)*5  # Example input tensor\n",
    "output = scaled_sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1736959412655,
     "user": {
      "displayName": "Xiaomeng Ye",
      "userId": "13514710516313163849"
     },
     "user_tz": 300
    },
    "id": "7CVkE7Kmczzj"
   },
   "outputs": [],
   "source": [
    "def mirrored_leaky_relu(x, negative_slope= 0.01, threshold = case_default_bias):\n",
    "    \"\"\"\n",
    "    Custom Leaky ReLU with mirrored behavior above a threshold.\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor.\n",
    "        negative_slope: Slope for x < 0.\n",
    "        threshold: Upper bound where the mirroring begins.\n",
    "\n",
    "    Returns:\n",
    "        Transformed tensor.\n",
    "    \"\"\"\n",
    "    # Leaky ReLU for x < 0\n",
    "    leaky_part = torch.where(x < 0, negative_slope * x, x)\n",
    "\n",
    "    # Mirroring effect for x > threshold\n",
    "    mirror_part = torch.where(x > threshold,\n",
    "                              threshold + negative_slope * (x - threshold),\n",
    "                              leaky_part)\n",
    "\n",
    "    return mirror_part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: one hot encode ys\n",
    "\n",
    "import torch\n",
    "ys = torch.tensor(ys) # Assuming ys is a NumPy array or a list\n",
    "num_classes = len(torch.unique(ys))\n",
    "ys_onehot = torch.nn.functional.one_hot(ys, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = Xs.to(device)\n",
    "ys_onehot = ys_onehot.to(device)\n",
    "ys = ys.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "je4SsvHEbB7Z"
   },
   "source": [
    "### Real Case Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1736959412655,
     "user": {
      "displayName": "Xiaomeng Ye",
      "userId": "13514710516313163849"
     },
     "user_tz": 300
    },
    "id": "sVTM16Y4gwww"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CaseNetsClassifier(nn.Module):\n",
    "    def __init__(self, cases, labels, feature_extractor=None, glocal_weightor=None, sampling_cases=sampling_cases_flag, top_k=4):\n",
    "        \"\"\"\n",
    "        A combined class that replaces both `CaseNet` and `CaseNetsClassifier`.\n",
    "\n",
    "        Args:\n",
    "            cases (torch.Tensor): Tensor containing all cases (e.g., images or sequences).\n",
    "            labels (torch.Tensor): Tensor of one-hot encoded labels for each case.\n",
    "            feature_extractor (nn.Module): Feature extractor (e.g., CNN for images or embedding for text).\n",
    "            glocal_weightor (nn.Module): Global-local weightor for feature weighting.\n",
    "            sampling_cases (bool): Whether to use sampling for case selection.\n",
    "            top_k (int): Number of top cases to retrieve for explanation.\n",
    "        \"\"\"\n",
    "        super(CaseNetsClassifier, self).__init__()\n",
    "        self.cases = cases  # Shape: [num_cases, *case_shape]\n",
    "        self.labels = labels  # Shape: [num_cases, num_classes]\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.glocal_weightor = glocal_weightor\n",
    "\n",
    "        # Group cases by class\n",
    "        self.class_to_cases = {}\n",
    "        for i, label in enumerate(self.labels):\n",
    "            class_label = torch.argmax(label).item()  # Extract class label\n",
    "            if class_label not in self.class_to_cases:\n",
    "                self.class_to_cases[class_label] = []\n",
    "            self.class_to_cases[class_label].append(i)\n",
    "\n",
    "        self.sampling_cases = sampling_cases\n",
    "        self.sample_num = num_samples\n",
    "        self.top_k = top_k\n",
    "\n",
    "        # Parameters specific to each case\n",
    "        self.biases = nn.Parameter(torch.full((len(cases),), case_default_bias))  # Shape: [num_cases]\n",
    "        self.weights = nn.Parameter(torch.ones(len(cases)))  # Shape: [num_cases]\n",
    "        self.glocal_weights = nn.Parameter(\n",
    "            torch.softmax(torch.ones(len(cases), glocal_fw_set_num), dim=-1)\n",
    "        )  # Shape: [num_cases, set_dim]\n",
    "\n",
    "        # Precompute feature dimensions if feature extractor exists\n",
    "        self.feature_dim = None\n",
    "        if feature_extractor is not None:\n",
    "            with torch.no_grad():\n",
    "                dummy_input = cases[0].unsqueeze(0).to(device)\n",
    "                self.feature_dim = feature_extractor(dummy_input).shape[-1]\n",
    "        else:\n",
    "            self.feature_dim = cases.shape[-1]\n",
    "        self.cached_features = None  # To cache features during evaluation mode\n",
    "\n",
    "        self.explanation_mode = False\n",
    "    def _extract_features(self, case_indices):\n",
    "        \"\"\"\n",
    "        Extract features for selected cases using the feature extractor.\n",
    "\n",
    "        Args:\n",
    "            case_indices (torch.Tensor): Indices of cases to process.\n",
    "\n",
    "        Returns:\n",
    "            extracted_features (torch.Tensor): Features for the selected cases.\n",
    "        \"\"\"\n",
    "        selected_cases = self.cases[case_indices]  # Shape: [num_selected_cases, *case_shape]\n",
    "\n",
    "        if self.feature_extractor is not None:\n",
    "            if self.training:\n",
    "                # Always compute features during training\n",
    "                extracted_features = self.feature_extractor(selected_cases)  # Shape: [num_selected_cases, feature_dim]\n",
    "                #wipe cache because feature extractor will be updated\n",
    "                self.cached_features = None\n",
    "            else:\n",
    "                # During evaluation, update cache only for processed indices\n",
    "                if self.cached_features is None:\n",
    "                    # Initialize cache on the first evaluation pass\n",
    "                    self.cached_features = torch.zeros(\n",
    "                        (len(self.cases), self.feature_dim), dtype=torch.float32, device=selected_cases.device\n",
    "                    )\n",
    "\n",
    "                # Check which indices need to be computed\n",
    "                uncached_indices = [idx.item() for idx in case_indices if self.cached_features[idx].sum() == 0]\n",
    "                if uncached_indices:\n",
    "                    uncached_cases = self.cases[uncached_indices]\n",
    "                    uncached_features = self.feature_extractor(uncached_cases)  # Extract features for uncached cases\n",
    "                    self.cached_features[uncached_indices] = uncached_features\n",
    "\n",
    "                # Retrieve features from the cache\n",
    "                extracted_features = self.cached_features[case_indices]\n",
    "        else:\n",
    "            # No feature extraction; use raw cases as features\n",
    "            extracted_features = selected_cases\n",
    "\n",
    "        return extracted_features\n",
    "\n",
    "\n",
    "    def forward(self, query):\n",
    "        \"\"\"\n",
    "        Perform forward pass and optionally provide explanations.\n",
    "\n",
    "        Args:\n",
    "            query (torch.Tensor): Query tensor of shape [batch_size, *query_shape].\n",
    "            explanation_mode (bool): Whether to provide explanations (top-k cases).\n",
    "\n",
    "        Returns:\n",
    "            final_predictions (torch.Tensor): Predicted probabilities/logits for each class.\n",
    "            predicted_class (torch.Tensor): Predicted class indices.\n",
    "            most_activated_cases (list, optional): List of top-k most activated cases (if explanation_mode=True).\n",
    "            most_activated_activations (torch.Tensor, optional): Activations of the top-k most activated cases.\n",
    "        \"\"\"\n",
    "        batch_size = query.size(0)\n",
    "        num_cases = len(self.cases)\n",
    "        case_indices = torch.arange(num_cases).to(query.device)  # Default: use all case_nets\n",
    "        # Sampling cases (optional)\n",
    "        if self.sampling_cases:\n",
    "          sampled_indices = []\n",
    "          each_class_sample_num = max(1, self.sample_num // len(self.class_to_cases))\n",
    "\n",
    "          for class_label, case_indices in self.class_to_cases.items():\n",
    "              if len(case_indices) >= each_class_sample_num:\n",
    "                  # Sample directly from global indices\n",
    "                  sampled_indices.extend(torch.tensor(case_indices)[torch.randperm(len(case_indices))[:each_class_sample_num]].tolist())\n",
    "              else:\n",
    "                  # If fewer cases, sample with replacement\n",
    "                  sampled_indices.extend(\n",
    "                      torch.tensor(case_indices)[torch.randint(0, len(case_indices), (each_class_sample_num,))].tolist()\n",
    "                  )\n",
    "          case_indices = torch.tensor(sampled_indices).to(query.device)\n",
    "\n",
    "        # Extract features\n",
    "        query_features = self.feature_extractor(query) if self.feature_extractor is not None else query\n",
    "        case_features = self._extract_features(case_indices)\n",
    "\n",
    "        # Compute distances\n",
    "        query_expanded = query_features.unsqueeze(1).expand(-1, len(case_indices), -1)  # [batch_size, num_selected_cases, feature_dim]\n",
    "        case_expanded = case_features.unsqueeze(0).expand(batch_size, -1, -1)  # [batch_size, num_selected_cases, feature_dim]\n",
    "        elementwise_distance = (query_expanded - case_expanded) ** 2  # Shape: [batch_size, num_selected_cases, feature_dim]\n",
    "\n",
    "        # Apply global-local weighting if applicable\n",
    "        if self.glocal_weightor is not None:\n",
    "            glocal_weights = self.glocal_weights[case_indices]  # [num_selected_cases, set_dim]\n",
    "            elementwise_distance = self.glocal_weightor(elementwise_distance, glocal_weights)  # Weighted distances\n",
    "\n",
    "        distances = torch.sqrt(torch.relu(torch.sum(elementwise_distance, dim=-1)))  # [batch_size, num_selected_cases]\n",
    "        # Convert distances to activations\n",
    "        activations = self.biases[case_indices] - torch.sqrt(distances)  # [batch_size, num_selected_cases]\n",
    "        activations = scaled_sigmoid(activations) * self.weights[case_indices]  # Scale by case-specific weights\n",
    "\n",
    "        # Multiply activations by labels\n",
    "        selected_labels = self.labels[case_indices]  # [num_selected_cases, num_classes]\n",
    "        weighted_activations = activations.unsqueeze(2) * selected_labels.unsqueeze(0)  # [batch_size, num_selected_cases, num_classes]\n",
    "\n",
    "        # Sum over cases to produce predictions\n",
    "        final_predictions = weighted_activations.sum(dim=1)  # [batch_size, num_classes]\n",
    "        predicted_class = final_predictions.argmax(dim=1)  # [batch_size]\n",
    "\n",
    "        # Explanation (Top-k cases)\n",
    "        most_activated_cases, most_activated_case_labels, most_activated_activations = None, None, None\n",
    "        if self.explanation_mode:\n",
    "            top_k_activations, top_k_indices = torch.topk(activations, self.top_k, dim=1)  # [batch_size, top_k]\n",
    "            most_activated_cases = [self.cases[case_indices[idx]] for idx in top_k_indices]\n",
    "            most_activated_case_labels = [self.labels[case_indices[idx]] for idx in top_k_indices]\n",
    "            most_activated_activations = top_k_activations\n",
    "\n",
    "        return final_predictions, predicted_class, most_activated_cases, most_activated_case_labels, most_activated_activations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpR7hv0_HIsD"
   },
   "source": [
    "Debugging code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1736959413018,
     "user": {
      "displayName": "Xiaomeng Ye",
      "userId": "13514710516313163849"
     },
     "user_tz": 300
    },
    "id": "1Z16yaz5hVfG"
   },
   "outputs": [],
   "source": [
    "# CNs = CaseNetsClassifier([exampleCN0])\n",
    "# CNs = CaseNetsClassifier([exampleCN0, exampleCN1])\n",
    "# CNs = CaseNetsClassifier([exampleCN0, exampleCN1], top_case_enabled=True)\n",
    "# CNs.eval()\n",
    "# example_queries = Xs[0:2]\n",
    "# final_predictions, predicted_class = CNs(example_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1736959413018,
     "user": {
      "displayName": "Xiaomeng Ye",
      "userId": "13514710516313163849"
     },
     "user_tz": 300
    },
    "id": "S_hxHspW_nF3"
   },
   "outputs": [],
   "source": [
    "# final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1736959413018,
     "user": {
      "displayName": "Xiaomeng Ye",
      "userId": "13514710516313163849"
     },
     "user_tz": 300
    },
    "id": "f3GEIoYi_pHn"
   },
   "outputs": [],
   "source": [
    "# predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1736959413019,
     "user": {
      "displayName": "Xiaomeng Ye",
      "userId": "13514710516313163849"
     },
     "user_tz": 300
    },
    "id": "HBBhj1VvDDlo"
   },
   "outputs": [],
   "source": [
    "# for name, param in CNs.named_parameters():\n",
    "#     print(f\"Parameter name: {name}\")\n",
    "#     print(f\"Parameter data: {param.data}\")\n",
    "#     print(f\"Requires gradient: {param.requires_grad}\")\n",
    "#     print(\"------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANUAL RUN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmbLMmPmvupr"
   },
   "source": [
    "## Training Case Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.freeze_feature_extractor:\n",
    "    X_train_transformed = transform_dataset(X_train, feature_extractor, batch_size=128, device=device)\n",
    "    X_test_transformed = transform_dataset(X_test, feature_extractor, batch_size=128, device=device)\n",
    "    X_train = X_train_transformed\n",
    "    X_test = X_test_transformed\n",
    "    feature_extractor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.batch_size = 100\n",
    "cfg.PATH = os.path.join(folder_name, f'checkpoints/classifier_{dataset_name}.h5')\n",
    "cfg.patience = 7\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1736959413019,
     "user": {
      "displayName": "Xiaomeng Ye",
      "userId": "13514710516313163849"
     },
     "user_tz": 300
    },
    "id": "GS1vkeXb-W49",
    "outputId": "e3bd747e-c64f-4183-a35c-471a454363a3"
   },
   "outputs": [],
   "source": [
    "if feature_extractor is not None:\n",
    "    for param in feature_extractor.parameters():\n",
    "        print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ELS7DMrCCvVK",
    "outputId": "0dfd2ff4-e40b-4afc-ec0e-4a77f0e3c84b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def train_model(X_train, y_train, X_val, y_val, cfg, glocal_fw_set_num=glocal_fw_set_num):\n",
    "    global debug_print\n",
    "    \"\"\"\n",
    "    Train the NN-kNN model using the provided train/validation split.\n",
    "\n",
    "    Args:\n",
    "        X_train: Training feature tensor.\n",
    "        y_train: Training labels.\n",
    "        X_val: Validation feature tensor.\n",
    "        y_val: Validation labels.\n",
    "        cfg: Configuration object with training hyperparameters.\n",
    "        glocal_fw_set_num: Number of sets for the global feature weightor.\n",
    "\n",
    "    Returns:\n",
    "        best_accuracy: The best accuracy achieved during training.\n",
    "        glocal_weightor: The trained global feature weightor.\n",
    "    \"\"\"\n",
    "    # Move data to the appropriate device\n",
    "    X_train = X_train.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "\n",
    "    # DataLoader for batching\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.TensorDataset(X_train, y_train),\n",
    "        batch_size=cfg.batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.TensorDataset(X_val, y_val),\n",
    "        batch_size=cfg.batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Initialize the global feature weightor\n",
    "    glocal_weightor = GlocalFeatureWeight(feature_dim, glocal_fw_set_num)\n",
    "    glocal_weightor.to(device)\n",
    "\n",
    "    print(glocal_weightor.state_dict())\n",
    "    # Initialize CaseNet instances for the training set\n",
    "    # case_nets = [CaseNet(X_train[i], ys_onehot[i], feature_weightor=glocal_weightor) for i in range(len(X_train))]\n",
    "    # model = CaseNetsClassifier(case_nets, glocal_weightor, feature_extractor)\n",
    "\n",
    "    model = CaseNetsClassifier(X_train, ys_onehot, feature_extractor, glocal_weightor)\n",
    "    model.to(device)\n",
    "    # Separate parameters for different learning rates\n",
    "    feature_extractor_params = list()\n",
    "    if(feature_extractor is not None):\n",
    "        feature_extractor_params = list(feature_extractor.parameters())\n",
    "    glocal_weightor_params = list(model.glocal_weightor.parameters())\n",
    "    #print out number of parameters here\n",
    "\n",
    "    shared_params_ids = {id(param) for param in feature_extractor_params + glocal_weightor_params}\n",
    "    # case_net_params = [param for case_net in model.case_nets for param in case_net.parameters() if id(param) not in shared_params_ids]\n",
    "    case_net_params = [param for param in model.parameters() if id(param) not in shared_params_ids]\n",
    "    print(\"Number of feature extractor parameters:\", len(feature_extractor_params))\n",
    "    for param in feature_extractor_params:\n",
    "        print(param.shape)\n",
    "    print(\"Number of glocal weightor parameters:\", len(glocal_weightor_params))\n",
    "    for param in glocal_weightor_params:\n",
    "        print(param.shape)\n",
    "    print(\"Number of case_net_params:\", len(case_net_params))\n",
    "    for param in case_net_params:\n",
    "        print(param.shape)\n",
    "    print(\"*****************\")\n",
    "    # print(model.state_dict())\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': feature_extractor_params, 'lr': 1e-4},\n",
    "        {'params': glocal_weightor_params, 'lr': 1e-3}, #I tried 1e-3 here, this is better.\n",
    "        {'params': case_net_params, 'lr': 1e-4}\n",
    "    ], weight_decay=1e-5)\n",
    "\n",
    "    patience_counter = 0\n",
    "    best_accuracy = 0\n",
    "    best_val_loss = float('inf')\n",
    "    best_found = False\n",
    "    best_epoch = 0\n",
    "    print(f\"Training started for {cfg.training_epochs} epochs with batch size {cfg.batch_size}\")\n",
    "\n",
    "    for epoch in range(cfg.training_epochs):\n",
    "        if best_found:\n",
    "            break\n",
    "        running_loss = 0.0\n",
    "        total_batches = len(train_loader)\n",
    "\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            # break\n",
    "            optimizer.zero_grad()\n",
    "            # print(X_batch.shape)\n",
    "            final_predictions, _, _, _,_= model(X_batch)\n",
    "            # print(\"Checking final pred\")\n",
    "            # print(final_predictions)\n",
    "            # print(\"Checking y_batch\")\n",
    "            # print(y_batch)\n",
    "            loss = criterion(final_predictions, y_batch)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"[Epoch {epoch+1}/{cfg.training_epochs}] - Loss: {loss.item():.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            final_predictions = torch.empty((0, num_classes))\n",
    "            predicted_classes = torch.empty((0,))\n",
    "            for batch_idx, (X_batch, _) in enumerate(val_loader):\n",
    "                X_batch = X_batch.to(device)\n",
    "\n",
    "                final_prediction, predicted_class,_,_, _ = model(X_batch)\n",
    "                \n",
    "                final_predictions = torch.cat((final_predictions, final_prediction.cpu()), dim=0)\n",
    "                predicted_classes = torch.cat((predicted_classes, predicted_class.cpu()), dim=0)\n",
    "\n",
    "            # print(final_predictions.shape, y_val.shape)\n",
    "            accuracy = accuracy_score(y_val, predicted_classes.cpu().numpy())\n",
    "            val_loss = criterion(final_predictions, y_val).item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1} - Validation Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Epoch {epoch+1} - Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping and model saving\n",
    "\n",
    "        if epoch == 0 or best_accuracy < accuracy:\n",
    "            best_val_loss = val_loss\n",
    "            best_accuracy = accuracy_score(y_val, predicted_classes.cpu().numpy())\n",
    "            torch.save(model.state_dict(), cfg.PATH)\n",
    "            print(f\"New best loss {val_loss:.4f} - Model saved.\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"so far, best loss: {best_val_loss:.4f}\")\n",
    "            print(f\"so far, best acc: {best_accuracy:.4f}\")\n",
    "        if patience_counter > cfg.patience:\n",
    "            print(\"Patience exceeded. Loading best model.\")\n",
    "            model.load_state_dict(torch.load(cfg.PATH))\n",
    "            best_found = True\n",
    "            break\n",
    "\n",
    "    print(\"Training completed. Best Acc: \", best_accuracy)\n",
    "    return best_accuracy, glocal_weightor, model\n",
    "\n",
    "\n",
    "def cross_validate(Xs, ys, cfg, k_folds=10):\n",
    "    \"\"\"\n",
    "    Perform k-fold cross-validation using the train_model function.\n",
    "\n",
    "    Args:\n",
    "        Xs: Feature tensor.\n",
    "        ys: Labels.\n",
    "        cfg: Configuration object.\n",
    "        k_folds: Number of cross-validation folds.\n",
    "\n",
    "    Returns:\n",
    "        best_accuracies: List of best accuracies for each fold.\n",
    "    \"\"\"\n",
    "    k_fold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    best_accuracies = []\n",
    "    last_model = None\n",
    "    for train_index, test_index in k_fold.split(Xs):\n",
    "        X_train, X_test = Xs[train_index], Xs[test_index]\n",
    "        y_train, y_test = ys[train_index], ys[test_index]\n",
    "\n",
    "        best_accuracy, _, last_model = train_model(X_train, y_train, X_test, y_test, cfg)\n",
    "        best_accuracies.append(best_accuracy)\n",
    "        # break\n",
    "\n",
    "    print(\"Cross-validation results:\", best_accuracies)\n",
    "    print(f\"Average accuracy: {np.mean(best_accuracies):.3f}\")\n",
    "    print(f\"Standard deviation: {np.std(best_accuracies):.3f}\")\n",
    "    print(f\"{np.mean(best_accuracies):.3f} ({np.std(best_accuracies):.3f})\")\n",
    "    return best_accuracies, last_model\n",
    "\n",
    "\n",
    "def train_with_given_split(X_train, y_train, X_test, y_test, cfg):\n",
    "    \"\"\"\n",
    "    Train NN-kNN directly with a provided train/test split.\n",
    "\n",
    "    Args:\n",
    "        X_train: Training feature tensor.\n",
    "        y_train: Training labels.\n",
    "        X_test: Test feature tensor.\n",
    "        y_test: Test labels.\n",
    "        cfg: Configuration object.\n",
    "    \"\"\"\n",
    "    best_accuracy, glocal_weightor, model = train_model(X_train, y_train, X_test, y_test, cfg)\n",
    "    print(f\"Accuracy on provided split: {best_accuracy:.3f}\")\n",
    "    #print(\"Final global feature weights:\", glocal_weightor.feature_weights)\n",
    "    return best_accuracy, glocal_weightor, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dim = 256\n",
    "\n",
    "best_accuracies = []\n",
    "for i in range(8):\n",
    "    if not cfg.freeze_feature_extractor:\n",
    "       feature_extractor = BiLSTMFeatureExtractor().to(device)\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "      torch.cuda.empty_cache()\n",
    "    best_accuracy, glocal_weightor, last_model = train_with_given_split(X_train, y_train, X_test, y_test, cfg)\n",
    "    best_accuracies.append(best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_accuracy = np.mean(best_accuracies)\n",
    "print(f\"Average accuracy across all folds: {average_accuracy}\")\n",
    "print(f\"Standard deviation of accuracy: {np.std(best_accuracies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average accuracy:{np.mean(best_accuracies):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(best_accuracies), min(best_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9Ueijo6OGP1"
   },
   "source": [
    "## Load Model From Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cUuWejcPPEsn"
   },
   "outputs": [],
   "source": [
    "# Updated to reflect the removal of CaseNet\n",
    "def load_model_cns(X_train, y_train, cfg):\n",
    "    \"\"\"\n",
    "    Load a CaseNetsClassifier model with the provided training data and configuration.\n",
    "\n",
    "    Args:\n",
    "        X_train (torch.Tensor): Tensor of training cases (e.g., images or sequences).\n",
    "        y_train (torch.Tensor): Tensor of one-hot encoded labels for each case.\n",
    "        cfg: Configuration object containing model parameters.\n",
    "\n",
    "    Returns:\n",
    "        CaseNetsClassifier: The loaded model.\n",
    "    \"\"\"\n",
    "    # Define the global-local weightor\n",
    "    glocal_weightor = GlocalFeatureWeight(feature_dim=feature_dim, set_dim=glocal_fw_set_num)\n",
    "    # glocal_weightor.load_state_dict(torch.load(feature_weightor_path))  # Optional: Load pre-trained weights\n",
    "    glocal_weightor.to(device)\n",
    "\n",
    "    # Initialize the CaseNetsClassifier directly with cases and labels\n",
    "    model = CaseNetsClassifier(\n",
    "        cases=X_train,\n",
    "        labels=y_train,\n",
    "        feature_extractor=feature_extractor,  # Pass the feature extractor\n",
    "        glocal_weightor=glocal_weightor  # Pass the global-local weightor\n",
    "    )\n",
    "\n",
    "    # Load the model's weights\n",
    "    model.load_state_dict(torch.load(cfg.PATH))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 76020,
     "status": "ok",
     "timestamp": 1736719243813,
     "user": {
      "displayName": "Xiaomeng Ye",
      "userId": "13514710516313163849"
     },
     "user_tz": 300
    },
    "id": "knVNy1AXOFw9",
    "outputId": "ebd209db-d852-4df0-dea2-591b7f06e42e"
   },
   "outputs": [],
   "source": [
    "cfg.PATH = os.path.join(folder_name, f'checkpoints/classifier_{dataset_name}.h5')\n",
    "model = load_model_cns(X_train, y_train, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1736719243814,
     "user": {
      "displayName": "Xiaomeng Ye",
      "userId": "13514710516313163849"
     },
     "user_tz": 300
    },
    "id": "geCINROvItc1",
    "outputId": "4b2554f0-2261-44f6-e590-abd9ef2c50e5"
   },
   "outputs": [],
   "source": [
    "model.sample_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3635,
     "status": "ok",
     "timestamp": 1736719247447,
     "user": {
      "displayName": "Xiaomeng Ye",
      "userId": "13514710516313163849"
     },
     "user_tz": 300
    },
    "id": "qhVk1AJBT-h1",
    "outputId": "6b00a3c4-303d-4af4-ad79-96e9ceb1a4ce"
   },
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9j5C3HOCJ_6_"
   },
   "outputs": [],
   "source": [
    "# prompt: garbage collection\n",
    "\n",
    "import gc\n",
    "\n",
    "# Force garbage collection\n",
    "gc.collect()\n",
    "\n",
    "# For CUDA tensors\n",
    "if torch.cuda.is_available():\n",
    "  torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 873,
     "status": "ok",
     "timestamp": 1736622899487,
     "user": {
      "displayName": "Xiaomeng Ye",
      "userId": "13514710516313163849"
     },
     "user_tz": 300
    },
    "id": "crtSSc0RUFGM",
    "outputId": "3b538378-2894-40b4-ab0a-cbb305e5644e"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset # Import TensorDataset\n",
    "\n",
    "\n",
    "X_val = X_test.to(device)\n",
    "y_val = y_test.to(device)\n",
    "batch_size = 128  # Or an even smaller size if needed\n",
    "\n",
    "# Create a DataLoader for your validation data\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "final_predictions_list = []\n",
    "predicted_class_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in val_loader:\n",
    "        batch_final_predictions, batch_predicted_class,_,_ = model(batch_X)\n",
    "        final_predictions_list.append(batch_final_predictions)\n",
    "        predicted_class_list.append(batch_predicted_class)\n",
    "\n",
    "# Concatenate predictions from all batches\n",
    "final_predictions = torch.cat(final_predictions_list, dim=0)\n",
    "predicted_class = torch.cat(predicted_class_list, dim=0)\n",
    "# final_predictions, predicted_class = model(X_val)\n",
    "val_loss = criterion(final_predictions, y_val).item()\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "best_accuracy = accuracy_score(y_val.cpu().numpy(), predicted_class.cpu().numpy())\n",
    "print(f\"Validation Accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Move data to device\n",
    "X_val = X_test.to(device)\n",
    "y_val = y_test.to(device)\n",
    "batch_size = 128  # Or an even smaller size if needed\n",
    "\n",
    "# Create a DataLoader for your validation data\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "final_predictions_list = []\n",
    "predicted_class_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in val_loader:\n",
    "        # Get predictions for the batch\n",
    "        batch_final_predictions, batch_predicted_class, _, _, _ = model(batch_X)\n",
    "        final_predictions_list.append(batch_final_predictions)\n",
    "        predicted_class_list.append(batch_predicted_class)\n",
    "\n",
    "# Concatenate predictions from all batches\n",
    "final_predictions = torch.cat(final_predictions_list, dim=0)\n",
    "predicted_class = torch.cat(predicted_class_list, dim=0)\n",
    "\n",
    "# Compute validation loss\n",
    "val_loss = criterion(final_predictions, y_val).item()\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Calculate accuracy for the top-1 predictions\n",
    "best_accuracy = accuracy_score(y_val.cpu().numpy(), predicted_class.cpu().numpy())\n",
    "print(f\"Validation Accuracy (Top-1): {best_accuracy:.4f}\")\n",
    "\n",
    "# Calculate Top-k Accuracies (Top-1, Top-2, Top-3)\n",
    "top_k_values = [1, 2, 3]\n",
    "top_k_correct_counts = {k: 0 for k in top_k_values}\n",
    "\n",
    "# Get top-k predictions for each sample\n",
    "top_k_predictions = torch.topk(final_predictions, max(top_k_values), dim=1).indices  # Shape: [num_samples, max_k]\n",
    "\n",
    "for k in top_k_values:\n",
    "    # Check if the correct class is within the top-k predictions\n",
    "    correct_in_top_k = torch.any(top_k_predictions[:, :k] == y_val.unsqueeze(1), dim=1)\n",
    "    top_k_correct_counts[k] = correct_in_top_k.sum().item()\n",
    "\n",
    "# Calculate percentages\n",
    "num_samples = y_val.size(0)\n",
    "for k in top_k_values:\n",
    "    accuracy_k = top_k_correct_counts[k] / num_samples * 100\n",
    "    print(f\"Top-{k} Accuracy: {accuracy_k:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQMTPXLwaBVq"
   },
   "source": [
    "# Results Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FeyCa4Nitll8"
   },
   "source": [
    "## Inspecting one case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3uBeaYMgI_G"
   },
   "source": [
    "### Explanation for SST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code need a feature extractor which is supposed to be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_transformed:\n",
    "    raise ValueError(\"Please use the feature extractor and the data before transformation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_and_explain_sst(model, query, vocab, classes, device='cuda'):\n",
    "    \"\"\"\n",
    "    Classify a query sentence and provide the most activated case as an explanation.\n",
    "\n",
    "    Args:\n",
    "        model (CaseNetsClassifier): Trained model for classification.\n",
    "        query (torch.Tensor): Query tensor of shape [seq_len].\n",
    "        case_nets (list): List of CaseNet objects.\n",
    "        vocab (torchtext.vocab.Vocab): Vocabulary used for numericalization.\n",
    "        classes (list): List of class names for the dataset.\n",
    "        device (str): Device to run the inference on ('cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "        dict: Results containing predictions and explanation.\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    query = query.unsqueeze(0).to(device)  # Add batch dimension [1, seq_len]\n",
    "\n",
    "    # Classify query and get explanation\n",
    "    final_predictions, predicted_class, most_activated_cases, most_activated_case_labels, most_activated_activations = model(query)\n",
    "    \n",
    "    results = {\"query\": None,\n",
    "                \"query_prediction\": classes[predicted_class.item()],\n",
    "                \"explanations\": []}\n",
    "    # Get the most activated case and its label\n",
    "    for i, (case, label, activation) in enumerate(zip(most_activated_cases[0], most_activated_case_labels[0], most_activated_activations[0])):\n",
    "        most_activated_case = case.cpu().squeeze()\n",
    "        most_activated_label = torch.argmax(label).item()\n",
    "        most_activated_activation = activation.item()\n",
    "\n",
    "        # Decode query and most activated case from indices to tokens\n",
    "        def decode(tokens, vocab):\n",
    "            reverse_vocab = {idx: token for token, idx in vocab.items()}  # Create reverse mapping\n",
    "            return \" \".join([reverse_vocab[token.item()] for token in tokens if token.item() != vocab[\"<pad>\"]])\n",
    "\n",
    "        query_text = decode(query.squeeze().cpu(), vocab)\n",
    "        results[\"query\"] = query_text\n",
    "        most_activated_case_text = decode(most_activated_case, vocab)\n",
    "        # Append explanation to results\n",
    "        results[\"explanations\"].append({\n",
    "            \"most_activated_case\": most_activated_case_text,\n",
    "            \"most_activated_case_label\": classes[most_activated_label],\n",
    "            \"most_activated_activation\": most_activated_activation\n",
    "        })\n",
    "    # Return detailed results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random_indices = random.sample(range(len(X_test)), 20)\n",
    "\n",
    "classes = [\"Negative\", \"Positive\"] if dataset_name == 'sst2' else [\"Negative\", \"Somewhat Negative\", \"Neutral\", \"Somewhat Positive\", \"Positive\"] # SST five classes\n",
    "model = last_model\n",
    "model.explanation_mode = True\n",
    "# Loop through the randomly selected queries\n",
    "for i, query_idx in enumerate(random_indices):  # Loop through the first 20 test queries\n",
    "    query = X_test[query_idx]  # Get numericalized query tensor\n",
    "    true_class = y_test[query_idx]  # Get true class label\n",
    "    # Run the classify_and_explain_sst function\n",
    "    results = classify_and_explain_sst(model, query, word2idx, classes, device)\n",
    "\n",
    "    # Print the classification results\n",
    "    print(f\"--- Example {query_idx + 1} ---\")\n",
    "    print(f\"Query Sentence: {results['query']}\")\n",
    "    print(f\"True Class: {classes[true_class]}\")\n",
    "    print(f\"Predicted Class: {results['query_prediction']}\")\n",
    "    for j in range(4):\n",
    "        print(f\"{j}-th most Activated Case Sentence: {results['explanations'][j]['most_activated_case']}\")\n",
    "        print(f\"{j}-th most Activated Case Label: {results['explanations'][j]['most_activated_case_label']}\")\n",
    "        print(f\"{j}-th most Activated Activation: {results['explanations'][j]['most_activated_activation']:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "vHknYLrK33ES",
    "2MNAEUwC30I0",
    "r3LIZuDx1nTb"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0422fc6571be4c74a52f6921ede7ffe3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04742c89c1b547688d00e83061e2745a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d23bc184c24d45caa0edf9cf4348b799",
      "placeholder": "​",
      "style": "IPY_MODEL_bae282222a5c411fa537b916657a2484",
      "value": "README.md: 100%"
     }
    },
    "087d58161c88469c849d7447cf955587": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ad45f84f676414e9d3f6306190c4f54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3dd500a973f84a69ad006789fd3dae78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_feb45fffa16343feb7d3d37b02789985",
      "placeholder": "​",
      "style": "IPY_MODEL_d7d1390fd2324a2e825d2ae15255b2dc",
      "value": "sst.py: 100%"
     }
    },
    "4257c6ca9c3145ab98f1e7bc6294af74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4ffdb54012f441c5a126a4f18c9bdeea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7b94c3ac67bd4725acd667224e68f760": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8b7109d8d8794d448fb7231dd462cc57": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_04742c89c1b547688d00e83061e2745a",
       "IPY_MODEL_cc0f4b41fc144ff8b992d6213b1fee9e",
       "IPY_MODEL_8cc7a3530c95486180f899f26f6a957e"
      ],
      "layout": "IPY_MODEL_e244bc14a76643a48c42a4e2f24e693d"
     }
    },
    "8cc7a3530c95486180f899f26f6a957e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be07a610139e4891a5497b6707b8a218",
      "placeholder": "​",
      "style": "IPY_MODEL_7b94c3ac67bd4725acd667224e68f760",
      "value": " 6.68k/6.68k [00:00&lt;00:00, 165kB/s]"
     }
    },
    "bae282222a5c411fa537b916657a2484": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bd8cdb7e1899475c94df9be717531dcb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be07a610139e4891a5497b6707b8a218": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c55a77cae6514cd78a8767b336dc8d84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0422fc6571be4c74a52f6921ede7ffe3",
      "max": 9132,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0ad45f84f676414e9d3f6306190c4f54",
      "value": 9132
     }
    },
    "cc0f4b41fc144ff8b992d6213b1fee9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_087d58161c88469c849d7447cf955587",
      "max": 6679,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4257c6ca9c3145ab98f1e7bc6294af74",
      "value": 6679
     }
    },
    "d02edeb6734d420db15f7316da338020": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd8cdb7e1899475c94df9be717531dcb",
      "placeholder": "​",
      "style": "IPY_MODEL_4ffdb54012f441c5a126a4f18c9bdeea",
      "value": " 9.13k/9.13k [00:00&lt;00:00, 328kB/s]"
     }
    },
    "d23bc184c24d45caa0edf9cf4348b799": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7d1390fd2324a2e825d2ae15255b2dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e244bc14a76643a48c42a4e2f24e693d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9d6cb061ce34f94928f92fccc7dd87a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec3b72b7b99047c8b8a21e05949cf13b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3dd500a973f84a69ad006789fd3dae78",
       "IPY_MODEL_c55a77cae6514cd78a8767b336dc8d84",
       "IPY_MODEL_d02edeb6734d420db15f7316da338020"
      ],
      "layout": "IPY_MODEL_e9d6cb061ce34f94928f92fccc7dd87a"
     }
    },
    "feb45fffa16343feb7d3d37b02789985": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
